{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd2d5d-0c88-4acf-b033-1bd39f98df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import gc\n",
    "import time\n",
    "\n",
    "gc.collect()  # Clear unused memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81c5d5-8b29-4266-bf38-358b1e2ce07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .h5 file into memory once\n",
    "h5_file_path_train = r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\classification_data\\training_20_perc_subset.h5\"\n",
    "h5_file_path_test = r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\classification_data\\testing_20_perc_subset.h5\"\n",
    "\n",
    "# Open the H5 files\n",
    "h5_train = h5py.File(h5_file_path_train, 'r')\n",
    "h5_test = h5py.File(h5_file_path_test, 'r')\n",
    "\n",
    "# Extract datasets\n",
    "train_sen1_data = h5_train['sen1']\n",
    "train_sen2_data = h5_train['sen2']\n",
    "train_labels = h5_train['label']\n",
    "\n",
    "test_sen1_data = h5_test['sen1']\n",
    "test_sen2_data = h5_test['sen2']\n",
    "test_labels = h5_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f605-f75e-44c6-962b-27a0d9b8a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, sen1_data, sen2_data, labels):\n",
    "        self.sen1_data = sen1_data\n",
    "        self.sen2_data = sen2_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sen1_image = self.sen1_data[idx]\n",
    "        sen2_image = self.sen2_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        sen1_image = torch.tensor(sen1_image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        sen2_image = torch.tensor(sen2_image, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        # Convert one-hot encoded label to class index\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        label = torch.argmax(label).long()\n",
    "\n",
    "        return sen1_image, sen2_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4895f3-7da0-4044-b406-46618b0e9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SatelliteDataset(train_sen1_data, train_sen2_data, train_labels)\n",
    "test_dataset = SatelliteDataset(test_sen1_data, test_sen2_data, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df3f85-6f79-40d3-9e95-b97d4782ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=17):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Hyperparameters from Optuna\n",
    "        kernel_size = 7\n",
    "        dropout_rate = 0.24494376906450327\n",
    "\n",
    "        # Sentinel-1 branch\n",
    "        self.sen1_conv1 = nn.Conv2d(8, 32, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen1_dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen1_conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen1_dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen1_conv3 = nn.Conv2d(64, 128, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen1_dropout3 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen1_pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Sentinel-2 branch\n",
    "        self.sen2_conv1 = nn.Conv2d(10, 32, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen2_dropout1 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen2_conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen2_dropout2 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen2_conv3 = nn.Conv2d(64, 128, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.sen2_dropout3 = nn.Dropout(p=dropout_rate)\n",
    "        self.sen2_pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8 * 2, 128)  # Adjusted based on additional convolution\n",
    "        self.fc1_dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc2_dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, sen1, sen2):\n",
    "        # Sentinel-1 forward pass\n",
    "        x1 = F.relu(self.sen1_conv1(sen1))\n",
    "        x1 = self.sen1_dropout1(x1)\n",
    "        x1 = F.relu(self.sen1_conv2(x1))\n",
    "        x1 = self.sen1_dropout2(x1)\n",
    "        x1 = self.sen1_pool(F.relu(self.sen1_conv3(x1)))\n",
    "        x1 = self.sen1_dropout3(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        # Sentinel-2 forward pass\n",
    "        x2 = F.relu(self.sen2_conv1(sen2))\n",
    "        x2 = self.sen2_dropout1(x2)\n",
    "        x2 = F.relu(self.sen2_conv2(x2))\n",
    "        x2 = self.sen2_dropout2(x2)\n",
    "        x2 = self.sen2_pool(F.relu(self.sen2_conv3(x2)))\n",
    "        x2 = self.sen2_dropout3(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        # Concatenate both branches\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bca84e-b7a0-49ac-a21b-8fdc15bd3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with visualization and memory clearing\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []  # List to store training loss for visualization\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i, (sen1, sen2, labels) in enumerate(train_loader):\n",
    "            sen1, sen2, labels = sen1.to(device), sen2.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sen1, sen2)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Clear memory for each batch (optional but not usually necessary here)\n",
    "            del outputs, loss\n",
    "\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        epoch_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Average Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # Clear unused memory after each epoch\n",
    "        torch.cuda.empty_cache()  # Clear GPU memory\n",
    "        gc.collect()  # Trigger garbage collection for CPU memory\n",
    "\n",
    "    print('Training complete')\n",
    "\n",
    "    # Visualization of training loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7b178-0de8-41b6-b5d5-a6bcef592cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    val_losses = []  # Optional, to track across batches if needed\n",
    "    val_accuracies = []  # Optional, to track across batches if needed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sen1, sen2, labels in test_loader:\n",
    "            sen1, sen2, labels = sen1.to(device), sen2.to(device), labels.to(device)\n",
    "            outputs = model(sen1, sen2)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f'Average Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Visualization (optional)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['Loss', 'Accuracy'], [avg_loss, accuracy])\n",
    "    plt.title('Evaluation Results')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a443ae-ac07-4775-ad71-be324357ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "# model = ConvNet(num_classes=17)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffdaff-5fd0-43bd-b1ac-07985ccde55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# gc.collect()\n",
    "# train_model(model, train_loader, criterion, optimizer, num_epochs=50, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb524ae-cba3-489c-a843-10a547b7da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform evaluation\n",
    "# gc.collect()\n",
    "# evaluate_model(model, test_loader, criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb184c8-aae3-4638-a372-337115923159",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print((end-start)//60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7352f5e-4ecd-40f0-aff7-e8c6361e6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_dataset, val_dataset):\n",
    "    # Hyperparameter search space\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5, 7])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 32, 256, step=32)\n",
    "\n",
    "    # Model initialization\n",
    "    model = ConvNet(num_classes=17)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = 5\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for sen1_inputs, sen2_inputs, labels in train_loader:\n",
    "            sen1_inputs, sen2_inputs, labels = (\n",
    "                sen1_inputs.to(device),\n",
    "                sen2_inputs.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sen1_inputs, sen2_inputs)  # Pass both inputs to the model\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sen1_inputs, sen2_inputs, labels in val_loader:\n",
    "                sen1_inputs, sen2_inputs, labels = (\n",
    "                    sen1_inputs.to(device),\n",
    "                    sen2_inputs.to(device),\n",
    "                    labels.to(device),\n",
    "                )\n",
    "                outputs = model(sen1_inputs, sen2_inputs)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_accuracy = correct / total\n",
    "        best_val_accuracy = max(best_val_accuracy, val_accuracy)\n",
    "\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7314d4-4bde-4591-b6b7-b2516b7c714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Run the study with datasets passed as arguments\n",
    "study = optuna.create_study(direction=\"maximize\")  # Maximize validation accuracy\n",
    "study.optimize(lambda trial: objective(trial, train_dataset, test_dataset), n_trials=50)  # Pass datasets\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best Validation Accuracy:\", study.best_value)\n",
    "\n",
    "end = time.time()\n",
    "print((end-start)//60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a7554-bafc-4272-9798-8f6a20c97e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd579aae-5488-4d55-b4f7-a923e8003fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
