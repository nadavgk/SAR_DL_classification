{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4172e526-0fa0-455b-8041-be7781b0b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import gc\n",
    "\n",
    "gc.collect()  # Clear unused memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3d609f-5b72-48eb-a4ec-a87dafdff2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .h5 file into memory once\n",
    "h5_file_path_train = r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\classification_data\\training.h5\"\n",
    "h5_file_path_test = r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\classification_data\\testing.h5\"\n",
    "\n",
    "\n",
    "# Open the H5 files\n",
    "h5_train = h5py.File(h5_file_path_train, 'r')\n",
    "h5_test = h5py.File(h5_file_path_test, 'r')\n",
    "\n",
    "# Extract datasets\n",
    "#train_sen1_data = h5_train['sen1']\n",
    "train_sen2_data = h5_train['sen2']\n",
    "train_labels = h5_train['new_labels']\n",
    "\n",
    "#test_sen1_data = h5_test['sen1']\n",
    "test_sen2_data = h5_test['sen2']\n",
    "test_labels = h5_test['new_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfb0654-8a29-4446-bc74-cb1e7411a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentinel2Dataset(Dataset):\n",
    "    def __init__(self, sen2_data, labels):\n",
    "        self.sen2_data = sen2_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract Sentinel-2 image and label\n",
    "        sen2_image = self.sen2_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        sen2_image = torch.tensor(sen2_image, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        # Convert one-hot encoded label to class index\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        label = torch.argmax(label).long()\n",
    "\n",
    "        return sen2_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf932b0a-a713-45c6-912d-d13126e9ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = Sentinel2Dataset(train_sen2_data, train_labels)\n",
    "test_dataset = Sentinel2Dataset(test_sen2_data, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb92685f-8142-4e6d-aed1-8144df1bdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentinel2ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(Sentinel2ConvNet, self).__init__()\n",
    "\n",
    "        # Sentinel-2 branch\n",
    "        self.conv1 = nn.Conv2d(10, 32, kernel_size=3, padding=1)  # Adjusted input channels to 10\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout2 = nn.Dropout(p=0.25)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # Adjust as per the spatial dimensions of the feature map\n",
    "        self.fc1_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc2_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Sentinel-2 forward pass\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48ea977b-5567-47ad-b37e-2d72913208cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with visualization and memory clearing for Sentinel-2\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []  # List to store training loss for visualization\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i, (sen2, labels) in enumerate(train_loader):\n",
    "            sen2, labels = sen2.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sen2)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Clear memory for each batch (optional but not usually necessary here)\n",
    "            del outputs, loss\n",
    "\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Average loss for the epoch\n",
    "        epoch_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Average Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        # Clear unused memory after each epoch\n",
    "        torch.cuda.empty_cache()  # Clear GPU memory\n",
    "        gc.collect()  # Trigger garbage collection for CPU memory\n",
    "\n",
    "    print('Training complete')\n",
    "\n",
    "    # Visualization of training loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba395fe6-1fcb-40ae-8122-7bbfcee60d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device='cuda'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sen2, labels in test_loader:\n",
    "            sen2, labels = sen2.to(device), labels.to(device)\n",
    "            outputs = model(sen2)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f'Average Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Visualization (optional)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(['Loss', 'Accuracy'], [avg_loss, accuracy])\n",
    "    plt.title('Evaluation Results')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d809843d-7b2d-4e6a-9afb-a905abd9d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = Sentinel2ConvNet(num_classes=9)  # Adjust num_classes based on your dataset\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0209824a-a770-4c1a-9386-fcd23cb9c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/5013], Loss: 1.5640\n",
      "Epoch [1/50], Step [200/5013], Loss: 1.2387\n",
      "Epoch [1/50], Step [300/5013], Loss: 1.1490\n",
      "Epoch [1/50], Step [400/5013], Loss: 1.1138\n",
      "Epoch [1/50], Step [500/5013], Loss: 1.0493\n",
      "Epoch [1/50], Step [600/5013], Loss: 1.0570\n",
      "Epoch [1/50], Step [700/5013], Loss: 1.0428\n",
      "Epoch [1/50], Step [800/5013], Loss: 0.9968\n",
      "Epoch [1/50], Step [900/5013], Loss: 0.9798\n",
      "Epoch [1/50], Step [1000/5013], Loss: 0.9803\n",
      "Epoch [1/50], Step [1100/5013], Loss: 0.9199\n",
      "Epoch [1/50], Step [1200/5013], Loss: 0.9276\n",
      "Epoch [1/50], Step [1300/5013], Loss: 0.9153\n",
      "Epoch [1/50], Step [1400/5013], Loss: 0.8857\n",
      "Epoch [1/50], Step [1500/5013], Loss: 0.8734\n",
      "Epoch [1/50], Step [1600/5013], Loss: 0.8405\n",
      "Epoch [1/50], Step [1700/5013], Loss: 0.8443\n",
      "Epoch [1/50], Step [1800/5013], Loss: 0.7993\n",
      "Epoch [1/50], Step [1900/5013], Loss: 0.8002\n",
      "Epoch [1/50], Step [2000/5013], Loss: 0.8066\n",
      "Epoch [1/50], Step [2100/5013], Loss: 0.7861\n",
      "Epoch [1/50], Step [2200/5013], Loss: 0.7796\n",
      "Epoch [1/50], Step [2300/5013], Loss: 0.7948\n",
      "Epoch [1/50], Step [2400/5013], Loss: 0.7450\n",
      "Epoch [1/50], Step [2500/5013], Loss: 0.7818\n",
      "Epoch [1/50], Step [2600/5013], Loss: 0.7412\n",
      "Epoch [1/50], Step [2700/5013], Loss: 0.7248\n",
      "Epoch [1/50], Step [2800/5013], Loss: 0.7617\n",
      "Epoch [1/50], Step [2900/5013], Loss: 0.7394\n",
      "Epoch [1/50], Step [3000/5013], Loss: 0.7232\n",
      "Epoch [1/50], Step [3100/5013], Loss: 0.7160\n",
      "Epoch [1/50], Step [3200/5013], Loss: 0.7141\n",
      "Epoch [1/50], Step [3300/5013], Loss: 0.6993\n",
      "Epoch [1/50], Step [3400/5013], Loss: 0.6857\n",
      "Epoch [1/50], Step [3500/5013], Loss: 0.6953\n",
      "Epoch [1/50], Step [3600/5013], Loss: 0.6912\n",
      "Epoch [1/50], Step [3700/5013], Loss: 0.6902\n",
      "Epoch [1/50], Step [3800/5013], Loss: 0.6681\n",
      "Epoch [1/50], Step [3900/5013], Loss: 0.7064\n",
      "Epoch [1/50], Step [4000/5013], Loss: 0.6584\n",
      "Epoch [1/50], Step [4100/5013], Loss: 0.6426\n",
      "Epoch [1/50], Step [4200/5013], Loss: 0.6513\n",
      "Epoch [1/50], Step [4300/5013], Loss: 0.6590\n",
      "Epoch [1/50], Step [4400/5013], Loss: 0.6736\n",
      "Epoch [1/50], Step [4500/5013], Loss: 0.6451\n",
      "Epoch [1/50], Step [4600/5013], Loss: 0.6261\n",
      "Epoch [1/50], Step [4700/5013], Loss: 0.6795\n",
      "Epoch [1/50], Step [4800/5013], Loss: 0.6485\n",
      "Epoch [1/50], Step [4900/5013], Loss: 0.6419\n",
      "Epoch [1/50], Step [5000/5013], Loss: 0.6367\n",
      "Epoch [1/50] Average Loss: 0.8154\n",
      "Epoch [2/50], Step [100/5013], Loss: 0.6295\n",
      "Epoch [2/50], Step [200/5013], Loss: 0.6216\n",
      "Epoch [2/50], Step [300/5013], Loss: 0.6179\n",
      "Epoch [2/50], Step [400/5013], Loss: 0.6518\n",
      "Epoch [2/50], Step [500/5013], Loss: 0.5873\n",
      "Epoch [2/50], Step [600/5013], Loss: 0.6169\n",
      "Epoch [2/50], Step [700/5013], Loss: 0.5960\n",
      "Epoch [2/50], Step [800/5013], Loss: 0.6007\n",
      "Epoch [2/50], Step [900/5013], Loss: 0.6022\n",
      "Epoch [2/50], Step [1000/5013], Loss: 0.6353\n",
      "Epoch [2/50], Step [1100/5013], Loss: 0.6226\n",
      "Epoch [2/50], Step [1200/5013], Loss: 0.6037\n",
      "Epoch [2/50], Step [1300/5013], Loss: 0.6197\n",
      "Epoch [2/50], Step [1400/5013], Loss: 0.5923\n",
      "Epoch [2/50], Step [1500/5013], Loss: 0.6114\n",
      "Epoch [2/50], Step [1600/5013], Loss: 0.6281\n",
      "Epoch [2/50], Step [1700/5013], Loss: 0.6009\n",
      "Epoch [2/50], Step [1800/5013], Loss: 0.5727\n",
      "Epoch [2/50], Step [1900/5013], Loss: 0.6042\n",
      "Epoch [2/50], Step [2000/5013], Loss: 0.6024\n",
      "Epoch [2/50], Step [2100/5013], Loss: 0.6044\n",
      "Epoch [2/50], Step [2200/5013], Loss: 0.5964\n",
      "Epoch [2/50], Step [2300/5013], Loss: 0.5719\n",
      "Epoch [2/50], Step [2400/5013], Loss: 0.6000\n",
      "Epoch [2/50], Step [2500/5013], Loss: 0.6120\n",
      "Epoch [2/50], Step [2600/5013], Loss: 0.5824\n",
      "Epoch [2/50], Step [2700/5013], Loss: 0.5774\n",
      "Epoch [2/50], Step [2800/5013], Loss: 0.5620\n",
      "Epoch [2/50], Step [2900/5013], Loss: 0.5563\n",
      "Epoch [2/50], Step [3000/5013], Loss: 0.5667\n",
      "Epoch [2/50], Step [3100/5013], Loss: 0.5982\n",
      "Epoch [2/50], Step [3200/5013], Loss: 0.5933\n",
      "Epoch [2/50], Step [3300/5013], Loss: 0.5949\n",
      "Epoch [2/50], Step [3400/5013], Loss: 0.5598\n",
      "Epoch [2/50], Step [3500/5013], Loss: 0.5724\n",
      "Epoch [2/50], Step [3600/5013], Loss: 0.5570\n",
      "Epoch [2/50], Step [3700/5013], Loss: 0.5969\n",
      "Epoch [2/50], Step [3800/5013], Loss: 0.5694\n",
      "Epoch [2/50], Step [3900/5013], Loss: 0.5406\n",
      "Epoch [2/50], Step [4000/5013], Loss: 0.5693\n",
      "Epoch [2/50], Step [4100/5013], Loss: 0.5589\n",
      "Epoch [2/50], Step [4200/5013], Loss: 0.5686\n",
      "Epoch [2/50], Step [4300/5013], Loss: 0.5644\n",
      "Epoch [2/50], Step [4400/5013], Loss: 0.5519\n",
      "Epoch [2/50], Step [4500/5013], Loss: 0.5804\n",
      "Epoch [2/50], Step [4600/5013], Loss: 0.5743\n",
      "Epoch [2/50], Step [4700/5013], Loss: 0.5521\n",
      "Epoch [2/50], Step [4800/5013], Loss: 0.5483\n",
      "Epoch [2/50], Step [4900/5013], Loss: 0.5485\n",
      "Epoch [2/50], Step [5000/5013], Loss: 0.5407\n",
      "Epoch [2/50] Average Loss: 0.5875\n",
      "Epoch [3/50], Step [100/5013], Loss: 0.5358\n",
      "Epoch [3/50], Step [200/5013], Loss: 0.5451\n",
      "Epoch [3/50], Step [300/5013], Loss: 0.5545\n",
      "Epoch [3/50], Step [400/5013], Loss: 0.5301\n",
      "Epoch [3/50], Step [500/5013], Loss: 0.5303\n",
      "Epoch [3/50], Step [600/5013], Loss: 0.5670\n",
      "Epoch [3/50], Step [700/5013], Loss: 0.5374\n",
      "Epoch [3/50], Step [800/5013], Loss: 0.5411\n",
      "Epoch [3/50], Step [900/5013], Loss: 0.5445\n",
      "Epoch [3/50], Step [1000/5013], Loss: 0.5250\n",
      "Epoch [3/50], Step [1100/5013], Loss: 0.5353\n",
      "Epoch [3/50], Step [1200/5013], Loss: 0.5362\n",
      "Epoch [3/50], Step [1300/5013], Loss: 0.5293\n",
      "Epoch [3/50], Step [1400/5013], Loss: 0.5541\n",
      "Epoch [3/50], Step [1500/5013], Loss: 0.5358\n",
      "Epoch [3/50], Step [1600/5013], Loss: 0.5234\n",
      "Epoch [3/50], Step [1700/5013], Loss: 0.5355\n",
      "Epoch [3/50], Step [1800/5013], Loss: 0.5147\n",
      "Epoch [3/50], Step [1900/5013], Loss: 0.5236\n",
      "Epoch [3/50], Step [2000/5013], Loss: 0.5290\n",
      "Epoch [3/50], Step [2100/5013], Loss: 0.5275\n",
      "Epoch [3/50], Step [2200/5013], Loss: 0.5365\n",
      "Epoch [3/50], Step [2300/5013], Loss: 0.5322\n",
      "Epoch [3/50], Step [2400/5013], Loss: 0.5073\n",
      "Epoch [3/50], Step [2500/5013], Loss: 0.5198\n",
      "Epoch [3/50], Step [2600/5013], Loss: 0.5272\n",
      "Epoch [3/50], Step [2700/5013], Loss: 0.5452\n",
      "Epoch [3/50], Step [2800/5013], Loss: 0.5258\n",
      "Epoch [3/50], Step [2900/5013], Loss: 0.5064\n",
      "Epoch [3/50], Step [3000/5013], Loss: 0.5509\n",
      "Epoch [3/50], Step [3100/5013], Loss: 0.5057\n",
      "Epoch [3/50], Step [3200/5013], Loss: 0.5078\n",
      "Epoch [3/50], Step [3300/5013], Loss: 0.5183\n",
      "Epoch [3/50], Step [3400/5013], Loss: 0.5223\n",
      "Epoch [3/50], Step [3500/5013], Loss: 0.5187\n",
      "Epoch [3/50], Step [3600/5013], Loss: 0.5002\n",
      "Epoch [3/50], Step [3700/5013], Loss: 0.5255\n",
      "Epoch [3/50], Step [3800/5013], Loss: 0.4952\n",
      "Epoch [3/50], Step [3900/5013], Loss: 0.5115\n",
      "Epoch [3/50], Step [4000/5013], Loss: 0.5017\n",
      "Epoch [3/50], Step [4100/5013], Loss: 0.5063\n",
      "Epoch [3/50], Step [4200/5013], Loss: 0.5179\n",
      "Epoch [3/50], Step [4300/5013], Loss: 0.5181\n",
      "Epoch [3/50], Step [4400/5013], Loss: 0.5046\n",
      "Epoch [3/50], Step [4500/5013], Loss: 0.4928\n",
      "Epoch [3/50], Step [4600/5013], Loss: 0.5189\n",
      "Epoch [3/50], Step [4700/5013], Loss: 0.5098\n",
      "Epoch [3/50], Step [4800/5013], Loss: 0.5068\n",
      "Epoch [3/50], Step [4900/5013], Loss: 0.4970\n",
      "Epoch [3/50], Step [5000/5013], Loss: 0.5262\n",
      "Epoch [3/50] Average Loss: 0.5242\n",
      "Epoch [4/50], Step [100/5013], Loss: 0.5054\n",
      "Epoch [4/50], Step [200/5013], Loss: 0.5095\n",
      "Epoch [4/50], Step [300/5013], Loss: 0.5195\n",
      "Epoch [4/50], Step [400/5013], Loss: 0.5146\n",
      "Epoch [4/50], Step [500/5013], Loss: 0.4978\n",
      "Epoch [4/50], Step [600/5013], Loss: 0.4796\n",
      "Epoch [4/50], Step [700/5013], Loss: 0.5079\n",
      "Epoch [4/50], Step [800/5013], Loss: 0.4796\n",
      "Epoch [4/50], Step [900/5013], Loss: 0.4856\n",
      "Epoch [4/50], Step [1000/5013], Loss: 0.5071\n",
      "Epoch [4/50], Step [1100/5013], Loss: 0.5155\n",
      "Epoch [4/50], Step [1200/5013], Loss: 0.5082\n",
      "Epoch [4/50], Step [1300/5013], Loss: 0.4810\n",
      "Epoch [4/50], Step [1400/5013], Loss: 0.5166\n",
      "Epoch [4/50], Step [1500/5013], Loss: 0.4846\n",
      "Epoch [4/50], Step [1600/5013], Loss: 0.4892\n",
      "Epoch [4/50], Step [1700/5013], Loss: 0.4985\n",
      "Epoch [4/50], Step [1800/5013], Loss: 0.4762\n",
      "Epoch [4/50], Step [1900/5013], Loss: 0.4973\n",
      "Epoch [4/50], Step [2000/5013], Loss: 0.4657\n",
      "Epoch [4/50], Step [2100/5013], Loss: 0.4913\n",
      "Epoch [4/50], Step [2200/5013], Loss: 0.4654\n",
      "Epoch [4/50], Step [2300/5013], Loss: 0.4661\n",
      "Epoch [4/50], Step [2400/5013], Loss: 0.5123\n",
      "Epoch [4/50], Step [2500/5013], Loss: 0.4815\n",
      "Epoch [4/50], Step [2600/5013], Loss: 0.4817\n",
      "Epoch [4/50], Step [2700/5013], Loss: 0.4940\n",
      "Epoch [4/50], Step [2800/5013], Loss: 0.4849\n",
      "Epoch [4/50], Step [2900/5013], Loss: 0.4797\n",
      "Epoch [4/50], Step [3000/5013], Loss: 0.5033\n",
      "Epoch [4/50], Step [3100/5013], Loss: 0.5339\n",
      "Epoch [4/50], Step [3200/5013], Loss: 0.5102\n",
      "Epoch [4/50], Step [3300/5013], Loss: 0.4958\n",
      "Epoch [4/50], Step [3400/5013], Loss: 0.4743\n",
      "Epoch [4/50], Step [3500/5013], Loss: 0.4795\n",
      "Epoch [4/50], Step [3600/5013], Loss: 0.4640\n",
      "Epoch [4/50], Step [3700/5013], Loss: 0.4714\n",
      "Epoch [4/50], Step [3800/5013], Loss: 0.4986\n",
      "Epoch [4/50], Step [3900/5013], Loss: 0.4918\n",
      "Epoch [4/50], Step [4000/5013], Loss: 0.5067\n",
      "Epoch [4/50], Step [4100/5013], Loss: 0.4957\n",
      "Epoch [4/50], Step [4200/5013], Loss: 0.4977\n",
      "Epoch [4/50], Step [4300/5013], Loss: 0.4855\n",
      "Epoch [4/50], Step [4400/5013], Loss: 0.4767\n",
      "Epoch [4/50], Step [4500/5013], Loss: 0.4746\n",
      "Epoch [4/50], Step [4600/5013], Loss: 0.5148\n",
      "Epoch [4/50], Step [4700/5013], Loss: 0.4853\n",
      "Epoch [4/50], Step [4800/5013], Loss: 0.4796\n",
      "Epoch [4/50], Step [4900/5013], Loss: 0.4954\n",
      "Epoch [4/50], Step [5000/5013], Loss: 0.4878\n",
      "Epoch [4/50] Average Loss: 0.4926\n",
      "Epoch [5/50], Step [100/5013], Loss: 0.4666\n",
      "Epoch [5/50], Step [200/5013], Loss: 0.4542\n",
      "Epoch [5/50], Step [300/5013], Loss: 0.4656\n",
      "Epoch [5/50], Step [400/5013], Loss: 0.4797\n",
      "Epoch [5/50], Step [500/5013], Loss: 0.4796\n",
      "Epoch [5/50], Step [600/5013], Loss: 0.4646\n",
      "Epoch [5/50], Step [700/5013], Loss: 0.4562\n",
      "Epoch [5/50], Step [800/5013], Loss: 0.4618\n",
      "Epoch [5/50], Step [900/5013], Loss: 0.4917\n",
      "Epoch [5/50], Step [1000/5013], Loss: 0.4880\n",
      "Epoch [5/50], Step [1100/5013], Loss: 0.4762\n",
      "Epoch [5/50], Step [1200/5013], Loss: 0.4667\n",
      "Epoch [5/50], Step [1300/5013], Loss: 0.4659\n",
      "Epoch [5/50], Step [1400/5013], Loss: 0.4765\n",
      "Epoch [5/50], Step [1500/5013], Loss: 0.4612\n",
      "Epoch [5/50], Step [1600/5013], Loss: 0.4496\n",
      "Epoch [5/50], Step [1700/5013], Loss: 0.4786\n",
      "Epoch [5/50], Step [1800/5013], Loss: 0.4625\n",
      "Epoch [5/50], Step [1900/5013], Loss: 0.4875\n",
      "Epoch [5/50], Step [2000/5013], Loss: 0.4673\n",
      "Epoch [5/50], Step [2100/5013], Loss: 0.4811\n",
      "Epoch [5/50], Step [2200/5013], Loss: 0.4663\n",
      "Epoch [5/50], Step [2300/5013], Loss: 0.4785\n",
      "Epoch [5/50], Step [2400/5013], Loss: 0.4756\n",
      "Epoch [5/50], Step [2500/5013], Loss: 0.4652\n",
      "Epoch [5/50], Step [2600/5013], Loss: 0.4859\n",
      "Epoch [5/50], Step [2700/5013], Loss: 0.5020\n",
      "Epoch [5/50], Step [2800/5013], Loss: 0.4702\n",
      "Epoch [5/50], Step [2900/5013], Loss: 0.4554\n",
      "Epoch [5/50], Step [3000/5013], Loss: 0.4844\n",
      "Epoch [5/50], Step [3100/5013], Loss: 0.4596\n",
      "Epoch [5/50], Step [3200/5013], Loss: 0.4567\n",
      "Epoch [5/50], Step [3300/5013], Loss: 0.4714\n",
      "Epoch [5/50], Step [3400/5013], Loss: 0.4774\n",
      "Epoch [5/50], Step [3500/5013], Loss: 0.4375\n",
      "Epoch [5/50], Step [3600/5013], Loss: 0.4509\n",
      "Epoch [5/50], Step [3700/5013], Loss: 0.4608\n",
      "Epoch [5/50], Step [3800/5013], Loss: 0.4698\n",
      "Epoch [5/50], Step [3900/5013], Loss: 0.4902\n",
      "Epoch [5/50], Step [4000/5013], Loss: 0.4676\n",
      "Epoch [5/50], Step [4100/5013], Loss: 0.4625\n",
      "Epoch [5/50], Step [4200/5013], Loss: 0.4703\n",
      "Epoch [5/50], Step [4300/5013], Loss: 0.4500\n",
      "Epoch [5/50], Step [4400/5013], Loss: 0.4594\n",
      "Epoch [5/50], Step [4500/5013], Loss: 0.4578\n",
      "Epoch [5/50], Step [4600/5013], Loss: 0.4383\n",
      "Epoch [5/50], Step [4700/5013], Loss: 0.4472\n",
      "Epoch [5/50], Step [4800/5013], Loss: 0.4897\n",
      "Epoch [5/50], Step [4900/5013], Loss: 0.4618\n",
      "Epoch [5/50], Step [5000/5013], Loss: 0.4537\n",
      "Epoch [5/50] Average Loss: 0.4680\n",
      "Epoch [6/50], Step [100/5013], Loss: 0.4628\n",
      "Epoch [6/50], Step [200/5013], Loss: 0.4636\n",
      "Epoch [6/50], Step [300/5013], Loss: 0.4412\n",
      "Epoch [6/50], Step [400/5013], Loss: 0.4300\n",
      "Epoch [6/50], Step [500/5013], Loss: 0.4577\n",
      "Epoch [6/50], Step [600/5013], Loss: 0.4526\n",
      "Epoch [6/50], Step [700/5013], Loss: 0.4592\n",
      "Epoch [6/50], Step [800/5013], Loss: 0.4658\n",
      "Epoch [6/50], Step [900/5013], Loss: 0.4768\n",
      "Epoch [6/50], Step [1000/5013], Loss: 0.4428\n",
      "Epoch [6/50], Step [1100/5013], Loss: 0.4449\n",
      "Epoch [6/50], Step [1200/5013], Loss: 0.4280\n",
      "Epoch [6/50], Step [1300/5013], Loss: 0.4387\n",
      "Epoch [6/50], Step [1400/5013], Loss: 0.4390\n",
      "Epoch [6/50], Step [1500/5013], Loss: 0.4379\n",
      "Epoch [6/50], Step [1600/5013], Loss: 0.4683\n",
      "Epoch [6/50], Step [1700/5013], Loss: 0.4525\n",
      "Epoch [6/50], Step [1800/5013], Loss: 0.4530\n",
      "Epoch [6/50], Step [1900/5013], Loss: 0.4475\n",
      "Epoch [6/50], Step [2000/5013], Loss: 0.4749\n",
      "Epoch [6/50], Step [2100/5013], Loss: 0.4340\n",
      "Epoch [6/50], Step [2200/5013], Loss: 0.4622\n",
      "Epoch [6/50], Step [2300/5013], Loss: 0.4454\n",
      "Epoch [6/50], Step [2400/5013], Loss: 0.4825\n",
      "Epoch [6/50], Step [2500/5013], Loss: 0.4593\n",
      "Epoch [6/50], Step [2600/5013], Loss: 0.4521\n",
      "Epoch [6/50], Step [2700/5013], Loss: 0.4333\n",
      "Epoch [6/50], Step [2800/5013], Loss: 0.4716\n",
      "Epoch [6/50], Step [2900/5013], Loss: 0.4713\n",
      "Epoch [6/50], Step [3000/5013], Loss: 0.4147\n",
      "Epoch [6/50], Step [3100/5013], Loss: 0.4542\n",
      "Epoch [6/50], Step [3200/5013], Loss: 0.4448\n",
      "Epoch [6/50], Step [3300/5013], Loss: 0.4650\n",
      "Epoch [6/50], Step [3400/5013], Loss: 0.4900\n",
      "Epoch [6/50], Step [3500/5013], Loss: 0.4482\n",
      "Epoch [6/50], Step [3600/5013], Loss: 0.4500\n",
      "Epoch [6/50], Step [3700/5013], Loss: 0.4514\n",
      "Epoch [6/50], Step [3800/5013], Loss: 0.4516\n",
      "Epoch [6/50], Step [3900/5013], Loss: 0.4519\n",
      "Epoch [6/50], Step [4000/5013], Loss: 0.4391\n",
      "Epoch [6/50], Step [4100/5013], Loss: 0.4402\n",
      "Epoch [6/50], Step [4200/5013], Loss: 0.4577\n",
      "Epoch [6/50], Step [4300/5013], Loss: 0.4396\n",
      "Epoch [6/50], Step [4400/5013], Loss: 0.4307\n",
      "Epoch [6/50], Step [4500/5013], Loss: 0.4568\n",
      "Epoch [6/50], Step [4600/5013], Loss: 0.4403\n",
      "Epoch [6/50], Step [4700/5013], Loss: 0.4385\n",
      "Epoch [6/50], Step [4800/5013], Loss: 0.4346\n",
      "Epoch [6/50], Step [4900/5013], Loss: 0.4431\n",
      "Epoch [6/50], Step [5000/5013], Loss: 0.4461\n",
      "Epoch [6/50] Average Loss: 0.4506\n",
      "Epoch [7/50], Step [100/5013], Loss: 0.4409\n",
      "Epoch [7/50], Step [200/5013], Loss: 0.4311\n",
      "Epoch [7/50], Step [300/5013], Loss: 0.4442\n",
      "Epoch [7/50], Step [400/5013], Loss: 0.4272\n",
      "Epoch [7/50], Step [500/5013], Loss: 0.4275\n",
      "Epoch [7/50], Step [600/5013], Loss: 0.4393\n",
      "Epoch [7/50], Step [700/5013], Loss: 0.4292\n",
      "Epoch [7/50], Step [800/5013], Loss: 0.4244\n",
      "Epoch [7/50], Step [900/5013], Loss: 0.4321\n",
      "Epoch [7/50], Step [1000/5013], Loss: 0.4310\n",
      "Epoch [7/50], Step [1100/5013], Loss: 0.4440\n",
      "Epoch [7/50], Step [1200/5013], Loss: 0.4485\n",
      "Epoch [7/50], Step [1300/5013], Loss: 0.4329\n",
      "Epoch [7/50], Step [1400/5013], Loss: 0.4114\n",
      "Epoch [7/50], Step [1500/5013], Loss: 0.4137\n",
      "Epoch [7/50], Step [1600/5013], Loss: 0.4206\n",
      "Epoch [7/50], Step [1700/5013], Loss: 0.4411\n",
      "Epoch [7/50], Step [1800/5013], Loss: 0.4442\n",
      "Epoch [7/50], Step [1900/5013], Loss: 0.4411\n",
      "Epoch [7/50], Step [2000/5013], Loss: 0.4408\n",
      "Epoch [7/50], Step [2100/5013], Loss: 0.4423\n",
      "Epoch [7/50], Step [2200/5013], Loss: 0.4439\n",
      "Epoch [7/50], Step [2300/5013], Loss: 0.4461\n",
      "Epoch [7/50], Step [2400/5013], Loss: 0.4260\n",
      "Epoch [7/50], Step [2500/5013], Loss: 0.4098\n",
      "Epoch [7/50], Step [2600/5013], Loss: 0.4184\n",
      "Epoch [7/50], Step [2700/5013], Loss: 0.4676\n",
      "Epoch [7/50], Step [2800/5013], Loss: 0.4065\n",
      "Epoch [7/50], Step [2900/5013], Loss: 0.4377\n",
      "Epoch [7/50], Step [3000/5013], Loss: 0.4492\n",
      "Epoch [7/50], Step [3100/5013], Loss: 0.4255\n",
      "Epoch [7/50], Step [3200/5013], Loss: 0.4516\n",
      "Epoch [7/50], Step [3300/5013], Loss: 0.4429\n",
      "Epoch [7/50], Step [3400/5013], Loss: 0.4210\n",
      "Epoch [7/50], Step [3500/5013], Loss: 0.4464\n",
      "Epoch [7/50], Step [3600/5013], Loss: 0.4454\n",
      "Epoch [7/50], Step [3700/5013], Loss: 0.4427\n",
      "Epoch [7/50], Step [3800/5013], Loss: 0.4228\n",
      "Epoch [7/50], Step [3900/5013], Loss: 0.4143\n",
      "Epoch [7/50], Step [4000/5013], Loss: 0.4440\n",
      "Epoch [7/50], Step [4100/5013], Loss: 0.4375\n",
      "Epoch [7/50], Step [4200/5013], Loss: 0.4403\n",
      "Epoch [7/50], Step [4300/5013], Loss: 0.4207\n",
      "Epoch [7/50], Step [4400/5013], Loss: 0.4337\n",
      "Epoch [7/50], Step [4500/5013], Loss: 0.4148\n",
      "Epoch [7/50], Step [4600/5013], Loss: 0.3942\n",
      "Epoch [7/50], Step [4700/5013], Loss: 0.4160\n",
      "Epoch [7/50], Step [4800/5013], Loss: 0.4338\n",
      "Epoch [7/50], Step [4900/5013], Loss: 0.4503\n",
      "Epoch [7/50], Step [5000/5013], Loss: 0.4462\n",
      "Epoch [7/50] Average Loss: 0.4333\n",
      "Epoch [8/50], Step [100/5013], Loss: 0.4383\n",
      "Epoch [8/50], Step [200/5013], Loss: 0.3938\n",
      "Epoch [8/50], Step [300/5013], Loss: 0.4231\n",
      "Epoch [8/50], Step [400/5013], Loss: 0.4277\n",
      "Epoch [8/50], Step [500/5013], Loss: 0.4097\n",
      "Epoch [8/50], Step [600/5013], Loss: 0.4261\n",
      "Epoch [8/50], Step [700/5013], Loss: 0.4105\n",
      "Epoch [8/50], Step [800/5013], Loss: 0.4315\n",
      "Epoch [8/50], Step [900/5013], Loss: 0.4424\n",
      "Epoch [8/50], Step [1000/5013], Loss: 0.4448\n",
      "Epoch [8/50], Step [1100/5013], Loss: 0.4235\n",
      "Epoch [8/50], Step [1200/5013], Loss: 0.4124\n",
      "Epoch [8/50], Step [1300/5013], Loss: 0.4357\n",
      "Epoch [8/50], Step [1400/5013], Loss: 0.3974\n",
      "Epoch [8/50], Step [1500/5013], Loss: 0.4117\n",
      "Epoch [8/50], Step [1600/5013], Loss: 0.3897\n",
      "Epoch [8/50], Step [1700/5013], Loss: 0.4112\n",
      "Epoch [8/50], Step [1800/5013], Loss: 0.4421\n",
      "Epoch [8/50], Step [1900/5013], Loss: 0.4466\n",
      "Epoch [8/50], Step [2000/5013], Loss: 0.4210\n",
      "Epoch [8/50], Step [2100/5013], Loss: 0.4046\n",
      "Epoch [8/50], Step [2200/5013], Loss: 0.4107\n",
      "Epoch [8/50], Step [2300/5013], Loss: 0.4060\n",
      "Epoch [8/50], Step [2400/5013], Loss: 0.4419\n",
      "Epoch [8/50], Step [2500/5013], Loss: 0.4175\n",
      "Epoch [8/50], Step [2600/5013], Loss: 0.4016\n",
      "Epoch [8/50], Step [2700/5013], Loss: 0.4139\n",
      "Epoch [8/50], Step [2800/5013], Loss: 0.4226\n",
      "Epoch [8/50], Step [2900/5013], Loss: 0.4102\n",
      "Epoch [8/50], Step [3000/5013], Loss: 0.4453\n",
      "Epoch [8/50], Step [3100/5013], Loss: 0.3994\n",
      "Epoch [8/50], Step [3200/5013], Loss: 0.4434\n",
      "Epoch [8/50], Step [3300/5013], Loss: 0.4154\n",
      "Epoch [8/50], Step [3400/5013], Loss: 0.4280\n",
      "Epoch [8/50], Step [3500/5013], Loss: 0.4582\n",
      "Epoch [8/50], Step [3600/5013], Loss: 0.4135\n",
      "Epoch [8/50], Step [3700/5013], Loss: 0.4218\n",
      "Epoch [8/50], Step [3800/5013], Loss: 0.4410\n",
      "Epoch [8/50], Step [3900/5013], Loss: 0.4380\n",
      "Epoch [8/50], Step [4000/5013], Loss: 0.4011\n",
      "Epoch [8/50], Step [4100/5013], Loss: 0.4064\n",
      "Epoch [8/50], Step [4200/5013], Loss: 0.4410\n",
      "Epoch [8/50], Step [4300/5013], Loss: 0.4055\n",
      "Epoch [8/50], Step [4400/5013], Loss: 0.4210\n",
      "Epoch [8/50], Step [4500/5013], Loss: 0.4241\n",
      "Epoch [8/50], Step [4600/5013], Loss: 0.4142\n",
      "Epoch [8/50], Step [4700/5013], Loss: 0.4218\n",
      "Epoch [8/50], Step [4800/5013], Loss: 0.4066\n",
      "Epoch [8/50], Step [4900/5013], Loss: 0.4182\n",
      "Epoch [8/50], Step [5000/5013], Loss: 0.4417\n",
      "Epoch [8/50] Average Loss: 0.4215\n",
      "Epoch [9/50], Step [100/5013], Loss: 0.4059\n",
      "Epoch [9/50], Step [200/5013], Loss: 0.4206\n",
      "Epoch [9/50], Step [300/5013], Loss: 0.4054\n",
      "Epoch [9/50], Step [400/5013], Loss: 0.4171\n",
      "Epoch [9/50], Step [500/5013], Loss: 0.4317\n",
      "Epoch [9/50], Step [600/5013], Loss: 0.3844\n",
      "Epoch [9/50], Step [700/5013], Loss: 0.4067\n",
      "Epoch [9/50], Step [800/5013], Loss: 0.4175\n",
      "Epoch [9/50], Step [900/5013], Loss: 0.4098\n",
      "Epoch [9/50], Step [1000/5013], Loss: 0.4088\n",
      "Epoch [9/50], Step [1100/5013], Loss: 0.4408\n",
      "Epoch [9/50], Step [1200/5013], Loss: 0.4081\n",
      "Epoch [9/50], Step [1300/5013], Loss: 0.4165\n",
      "Epoch [9/50], Step [1400/5013], Loss: 0.3925\n",
      "Epoch [9/50], Step [1500/5013], Loss: 0.4170\n",
      "Epoch [9/50], Step [1600/5013], Loss: 0.3801\n",
      "Epoch [9/50], Step [1700/5013], Loss: 0.4180\n",
      "Epoch [9/50], Step [1800/5013], Loss: 0.3885\n",
      "Epoch [9/50], Step [1900/5013], Loss: 0.4147\n",
      "Epoch [9/50], Step [2000/5013], Loss: 0.3905\n",
      "Epoch [9/50], Step [2100/5013], Loss: 0.4343\n",
      "Epoch [9/50], Step [2200/5013], Loss: 0.3924\n",
      "Epoch [9/50], Step [2300/5013], Loss: 0.4102\n",
      "Epoch [9/50], Step [2400/5013], Loss: 0.4245\n",
      "Epoch [9/50], Step [2500/5013], Loss: 0.4114\n",
      "Epoch [9/50], Step [2600/5013], Loss: 0.4007\n",
      "Epoch [9/50], Step [2700/5013], Loss: 0.4250\n",
      "Epoch [9/50], Step [2800/5013], Loss: 0.4319\n",
      "Epoch [9/50], Step [2900/5013], Loss: 0.4260\n",
      "Epoch [9/50], Step [3000/5013], Loss: 0.4086\n",
      "Epoch [9/50], Step [3100/5013], Loss: 0.4260\n",
      "Epoch [9/50], Step [3200/5013], Loss: 0.4069\n",
      "Epoch [9/50], Step [3300/5013], Loss: 0.4169\n",
      "Epoch [9/50], Step [3400/5013], Loss: 0.3993\n",
      "Epoch [9/50], Step [3500/5013], Loss: 0.4471\n",
      "Epoch [9/50], Step [3600/5013], Loss: 0.4088\n",
      "Epoch [9/50], Step [3700/5013], Loss: 0.4206\n",
      "Epoch [9/50], Step [3800/5013], Loss: 0.4072\n",
      "Epoch [9/50], Step [3900/5013], Loss: 0.3939\n",
      "Epoch [9/50], Step [4000/5013], Loss: 0.3845\n",
      "Epoch [9/50], Step [4100/5013], Loss: 0.3981\n",
      "Epoch [9/50], Step [4200/5013], Loss: 0.4171\n",
      "Epoch [9/50], Step [4300/5013], Loss: 0.3813\n",
      "Epoch [9/50], Step [4400/5013], Loss: 0.3939\n",
      "Epoch [9/50], Step [4500/5013], Loss: 0.4071\n",
      "Epoch [9/50], Step [4600/5013], Loss: 0.4350\n",
      "Epoch [9/50], Step [4700/5013], Loss: 0.3940\n",
      "Epoch [9/50], Step [4800/5013], Loss: 0.4088\n",
      "Epoch [9/50], Step [4900/5013], Loss: 0.4253\n",
      "Epoch [9/50], Step [5000/5013], Loss: 0.4121\n",
      "Epoch [9/50] Average Loss: 0.4104\n",
      "Epoch [10/50], Step [100/5013], Loss: 0.3906\n",
      "Epoch [10/50], Step [200/5013], Loss: 0.4247\n",
      "Epoch [10/50], Step [300/5013], Loss: 0.4077\n",
      "Epoch [10/50], Step [400/5013], Loss: 0.3924\n",
      "Epoch [10/50], Step [500/5013], Loss: 0.4070\n",
      "Epoch [10/50], Step [600/5013], Loss: 0.3885\n",
      "Epoch [10/50], Step [700/5013], Loss: 0.3979\n",
      "Epoch [10/50], Step [800/5013], Loss: 0.3904\n",
      "Epoch [10/50], Step [900/5013], Loss: 0.4147\n",
      "Epoch [10/50], Step [1000/5013], Loss: 0.4100\n",
      "Epoch [10/50], Step [1100/5013], Loss: 0.3743\n",
      "Epoch [10/50], Step [1200/5013], Loss: 0.3937\n",
      "Epoch [10/50], Step [1300/5013], Loss: 0.3998\n",
      "Epoch [10/50], Step [1400/5013], Loss: 0.4070\n",
      "Epoch [10/50], Step [1500/5013], Loss: 0.4023\n",
      "Epoch [10/50], Step [1600/5013], Loss: 0.3840\n",
      "Epoch [10/50], Step [1700/5013], Loss: 0.3882\n",
      "Epoch [10/50], Step [1800/5013], Loss: 0.4160\n",
      "Epoch [10/50], Step [1900/5013], Loss: 0.3901\n",
      "Epoch [10/50], Step [2000/5013], Loss: 0.3915\n",
      "Epoch [10/50], Step [2100/5013], Loss: 0.4151\n",
      "Epoch [10/50], Step [2200/5013], Loss: 0.4102\n",
      "Epoch [10/50], Step [2300/5013], Loss: 0.4034\n",
      "Epoch [10/50], Step [2400/5013], Loss: 0.3944\n",
      "Epoch [10/50], Step [2500/5013], Loss: 0.4222\n",
      "Epoch [10/50], Step [2600/5013], Loss: 0.3961\n",
      "Epoch [10/50], Step [2700/5013], Loss: 0.3781\n",
      "Epoch [10/50], Step [2800/5013], Loss: 0.3798\n",
      "Epoch [10/50], Step [2900/5013], Loss: 0.3915\n",
      "Epoch [10/50], Step [3000/5013], Loss: 0.4076\n",
      "Epoch [10/50], Step [3100/5013], Loss: 0.4091\n",
      "Epoch [10/50], Step [3200/5013], Loss: 0.4056\n",
      "Epoch [10/50], Step [3300/5013], Loss: 0.3780\n",
      "Epoch [10/50], Step [3400/5013], Loss: 0.4106\n",
      "Epoch [10/50], Step [3500/5013], Loss: 0.3927\n",
      "Epoch [10/50], Step [3600/5013], Loss: 0.3984\n",
      "Epoch [10/50], Step [3700/5013], Loss: 0.4034\n",
      "Epoch [10/50], Step [3800/5013], Loss: 0.3994\n",
      "Epoch [10/50], Step [3900/5013], Loss: 0.3932\n",
      "Epoch [10/50], Step [4000/5013], Loss: 0.4279\n",
      "Epoch [10/50], Step [4100/5013], Loss: 0.3785\n",
      "Epoch [10/50], Step [4200/5013], Loss: 0.4100\n",
      "Epoch [10/50], Step [4300/5013], Loss: 0.3950\n",
      "Epoch [10/50], Step [4400/5013], Loss: 0.4119\n",
      "Epoch [10/50], Step [4500/5013], Loss: 0.3948\n",
      "Epoch [10/50], Step [4600/5013], Loss: 0.3856\n",
      "Epoch [10/50], Step [4700/5013], Loss: 0.3833\n",
      "Epoch [10/50], Step [4800/5013], Loss: 0.3997\n",
      "Epoch [10/50], Step [4900/5013], Loss: 0.3796\n",
      "Epoch [10/50], Step [5000/5013], Loss: 0.4170\n",
      "Epoch [10/50] Average Loss: 0.3988\n",
      "Epoch [11/50], Step [100/5013], Loss: 0.4034\n",
      "Epoch [11/50], Step [200/5013], Loss: 0.4023\n",
      "Epoch [11/50], Step [300/5013], Loss: 0.3863\n",
      "Epoch [11/50], Step [400/5013], Loss: 0.3913\n",
      "Epoch [11/50], Step [500/5013], Loss: 0.3874\n",
      "Epoch [11/50], Step [600/5013], Loss: 0.3893\n",
      "Epoch [11/50], Step [700/5013], Loss: 0.3720\n",
      "Epoch [11/50], Step [800/5013], Loss: 0.3788\n",
      "Epoch [11/50], Step [900/5013], Loss: 0.3858\n",
      "Epoch [11/50], Step [1000/5013], Loss: 0.3934\n",
      "Epoch [11/50], Step [1100/5013], Loss: 0.3796\n",
      "Epoch [11/50], Step [1200/5013], Loss: 0.3812\n",
      "Epoch [11/50], Step [1300/5013], Loss: 0.3933\n",
      "Epoch [11/50], Step [1400/5013], Loss: 0.3994\n",
      "Epoch [11/50], Step [1500/5013], Loss: 0.3842\n",
      "Epoch [11/50], Step [1600/5013], Loss: 0.3975\n",
      "Epoch [11/50], Step [1700/5013], Loss: 0.4076\n",
      "Epoch [11/50], Step [1800/5013], Loss: 0.3889\n",
      "Epoch [11/50], Step [1900/5013], Loss: 0.3757\n",
      "Epoch [11/50], Step [2000/5013], Loss: 0.4216\n",
      "Epoch [11/50], Step [2100/5013], Loss: 0.3750\n",
      "Epoch [11/50], Step [2200/5013], Loss: 0.3867\n",
      "Epoch [11/50], Step [2300/5013], Loss: 0.3856\n",
      "Epoch [11/50], Step [2400/5013], Loss: 0.4009\n",
      "Epoch [11/50], Step [2500/5013], Loss: 0.4077\n",
      "Epoch [11/50], Step [2600/5013], Loss: 0.3781\n",
      "Epoch [11/50], Step [2700/5013], Loss: 0.3749\n",
      "Epoch [11/50], Step [2800/5013], Loss: 0.3912\n",
      "Epoch [11/50], Step [2900/5013], Loss: 0.3748\n",
      "Epoch [11/50], Step [3000/5013], Loss: 0.4191\n",
      "Epoch [11/50], Step [3100/5013], Loss: 0.3795\n",
      "Epoch [11/50], Step [3200/5013], Loss: 0.3916\n",
      "Epoch [11/50], Step [3300/5013], Loss: 0.3998\n",
      "Epoch [11/50], Step [3400/5013], Loss: 0.3654\n",
      "Epoch [11/50], Step [3500/5013], Loss: 0.3880\n",
      "Epoch [11/50], Step [3600/5013], Loss: 0.3939\n",
      "Epoch [11/50], Step [3700/5013], Loss: 0.3833\n",
      "Epoch [11/50], Step [3800/5013], Loss: 0.3871\n",
      "Epoch [11/50], Step [3900/5013], Loss: 0.4009\n",
      "Epoch [11/50], Step [4000/5013], Loss: 0.3981\n",
      "Epoch [11/50], Step [4100/5013], Loss: 0.3895\n",
      "Epoch [11/50], Step [4200/5013], Loss: 0.4119\n",
      "Epoch [11/50], Step [4300/5013], Loss: 0.3785\n",
      "Epoch [11/50], Step [4400/5013], Loss: 0.4064\n",
      "Epoch [11/50], Step [4500/5013], Loss: 0.3987\n",
      "Epoch [11/50], Step [4600/5013], Loss: 0.4084\n",
      "Epoch [11/50], Step [4700/5013], Loss: 0.4001\n",
      "Epoch [11/50], Step [4800/5013], Loss: 0.3953\n",
      "Epoch [11/50], Step [4900/5013], Loss: 0.4153\n",
      "Epoch [11/50], Step [5000/5013], Loss: 0.3991\n",
      "Epoch [11/50] Average Loss: 0.3922\n",
      "Epoch [12/50], Step [100/5013], Loss: 0.3986\n",
      "Epoch [12/50], Step [200/5013], Loss: 0.3806\n",
      "Epoch [12/50], Step [300/5013], Loss: 0.3586\n",
      "Epoch [12/50], Step [400/5013], Loss: 0.3923\n",
      "Epoch [12/50], Step [500/5013], Loss: 0.3821\n",
      "Epoch [12/50], Step [600/5013], Loss: 0.3655\n",
      "Epoch [12/50], Step [700/5013], Loss: 0.3923\n",
      "Epoch [12/50], Step [800/5013], Loss: 0.3702\n",
      "Epoch [12/50], Step [900/5013], Loss: 0.3875\n",
      "Epoch [12/50], Step [1000/5013], Loss: 0.3948\n",
      "Epoch [12/50], Step [1100/5013], Loss: 0.3893\n",
      "Epoch [12/50], Step [1200/5013], Loss: 0.3806\n",
      "Epoch [12/50], Step [1300/5013], Loss: 0.3724\n",
      "Epoch [12/50], Step [1400/5013], Loss: 0.3865\n",
      "Epoch [12/50], Step [1500/5013], Loss: 0.3740\n",
      "Epoch [12/50], Step [1600/5013], Loss: 0.3870\n",
      "Epoch [12/50], Step [1700/5013], Loss: 0.3919\n",
      "Epoch [12/50], Step [1800/5013], Loss: 0.4138\n",
      "Epoch [12/50], Step [1900/5013], Loss: 0.3869\n",
      "Epoch [12/50], Step [2000/5013], Loss: 0.3871\n",
      "Epoch [12/50], Step [2100/5013], Loss: 0.3913\n",
      "Epoch [12/50], Step [2200/5013], Loss: 0.3663\n",
      "Epoch [12/50], Step [2300/5013], Loss: 0.3807\n",
      "Epoch [12/50], Step [2400/5013], Loss: 0.3796\n",
      "Epoch [12/50], Step [2500/5013], Loss: 0.3763\n",
      "Epoch [12/50], Step [2600/5013], Loss: 0.3848\n",
      "Epoch [12/50], Step [2700/5013], Loss: 0.3797\n",
      "Epoch [12/50], Step [2800/5013], Loss: 0.3816\n",
      "Epoch [12/50], Step [2900/5013], Loss: 0.3723\n",
      "Epoch [12/50], Step [3000/5013], Loss: 0.3812\n",
      "Epoch [12/50], Step [3100/5013], Loss: 0.3805\n",
      "Epoch [12/50], Step [3200/5013], Loss: 0.3655\n",
      "Epoch [12/50], Step [3300/5013], Loss: 0.3797\n",
      "Epoch [12/50], Step [3400/5013], Loss: 0.4348\n",
      "Epoch [12/50], Step [3500/5013], Loss: 0.3819\n",
      "Epoch [12/50], Step [3600/5013], Loss: 0.3744\n",
      "Epoch [12/50], Step [3700/5013], Loss: 0.3944\n",
      "Epoch [12/50], Step [3800/5013], Loss: 0.3987\n",
      "Epoch [12/50], Step [3900/5013], Loss: 0.4132\n",
      "Epoch [12/50], Step [4000/5013], Loss: 0.3699\n",
      "Epoch [12/50], Step [4100/5013], Loss: 0.3879\n",
      "Epoch [12/50], Step [4200/5013], Loss: 0.3876\n",
      "Epoch [12/50], Step [4300/5013], Loss: 0.3914\n",
      "Epoch [12/50], Step [4400/5013], Loss: 0.3931\n",
      "Epoch [12/50], Step [4500/5013], Loss: 0.4094\n",
      "Epoch [12/50], Step [4600/5013], Loss: 0.3957\n",
      "Epoch [12/50], Step [4700/5013], Loss: 0.3793\n",
      "Epoch [12/50], Step [4800/5013], Loss: 0.3611\n",
      "Epoch [12/50], Step [4900/5013], Loss: 0.3960\n",
      "Epoch [12/50], Step [5000/5013], Loss: 0.3744\n",
      "Epoch [12/50] Average Loss: 0.3851\n",
      "Epoch [13/50], Step [100/5013], Loss: 0.3824\n",
      "Epoch [13/50], Step [200/5013], Loss: 0.3587\n",
      "Epoch [13/50], Step [300/5013], Loss: 0.3992\n",
      "Epoch [13/50], Step [400/5013], Loss: 0.3711\n",
      "Epoch [13/50], Step [500/5013], Loss: 0.3934\n",
      "Epoch [13/50], Step [600/5013], Loss: 0.3714\n",
      "Epoch [13/50], Step [700/5013], Loss: 0.3989\n",
      "Epoch [13/50], Step [800/5013], Loss: 0.3745\n",
      "Epoch [13/50], Step [900/5013], Loss: 0.3678\n",
      "Epoch [13/50], Step [1000/5013], Loss: 0.3630\n",
      "Epoch [13/50], Step [1100/5013], Loss: 0.3606\n",
      "Epoch [13/50], Step [1200/5013], Loss: 0.3776\n",
      "Epoch [13/50], Step [1300/5013], Loss: 0.4053\n",
      "Epoch [13/50], Step [1400/5013], Loss: 0.3649\n",
      "Epoch [13/50], Step [1500/5013], Loss: 0.3686\n",
      "Epoch [13/50], Step [1600/5013], Loss: 0.3734\n",
      "Epoch [13/50], Step [1700/5013], Loss: 0.3829\n",
      "Epoch [13/50], Step [1800/5013], Loss: 0.3915\n",
      "Epoch [13/50], Step [1900/5013], Loss: 0.3615\n",
      "Epoch [13/50], Step [2000/5013], Loss: 0.3742\n",
      "Epoch [13/50], Step [2100/5013], Loss: 0.3766\n",
      "Epoch [13/50], Step [2200/5013], Loss: 0.3811\n",
      "Epoch [13/50], Step [2300/5013], Loss: 0.3506\n",
      "Epoch [13/50], Step [2400/5013], Loss: 0.4058\n",
      "Epoch [13/50], Step [2500/5013], Loss: 0.3574\n",
      "Epoch [13/50], Step [2600/5013], Loss: 0.3811\n",
      "Epoch [13/50], Step [2700/5013], Loss: 0.3858\n",
      "Epoch [13/50], Step [2800/5013], Loss: 0.3734\n",
      "Epoch [13/50], Step [2900/5013], Loss: 0.3724\n",
      "Epoch [13/50], Step [3000/5013], Loss: 0.3856\n",
      "Epoch [13/50], Step [3100/5013], Loss: 0.3590\n",
      "Epoch [13/50], Step [3200/5013], Loss: 0.3969\n",
      "Epoch [13/50], Step [3300/5013], Loss: 0.3776\n",
      "Epoch [13/50], Step [3400/5013], Loss: 0.4151\n",
      "Epoch [13/50], Step [3500/5013], Loss: 0.3961\n",
      "Epoch [13/50], Step [3600/5013], Loss: 0.3869\n",
      "Epoch [13/50], Step [3700/5013], Loss: 0.3700\n",
      "Epoch [13/50], Step [3800/5013], Loss: 0.3567\n",
      "Epoch [13/50], Step [3900/5013], Loss: 0.3619\n",
      "Epoch [13/50], Step [4000/5013], Loss: 0.3700\n",
      "Epoch [13/50], Step [4100/5013], Loss: 0.3935\n",
      "Epoch [13/50], Step [4200/5013], Loss: 0.3840\n",
      "Epoch [13/50], Step [4300/5013], Loss: 0.3602\n",
      "Epoch [13/50], Step [4400/5013], Loss: 0.3835\n",
      "Epoch [13/50], Step [4500/5013], Loss: 0.3870\n",
      "Epoch [13/50], Step [4600/5013], Loss: 0.3434\n",
      "Epoch [13/50], Step [4700/5013], Loss: 0.4104\n",
      "Epoch [13/50], Step [4800/5013], Loss: 0.3950\n",
      "Epoch [13/50], Step [4900/5013], Loss: 0.3971\n",
      "Epoch [13/50], Step [5000/5013], Loss: 0.3688\n",
      "Epoch [13/50] Average Loss: 0.3784\n",
      "Epoch [14/50], Step [100/5013], Loss: 0.3601\n",
      "Epoch [14/50], Step [200/5013], Loss: 0.3493\n",
      "Epoch [14/50], Step [300/5013], Loss: 0.3542\n",
      "Epoch [14/50], Step [400/5013], Loss: 0.3488\n",
      "Epoch [14/50], Step [500/5013], Loss: 0.3770\n",
      "Epoch [14/50], Step [600/5013], Loss: 0.3581\n",
      "Epoch [14/50], Step [700/5013], Loss: 0.3819\n",
      "Epoch [14/50], Step [800/5013], Loss: 0.3837\n",
      "Epoch [14/50], Step [900/5013], Loss: 0.3822\n",
      "Epoch [14/50], Step [1000/5013], Loss: 0.3603\n",
      "Epoch [14/50], Step [1100/5013], Loss: 0.3674\n",
      "Epoch [14/50], Step [1200/5013], Loss: 0.3568\n",
      "Epoch [14/50], Step [1300/5013], Loss: 0.3543\n",
      "Epoch [14/50], Step [1400/5013], Loss: 0.3710\n",
      "Epoch [14/50], Step [1500/5013], Loss: 0.3807\n",
      "Epoch [14/50], Step [1600/5013], Loss: 0.3707\n",
      "Epoch [14/50], Step [1700/5013], Loss: 0.3506\n",
      "Epoch [14/50], Step [1800/5013], Loss: 0.3713\n",
      "Epoch [14/50], Step [1900/5013], Loss: 0.3677\n",
      "Epoch [14/50], Step [2000/5013], Loss: 0.4098\n",
      "Epoch [14/50], Step [2100/5013], Loss: 0.3819\n",
      "Epoch [14/50], Step [2200/5013], Loss: 0.4066\n",
      "Epoch [14/50], Step [2300/5013], Loss: 0.3811\n",
      "Epoch [14/50], Step [2400/5013], Loss: 0.3492\n",
      "Epoch [14/50], Step [2500/5013], Loss: 0.3952\n",
      "Epoch [14/50], Step [2600/5013], Loss: 0.3692\n",
      "Epoch [14/50], Step [2700/5013], Loss: 0.3762\n",
      "Epoch [14/50], Step [2800/5013], Loss: 0.3877\n",
      "Epoch [14/50], Step [2900/5013], Loss: 0.3827\n",
      "Epoch [14/50], Step [3000/5013], Loss: 0.3441\n",
      "Epoch [14/50], Step [3100/5013], Loss: 0.3737\n",
      "Epoch [14/50], Step [3200/5013], Loss: 0.3592\n",
      "Epoch [14/50], Step [3300/5013], Loss: 0.3939\n",
      "Epoch [14/50], Step [3400/5013], Loss: 0.3916\n",
      "Epoch [14/50], Step [3500/5013], Loss: 0.3723\n",
      "Epoch [14/50], Step [3600/5013], Loss: 0.3697\n",
      "Epoch [14/50], Step [3700/5013], Loss: 0.3871\n",
      "Epoch [14/50], Step [3800/5013], Loss: 0.3596\n",
      "Epoch [14/50], Step [3900/5013], Loss: 0.3924\n",
      "Epoch [14/50], Step [4000/5013], Loss: 0.3679\n",
      "Epoch [14/50], Step [4100/5013], Loss: 0.3554\n",
      "Epoch [14/50], Step [4200/5013], Loss: 0.3610\n",
      "Epoch [14/50], Step [4300/5013], Loss: 0.3734\n",
      "Epoch [14/50], Step [4400/5013], Loss: 0.3694\n",
      "Epoch [14/50], Step [4500/5013], Loss: 0.3913\n",
      "Epoch [14/50], Step [4600/5013], Loss: 0.3876\n",
      "Epoch [14/50], Step [4700/5013], Loss: 0.3784\n",
      "Epoch [14/50], Step [4800/5013], Loss: 0.3689\n",
      "Epoch [14/50], Step [4900/5013], Loss: 0.4075\n",
      "Epoch [14/50], Step [5000/5013], Loss: 0.3580\n",
      "Epoch [14/50] Average Loss: 0.3728\n",
      "Epoch [15/50], Step [100/5013], Loss: 0.3748\n",
      "Epoch [15/50], Step [200/5013], Loss: 0.3819\n",
      "Epoch [15/50], Step [300/5013], Loss: 0.3963\n",
      "Epoch [15/50], Step [400/5013], Loss: 0.3692\n",
      "Epoch [15/50], Step [500/5013], Loss: 0.3536\n",
      "Epoch [15/50], Step [600/5013], Loss: 0.3884\n",
      "Epoch [15/50], Step [700/5013], Loss: 0.3623\n",
      "Epoch [15/50], Step [800/5013], Loss: 0.3369\n",
      "Epoch [15/50], Step [900/5013], Loss: 0.3757\n",
      "Epoch [15/50], Step [1000/5013], Loss: 0.3674\n",
      "Epoch [15/50], Step [1100/5013], Loss: 0.3840\n",
      "Epoch [15/50], Step [1200/5013], Loss: 0.4012\n",
      "Epoch [15/50], Step [1300/5013], Loss: 0.3688\n",
      "Epoch [15/50], Step [1400/5013], Loss: 0.3454\n",
      "Epoch [15/50], Step [1500/5013], Loss: 0.3707\n",
      "Epoch [15/50], Step [1600/5013], Loss: 0.3493\n",
      "Epoch [15/50], Step [1700/5013], Loss: 0.3599\n",
      "Epoch [15/50], Step [1800/5013], Loss: 0.3401\n",
      "Epoch [15/50], Step [1900/5013], Loss: 0.3878\n",
      "Epoch [15/50], Step [2000/5013], Loss: 0.3580\n",
      "Epoch [15/50], Step [2100/5013], Loss: 0.3699\n",
      "Epoch [15/50], Step [2200/5013], Loss: 0.3660\n",
      "Epoch [15/50], Step [2300/5013], Loss: 0.3525\n",
      "Epoch [15/50], Step [2400/5013], Loss: 0.3722\n",
      "Epoch [15/50], Step [2500/5013], Loss: 0.3697\n",
      "Epoch [15/50], Step [2600/5013], Loss: 0.3727\n",
      "Epoch [15/50], Step [2700/5013], Loss: 0.3825\n",
      "Epoch [15/50], Step [2800/5013], Loss: 0.3642\n",
      "Epoch [15/50], Step [2900/5013], Loss: 0.3384\n",
      "Epoch [15/50], Step [3000/5013], Loss: 0.3555\n",
      "Epoch [15/50], Step [3100/5013], Loss: 0.3499\n",
      "Epoch [15/50], Step [3200/5013], Loss: 0.3679\n",
      "Epoch [15/50], Step [3300/5013], Loss: 0.3539\n",
      "Epoch [15/50], Step [3400/5013], Loss: 0.3762\n",
      "Epoch [15/50], Step [3500/5013], Loss: 0.3949\n",
      "Epoch [15/50], Step [3600/5013], Loss: 0.3654\n",
      "Epoch [15/50], Step [3700/5013], Loss: 0.3756\n",
      "Epoch [15/50], Step [3800/5013], Loss: 0.3861\n",
      "Epoch [15/50], Step [3900/5013], Loss: 0.3587\n",
      "Epoch [15/50], Step [4000/5013], Loss: 0.3650\n",
      "Epoch [15/50], Step [4100/5013], Loss: 0.3710\n",
      "Epoch [15/50], Step [4200/5013], Loss: 0.3591\n",
      "Epoch [15/50], Step [4300/5013], Loss: 0.3531\n",
      "Epoch [15/50], Step [4400/5013], Loss: 0.3654\n",
      "Epoch [15/50], Step [4500/5013], Loss: 0.3829\n",
      "Epoch [15/50], Step [4600/5013], Loss: 0.3605\n",
      "Epoch [15/50], Step [4700/5013], Loss: 0.3655\n",
      "Epoch [15/50], Step [4800/5013], Loss: 0.3930\n",
      "Epoch [15/50], Step [4900/5013], Loss: 0.3506\n",
      "Epoch [15/50], Step [5000/5013], Loss: 0.3696\n",
      "Epoch [15/50] Average Loss: 0.3675\n",
      "Epoch [16/50], Step [100/5013], Loss: 0.3601\n",
      "Epoch [16/50], Step [200/5013], Loss: 0.3818\n",
      "Epoch [16/50], Step [300/5013], Loss: 0.3798\n",
      "Epoch [16/50], Step [400/5013], Loss: 0.3304\n",
      "Epoch [16/50], Step [500/5013], Loss: 0.3609\n",
      "Epoch [16/50], Step [600/5013], Loss: 0.3458\n",
      "Epoch [16/50], Step [700/5013], Loss: 0.3341\n",
      "Epoch [16/50], Step [800/5013], Loss: 0.3541\n",
      "Epoch [16/50], Step [900/5013], Loss: 0.3466\n",
      "Epoch [16/50], Step [1000/5013], Loss: 0.3845\n",
      "Epoch [16/50], Step [1100/5013], Loss: 0.3598\n",
      "Epoch [16/50], Step [1200/5013], Loss: 0.3693\n",
      "Epoch [16/50], Step [1300/5013], Loss: 0.3584\n",
      "Epoch [16/50], Step [1400/5013], Loss: 0.3512\n",
      "Epoch [16/50], Step [1500/5013], Loss: 0.3614\n",
      "Epoch [16/50], Step [1600/5013], Loss: 0.3711\n",
      "Epoch [16/50], Step [1700/5013], Loss: 0.3709\n",
      "Epoch [16/50], Step [1800/5013], Loss: 0.3644\n",
      "Epoch [16/50], Step [1900/5013], Loss: 0.3844\n",
      "Epoch [16/50], Step [2000/5013], Loss: 0.3700\n",
      "Epoch [16/50], Step [2100/5013], Loss: 0.3636\n",
      "Epoch [16/50], Step [2200/5013], Loss: 0.3397\n",
      "Epoch [16/50], Step [2300/5013], Loss: 0.3668\n",
      "Epoch [16/50], Step [2400/5013], Loss: 0.3426\n",
      "Epoch [16/50], Step [2500/5013], Loss: 0.3799\n",
      "Epoch [16/50], Step [2600/5013], Loss: 0.3593\n",
      "Epoch [16/50], Step [2700/5013], Loss: 0.3650\n",
      "Epoch [16/50], Step [2800/5013], Loss: 0.3471\n",
      "Epoch [16/50], Step [2900/5013], Loss: 0.3610\n",
      "Epoch [16/50], Step [3000/5013], Loss: 0.3507\n",
      "Epoch [16/50], Step [3100/5013], Loss: 0.3991\n",
      "Epoch [16/50], Step [3200/5013], Loss: 0.3701\n",
      "Epoch [16/50], Step [3300/5013], Loss: 0.3654\n",
      "Epoch [16/50], Step [3400/5013], Loss: 0.3613\n",
      "Epoch [16/50], Step [3500/5013], Loss: 0.3732\n",
      "Epoch [16/50], Step [3600/5013], Loss: 0.3461\n",
      "Epoch [16/50], Step [3700/5013], Loss: 0.3877\n",
      "Epoch [16/50], Step [3800/5013], Loss: 0.3575\n",
      "Epoch [16/50], Step [3900/5013], Loss: 0.3643\n",
      "Epoch [16/50], Step [4000/5013], Loss: 0.3728\n",
      "Epoch [16/50], Step [4100/5013], Loss: 0.3577\n",
      "Epoch [16/50], Step [4200/5013], Loss: 0.3599\n",
      "Epoch [16/50], Step [4300/5013], Loss: 0.3632\n",
      "Epoch [16/50], Step [4400/5013], Loss: 0.3462\n",
      "Epoch [16/50], Step [4500/5013], Loss: 0.3737\n",
      "Epoch [16/50], Step [4600/5013], Loss: 0.3704\n",
      "Epoch [16/50], Step [4700/5013], Loss: 0.3516\n",
      "Epoch [16/50], Step [4800/5013], Loss: 0.3526\n",
      "Epoch [16/50], Step [4900/5013], Loss: 0.3726\n",
      "Epoch [16/50], Step [5000/5013], Loss: 0.3596\n",
      "Epoch [16/50] Average Loss: 0.3623\n",
      "Epoch [17/50], Step [100/5013], Loss: 0.3501\n",
      "Epoch [17/50], Step [200/5013], Loss: 0.3621\n",
      "Epoch [17/50], Step [300/5013], Loss: 0.3492\n",
      "Epoch [17/50], Step [400/5013], Loss: 0.3628\n",
      "Epoch [17/50], Step [500/5013], Loss: 0.3546\n",
      "Epoch [17/50], Step [600/5013], Loss: 0.3463\n",
      "Epoch [17/50], Step [700/5013], Loss: 0.3442\n",
      "Epoch [17/50], Step [800/5013], Loss: 0.3675\n",
      "Epoch [17/50], Step [900/5013], Loss: 0.3508\n",
      "Epoch [17/50], Step [1000/5013], Loss: 0.3414\n",
      "Epoch [17/50], Step [1100/5013], Loss: 0.3706\n",
      "Epoch [17/50], Step [1200/5013], Loss: 0.3461\n",
      "Epoch [17/50], Step [1300/5013], Loss: 0.3707\n",
      "Epoch [17/50], Step [1400/5013], Loss: 0.3552\n",
      "Epoch [17/50], Step [1500/5013], Loss: 0.3900\n",
      "Epoch [17/50], Step [1600/5013], Loss: 0.3527\n",
      "Epoch [17/50], Step [1700/5013], Loss: 0.3431\n",
      "Epoch [17/50], Step [1800/5013], Loss: 0.3584\n",
      "Epoch [17/50], Step [1900/5013], Loss: 0.3458\n",
      "Epoch [17/50], Step [2000/5013], Loss: 0.3529\n",
      "Epoch [17/50], Step [2100/5013], Loss: 0.3485\n",
      "Epoch [17/50], Step [2200/5013], Loss: 0.3477\n",
      "Epoch [17/50], Step [2300/5013], Loss: 0.3467\n",
      "Epoch [17/50], Step [2400/5013], Loss: 0.3688\n",
      "Epoch [17/50], Step [2500/5013], Loss: 0.3621\n",
      "Epoch [17/50], Step [2600/5013], Loss: 0.3260\n",
      "Epoch [17/50], Step [2700/5013], Loss: 0.3707\n",
      "Epoch [17/50], Step [2800/5013], Loss: 0.3550\n",
      "Epoch [17/50], Step [2900/5013], Loss: 0.3749\n",
      "Epoch [17/50], Step [3000/5013], Loss: 0.3529\n",
      "Epoch [17/50], Step [3100/5013], Loss: 0.3471\n",
      "Epoch [17/50], Step [3200/5013], Loss: 0.3575\n",
      "Epoch [17/50], Step [3300/5013], Loss: 0.3460\n",
      "Epoch [17/50], Step [3400/5013], Loss: 0.3652\n",
      "Epoch [17/50], Step [3500/5013], Loss: 0.3693\n",
      "Epoch [17/50], Step [3600/5013], Loss: 0.3894\n",
      "Epoch [17/50], Step [3700/5013], Loss: 0.3392\n",
      "Epoch [17/50], Step [3800/5013], Loss: 0.3451\n",
      "Epoch [17/50], Step [3900/5013], Loss: 0.3714\n",
      "Epoch [17/50], Step [4000/5013], Loss: 0.3699\n",
      "Epoch [17/50], Step [4100/5013], Loss: 0.3434\n",
      "Epoch [17/50], Step [4200/5013], Loss: 0.3685\n",
      "Epoch [17/50], Step [4300/5013], Loss: 0.3458\n",
      "Epoch [17/50], Step [4400/5013], Loss: 0.3527\n",
      "Epoch [17/50], Step [4500/5013], Loss: 0.3360\n",
      "Epoch [17/50], Step [4600/5013], Loss: 0.3396\n",
      "Epoch [17/50], Step [4700/5013], Loss: 0.3780\n",
      "Epoch [17/50], Step [4800/5013], Loss: 0.3479\n",
      "Epoch [17/50], Step [4900/5013], Loss: 0.3632\n",
      "Epoch [17/50], Step [5000/5013], Loss: 0.3675\n",
      "Epoch [17/50] Average Loss: 0.3563\n",
      "Epoch [18/50], Step [100/5013], Loss: 0.3528\n",
      "Epoch [18/50], Step [200/5013], Loss: 0.3789\n",
      "Epoch [18/50], Step [300/5013], Loss: 0.3354\n",
      "Epoch [18/50], Step [400/5013], Loss: 0.3486\n",
      "Epoch [18/50], Step [500/5013], Loss: 0.3555\n",
      "Epoch [18/50], Step [600/5013], Loss: 0.3645\n",
      "Epoch [18/50], Step [700/5013], Loss: 0.3539\n",
      "Epoch [18/50], Step [800/5013], Loss: 0.3352\n",
      "Epoch [18/50], Step [900/5013], Loss: 0.3360\n",
      "Epoch [18/50], Step [1000/5013], Loss: 0.3761\n",
      "Epoch [18/50], Step [1100/5013], Loss: 0.3315\n",
      "Epoch [18/50], Step [1200/5013], Loss: 0.3181\n",
      "Epoch [18/50], Step [1300/5013], Loss: 0.3668\n",
      "Epoch [18/50], Step [1400/5013], Loss: 0.3838\n",
      "Epoch [18/50], Step [1500/5013], Loss: 0.3459\n",
      "Epoch [18/50], Step [1600/5013], Loss: 0.3506\n",
      "Epoch [18/50], Step [1700/5013], Loss: 0.3541\n",
      "Epoch [18/50], Step [1800/5013], Loss: 0.3634\n",
      "Epoch [18/50], Step [1900/5013], Loss: 0.3511\n",
      "Epoch [18/50], Step [2000/5013], Loss: 0.3790\n",
      "Epoch [18/50], Step [2100/5013], Loss: 0.3382\n",
      "Epoch [18/50], Step [2200/5013], Loss: 0.3608\n",
      "Epoch [18/50], Step [2300/5013], Loss: 0.3336\n",
      "Epoch [18/50], Step [2400/5013], Loss: 0.3461\n",
      "Epoch [18/50], Step [2500/5013], Loss: 0.3760\n",
      "Epoch [18/50], Step [2600/5013], Loss: 0.3621\n",
      "Epoch [18/50], Step [2700/5013], Loss: 0.3557\n",
      "Epoch [18/50], Step [2800/5013], Loss: 0.3561\n",
      "Epoch [18/50], Step [2900/5013], Loss: 0.3568\n",
      "Epoch [18/50], Step [3000/5013], Loss: 0.3756\n",
      "Epoch [18/50], Step [3100/5013], Loss: 0.3530\n",
      "Epoch [18/50], Step [3200/5013], Loss: 0.3285\n",
      "Epoch [18/50], Step [3300/5013], Loss: 0.3616\n",
      "Epoch [18/50], Step [3400/5013], Loss: 0.3559\n",
      "Epoch [18/50], Step [3500/5013], Loss: 0.3508\n",
      "Epoch [18/50], Step [3600/5013], Loss: 0.3800\n",
      "Epoch [18/50], Step [3700/5013], Loss: 0.3864\n",
      "Epoch [18/50], Step [3800/5013], Loss: 0.3504\n",
      "Epoch [18/50], Step [3900/5013], Loss: 0.3494\n",
      "Epoch [18/50], Step [4000/5013], Loss: 0.3288\n",
      "Epoch [18/50], Step [4100/5013], Loss: 0.3284\n",
      "Epoch [18/50], Step [4200/5013], Loss: 0.3515\n",
      "Epoch [18/50], Step [4300/5013], Loss: 0.3486\n",
      "Epoch [18/50], Step [4400/5013], Loss: 0.3557\n",
      "Epoch [18/50], Step [4500/5013], Loss: 0.3481\n",
      "Epoch [18/50], Step [4600/5013], Loss: 0.3882\n",
      "Epoch [18/50], Step [4700/5013], Loss: 0.3546\n",
      "Epoch [18/50], Step [4800/5013], Loss: 0.3707\n",
      "Epoch [18/50], Step [4900/5013], Loss: 0.3539\n",
      "Epoch [18/50], Step [5000/5013], Loss: 0.3688\n",
      "Epoch [18/50] Average Loss: 0.3551\n",
      "Epoch [19/50], Step [100/5013], Loss: 0.3412\n",
      "Epoch [19/50], Step [200/5013], Loss: 0.3466\n",
      "Epoch [19/50], Step [300/5013], Loss: 0.3558\n",
      "Epoch [19/50], Step [400/5013], Loss: 0.3533\n",
      "Epoch [19/50], Step [500/5013], Loss: 0.3476\n",
      "Epoch [19/50], Step [600/5013], Loss: 0.3365\n",
      "Epoch [19/50], Step [700/5013], Loss: 0.3476\n",
      "Epoch [19/50], Step [800/5013], Loss: 0.3579\n",
      "Epoch [19/50], Step [900/5013], Loss: 0.3455\n",
      "Epoch [19/50], Step [1000/5013], Loss: 0.3472\n",
      "Epoch [19/50], Step [1100/5013], Loss: 0.3499\n",
      "Epoch [19/50], Step [1200/5013], Loss: 0.3578\n",
      "Epoch [19/50], Step [1300/5013], Loss: 0.3434\n",
      "Epoch [19/50], Step [1400/5013], Loss: 0.3485\n",
      "Epoch [19/50], Step [1500/5013], Loss: 0.3487\n",
      "Epoch [19/50], Step [1600/5013], Loss: 0.3279\n",
      "Epoch [19/50], Step [1700/5013], Loss: 0.3367\n",
      "Epoch [19/50], Step [1800/5013], Loss: 0.3654\n",
      "Epoch [19/50], Step [1900/5013], Loss: 0.3549\n",
      "Epoch [19/50], Step [2000/5013], Loss: 0.3603\n",
      "Epoch [19/50], Step [2100/5013], Loss: 0.3254\n",
      "Epoch [19/50], Step [2200/5013], Loss: 0.3629\n",
      "Epoch [19/50], Step [2300/5013], Loss: 0.3659\n",
      "Epoch [19/50], Step [2400/5013], Loss: 0.3403\n",
      "Epoch [19/50], Step [2500/5013], Loss: 0.3571\n",
      "Epoch [19/50], Step [2600/5013], Loss: 0.3475\n",
      "Epoch [19/50], Step [2700/5013], Loss: 0.3491\n",
      "Epoch [19/50], Step [2800/5013], Loss: 0.3361\n",
      "Epoch [19/50], Step [2900/5013], Loss: 0.3553\n",
      "Epoch [19/50], Step [3000/5013], Loss: 0.3456\n",
      "Epoch [19/50], Step [3100/5013], Loss: 0.3245\n",
      "Epoch [19/50], Step [3200/5013], Loss: 0.3381\n",
      "Epoch [19/50], Step [3300/5013], Loss: 0.3637\n",
      "Epoch [19/50], Step [3400/5013], Loss: 0.3463\n",
      "Epoch [19/50], Step [3500/5013], Loss: 0.3368\n",
      "Epoch [19/50], Step [3600/5013], Loss: 0.3325\n",
      "Epoch [19/50], Step [3700/5013], Loss: 0.3441\n",
      "Epoch [19/50], Step [3800/5013], Loss: 0.3811\n",
      "Epoch [19/50], Step [3900/5013], Loss: 0.3505\n",
      "Epoch [19/50], Step [4000/5013], Loss: 0.3369\n",
      "Epoch [19/50], Step [4100/5013], Loss: 0.3604\n",
      "Epoch [19/50], Step [4200/5013], Loss: 0.3953\n",
      "Epoch [19/50], Step [4300/5013], Loss: 0.3325\n",
      "Epoch [19/50], Step [4400/5013], Loss: 0.3528\n",
      "Epoch [19/50], Step [4500/5013], Loss: 0.3371\n",
      "Epoch [19/50], Step [4600/5013], Loss: 0.3398\n",
      "Epoch [19/50], Step [4700/5013], Loss: 0.3586\n",
      "Epoch [19/50], Step [4800/5013], Loss: 0.3319\n",
      "Epoch [19/50], Step [4900/5013], Loss: 0.3359\n",
      "Epoch [19/50], Step [5000/5013], Loss: 0.3693\n",
      "Epoch [19/50] Average Loss: 0.3487\n",
      "Epoch [20/50], Step [100/5013], Loss: 0.3255\n",
      "Epoch [20/50], Step [200/5013], Loss: 0.3466\n",
      "Epoch [20/50], Step [300/5013], Loss: 0.3305\n",
      "Epoch [20/50], Step [400/5013], Loss: 0.3339\n",
      "Epoch [20/50], Step [500/5013], Loss: 0.3417\n",
      "Epoch [20/50], Step [600/5013], Loss: 0.3470\n",
      "Epoch [20/50], Step [700/5013], Loss: 0.3577\n",
      "Epoch [20/50], Step [800/5013], Loss: 0.3323\n",
      "Epoch [20/50], Step [900/5013], Loss: 0.3327\n",
      "Epoch [20/50], Step [1000/5013], Loss: 0.3289\n",
      "Epoch [20/50], Step [1100/5013], Loss: 0.3573\n",
      "Epoch [20/50], Step [1200/5013], Loss: 0.3332\n",
      "Epoch [20/50], Step [1300/5013], Loss: 0.3505\n",
      "Epoch [20/50], Step [1400/5013], Loss: 0.3421\n",
      "Epoch [20/50], Step [1500/5013], Loss: 0.3509\n",
      "Epoch [20/50], Step [1600/5013], Loss: 0.3551\n",
      "Epoch [20/50], Step [1700/5013], Loss: 0.3391\n",
      "Epoch [20/50], Step [1800/5013], Loss: 0.3279\n",
      "Epoch [20/50], Step [1900/5013], Loss: 0.3480\n",
      "Epoch [20/50], Step [2000/5013], Loss: 0.3245\n",
      "Epoch [20/50], Step [2100/5013], Loss: 0.3464\n",
      "Epoch [20/50], Step [2200/5013], Loss: 0.3447\n",
      "Epoch [20/50], Step [2300/5013], Loss: 0.3522\n",
      "Epoch [20/50], Step [2400/5013], Loss: 0.3321\n",
      "Epoch [20/50], Step [2500/5013], Loss: 0.3406\n",
      "Epoch [20/50], Step [2600/5013], Loss: 0.3526\n",
      "Epoch [20/50], Step [2700/5013], Loss: 0.3382\n",
      "Epoch [20/50], Step [2800/5013], Loss: 0.3454\n",
      "Epoch [20/50], Step [2900/5013], Loss: 0.3293\n",
      "Epoch [20/50], Step [3000/5013], Loss: 0.3584\n",
      "Epoch [20/50], Step [3100/5013], Loss: 0.3354\n",
      "Epoch [20/50], Step [3200/5013], Loss: 0.3528\n",
      "Epoch [20/50], Step [3300/5013], Loss: 0.3604\n",
      "Epoch [20/50], Step [3400/5013], Loss: 0.3348\n",
      "Epoch [20/50], Step [3500/5013], Loss: 0.3740\n",
      "Epoch [20/50], Step [3600/5013], Loss: 0.3514\n",
      "Epoch [20/50], Step [3700/5013], Loss: 0.3421\n",
      "Epoch [20/50], Step [3800/5013], Loss: 0.3431\n",
      "Epoch [20/50], Step [3900/5013], Loss: 0.3400\n",
      "Epoch [20/50], Step [4000/5013], Loss: 0.3520\n",
      "Epoch [20/50], Step [4100/5013], Loss: 0.3383\n",
      "Epoch [20/50], Step [4200/5013], Loss: 0.3337\n",
      "Epoch [20/50], Step [4300/5013], Loss: 0.3479\n",
      "Epoch [20/50], Step [4400/5013], Loss: 0.3517\n",
      "Epoch [20/50], Step [4500/5013], Loss: 0.3581\n",
      "Epoch [20/50], Step [4600/5013], Loss: 0.3208\n",
      "Epoch [20/50], Step [4700/5013], Loss: 0.3572\n",
      "Epoch [20/50], Step [4800/5013], Loss: 0.3661\n",
      "Epoch [20/50], Step [4900/5013], Loss: 0.3442\n",
      "Epoch [20/50], Step [5000/5013], Loss: 0.3431\n",
      "Epoch [20/50] Average Loss: 0.3439\n",
      "Epoch [21/50], Step [100/5013], Loss: 0.3340\n",
      "Epoch [21/50], Step [200/5013], Loss: 0.3443\n",
      "Epoch [21/50], Step [300/5013], Loss: 0.3639\n",
      "Epoch [21/50], Step [400/5013], Loss: 0.3450\n",
      "Epoch [21/50], Step [500/5013], Loss: 0.3673\n",
      "Epoch [21/50], Step [600/5013], Loss: 0.3250\n",
      "Epoch [21/50], Step [700/5013], Loss: 0.3309\n",
      "Epoch [21/50], Step [800/5013], Loss: 0.3204\n",
      "Epoch [21/50], Step [900/5013], Loss: 0.3444\n",
      "Epoch [21/50], Step [1000/5013], Loss: 0.3428\n",
      "Epoch [21/50], Step [1100/5013], Loss: 0.3494\n",
      "Epoch [21/50], Step [1200/5013], Loss: 0.3465\n",
      "Epoch [21/50], Step [1300/5013], Loss: 0.3635\n",
      "Epoch [21/50], Step [1400/5013], Loss: 0.3429\n",
      "Epoch [21/50], Step [1500/5013], Loss: 0.3450\n",
      "Epoch [21/50], Step [1600/5013], Loss: 0.3730\n",
      "Epoch [21/50], Step [1700/5013], Loss: 0.3500\n",
      "Epoch [21/50], Step [1800/5013], Loss: 0.3339\n",
      "Epoch [21/50], Step [1900/5013], Loss: 0.3229\n",
      "Epoch [21/50], Step [2000/5013], Loss: 0.3240\n",
      "Epoch [21/50], Step [2100/5013], Loss: 0.3444\n",
      "Epoch [21/50], Step [2200/5013], Loss: 0.3306\n",
      "Epoch [21/50], Step [2300/5013], Loss: 0.3672\n",
      "Epoch [21/50], Step [2400/5013], Loss: 0.3531\n",
      "Epoch [21/50], Step [2500/5013], Loss: 0.3167\n",
      "Epoch [21/50], Step [2600/5013], Loss: 0.3517\n",
      "Epoch [21/50], Step [2700/5013], Loss: 0.3353\n",
      "Epoch [21/50], Step [2800/5013], Loss: 0.3437\n",
      "Epoch [21/50], Step [2900/5013], Loss: 0.3482\n",
      "Epoch [21/50], Step [3000/5013], Loss: 0.3261\n",
      "Epoch [21/50], Step [3100/5013], Loss: 0.3215\n",
      "Epoch [21/50], Step [3200/5013], Loss: 0.3483\n",
      "Epoch [21/50], Step [3300/5013], Loss: 0.3431\n",
      "Epoch [21/50], Step [3400/5013], Loss: 0.3450\n",
      "Epoch [21/50], Step [3500/5013], Loss: 0.3211\n",
      "Epoch [21/50], Step [3600/5013], Loss: 0.3110\n",
      "Epoch [21/50], Step [3700/5013], Loss: 0.3405\n",
      "Epoch [21/50], Step [3800/5013], Loss: 0.3004\n",
      "Epoch [21/50], Step [3900/5013], Loss: 0.3652\n",
      "Epoch [21/50], Step [4000/5013], Loss: 0.3505\n",
      "Epoch [21/50], Step [4100/5013], Loss: 0.3267\n",
      "Epoch [21/50], Step [4200/5013], Loss: 0.3531\n",
      "Epoch [21/50], Step [4300/5013], Loss: 0.3243\n",
      "Epoch [21/50], Step [4400/5013], Loss: 0.3585\n",
      "Epoch [21/50], Step [4500/5013], Loss: 0.3681\n",
      "Epoch [21/50], Step [4600/5013], Loss: 0.3441\n",
      "Epoch [21/50], Step [4700/5013], Loss: 0.3321\n",
      "Epoch [21/50], Step [4800/5013], Loss: 0.3276\n",
      "Epoch [21/50], Step [4900/5013], Loss: 0.3363\n",
      "Epoch [21/50], Step [5000/5013], Loss: 0.3516\n",
      "Epoch [21/50] Average Loss: 0.3411\n",
      "Epoch [22/50], Step [100/5013], Loss: 0.3689\n",
      "Epoch [22/50], Step [200/5013], Loss: 0.3385\n",
      "Epoch [22/50], Step [300/5013], Loss: 0.3302\n",
      "Epoch [22/50], Step [400/5013], Loss: 0.3378\n",
      "Epoch [22/50], Step [500/5013], Loss: 0.3364\n",
      "Epoch [22/50], Step [600/5013], Loss: 0.3667\n",
      "Epoch [22/50], Step [700/5013], Loss: 0.3409\n",
      "Epoch [22/50], Step [800/5013], Loss: 0.3214\n",
      "Epoch [22/50], Step [900/5013], Loss: 0.3349\n",
      "Epoch [22/50], Step [1000/5013], Loss: 0.3352\n",
      "Epoch [22/50], Step [1100/5013], Loss: 0.3576\n",
      "Epoch [22/50], Step [1200/5013], Loss: 0.3153\n",
      "Epoch [22/50], Step [1300/5013], Loss: 0.3549\n",
      "Epoch [22/50], Step [1400/5013], Loss: 0.3440\n",
      "Epoch [22/50], Step [1500/5013], Loss: 0.3264\n",
      "Epoch [22/50], Step [1600/5013], Loss: 0.3458\n",
      "Epoch [22/50], Step [1700/5013], Loss: 0.3321\n",
      "Epoch [22/50], Step [1800/5013], Loss: 0.3611\n",
      "Epoch [22/50], Step [1900/5013], Loss: 0.3713\n",
      "Epoch [22/50], Step [2000/5013], Loss: 0.3449\n",
      "Epoch [22/50], Step [2100/5013], Loss: 0.3459\n",
      "Epoch [22/50], Step [2200/5013], Loss: 0.3338\n",
      "Epoch [22/50], Step [2300/5013], Loss: 0.3359\n",
      "Epoch [22/50], Step [2400/5013], Loss: 0.3378\n",
      "Epoch [22/50], Step [2500/5013], Loss: 0.3284\n",
      "Epoch [22/50], Step [2600/5013], Loss: 0.3255\n",
      "Epoch [22/50], Step [2700/5013], Loss: 0.3308\n",
      "Epoch [22/50], Step [2800/5013], Loss: 0.3332\n",
      "Epoch [22/50], Step [2900/5013], Loss: 0.3456\n",
      "Epoch [22/50], Step [3000/5013], Loss: 0.3558\n",
      "Epoch [22/50], Step [3100/5013], Loss: 0.3508\n",
      "Epoch [22/50], Step [3200/5013], Loss: 0.3429\n",
      "Epoch [22/50], Step [3300/5013], Loss: 0.3241\n",
      "Epoch [22/50], Step [3400/5013], Loss: 0.3230\n",
      "Epoch [22/50], Step [3500/5013], Loss: 0.3352\n",
      "Epoch [22/50], Step [3600/5013], Loss: 0.3396\n",
      "Epoch [22/50], Step [3700/5013], Loss: 0.3346\n",
      "Epoch [22/50], Step [3800/5013], Loss: 0.3187\n",
      "Epoch [22/50], Step [3900/5013], Loss: 0.3430\n",
      "Epoch [22/50], Step [4000/5013], Loss: 0.3294\n",
      "Epoch [22/50], Step [4100/5013], Loss: 0.3420\n",
      "Epoch [22/50], Step [4200/5013], Loss: 0.3479\n",
      "Epoch [22/50], Step [4300/5013], Loss: 0.3262\n",
      "Epoch [22/50], Step [4400/5013], Loss: 0.3274\n",
      "Epoch [22/50], Step [4500/5013], Loss: 0.3888\n",
      "Epoch [22/50], Step [4600/5013], Loss: 0.3256\n",
      "Epoch [22/50], Step [4700/5013], Loss: 0.3405\n",
      "Epoch [22/50], Step [4800/5013], Loss: 0.3301\n",
      "Epoch [22/50], Step [4900/5013], Loss: 0.3340\n",
      "Epoch [22/50], Step [5000/5013], Loss: 0.3416\n",
      "Epoch [22/50] Average Loss: 0.3398\n",
      "Epoch [23/50], Step [100/5013], Loss: 0.3552\n",
      "Epoch [23/50], Step [200/5013], Loss: 0.3310\n",
      "Epoch [23/50], Step [300/5013], Loss: 0.3292\n",
      "Epoch [23/50], Step [400/5013], Loss: 0.3224\n",
      "Epoch [23/50], Step [500/5013], Loss: 0.3490\n",
      "Epoch [23/50], Step [600/5013], Loss: 0.3346\n",
      "Epoch [23/50], Step [700/5013], Loss: 0.3533\n",
      "Epoch [23/50], Step [800/5013], Loss: 0.3257\n",
      "Epoch [23/50], Step [900/5013], Loss: 0.3239\n",
      "Epoch [23/50], Step [1000/5013], Loss: 0.3029\n",
      "Epoch [23/50], Step [1100/5013], Loss: 0.3440\n",
      "Epoch [23/50], Step [1200/5013], Loss: 0.3491\n",
      "Epoch [23/50], Step [1300/5013], Loss: 0.3412\n",
      "Epoch [23/50], Step [1400/5013], Loss: 0.3039\n",
      "Epoch [23/50], Step [1500/5013], Loss: 0.3684\n",
      "Epoch [23/50], Step [1600/5013], Loss: 0.3375\n",
      "Epoch [23/50], Step [1700/5013], Loss: 0.3264\n",
      "Epoch [23/50], Step [1800/5013], Loss: 0.3379\n",
      "Epoch [23/50], Step [1900/5013], Loss: 0.3493\n",
      "Epoch [23/50], Step [2000/5013], Loss: 0.3432\n",
      "Epoch [23/50], Step [2100/5013], Loss: 0.3179\n",
      "Epoch [23/50], Step [2200/5013], Loss: 0.3260\n",
      "Epoch [23/50], Step [2300/5013], Loss: 0.3079\n",
      "Epoch [23/50], Step [2400/5013], Loss: 0.3441\n",
      "Epoch [23/50], Step [2500/5013], Loss: 0.3394\n",
      "Epoch [23/50], Step [2600/5013], Loss: 0.3029\n",
      "Epoch [23/50], Step [2700/5013], Loss: 0.3467\n",
      "Epoch [23/50], Step [2800/5013], Loss: 0.3336\n",
      "Epoch [23/50], Step [2900/5013], Loss: 0.3556\n",
      "Epoch [23/50], Step [3000/5013], Loss: 0.3125\n",
      "Epoch [23/50], Step [3100/5013], Loss: 0.3283\n",
      "Epoch [23/50], Step [3200/5013], Loss: 0.3547\n",
      "Epoch [23/50], Step [3300/5013], Loss: 0.3294\n",
      "Epoch [23/50], Step [3400/5013], Loss: 0.3289\n",
      "Epoch [23/50], Step [3500/5013], Loss: 0.3573\n",
      "Epoch [23/50], Step [3600/5013], Loss: 0.3390\n",
      "Epoch [23/50], Step [3700/5013], Loss: 0.3485\n",
      "Epoch [23/50], Step [3800/5013], Loss: 0.3445\n",
      "Epoch [23/50], Step [3900/5013], Loss: 0.3436\n",
      "Epoch [23/50], Step [4000/5013], Loss: 0.3377\n",
      "Epoch [23/50], Step [4100/5013], Loss: 0.3426\n",
      "Epoch [23/50], Step [4200/5013], Loss: 0.3321\n",
      "Epoch [23/50], Step [4300/5013], Loss: 0.3537\n",
      "Epoch [23/50], Step [4400/5013], Loss: 0.3192\n",
      "Epoch [23/50], Step [4500/5013], Loss: 0.3546\n",
      "Epoch [23/50], Step [4600/5013], Loss: 0.3349\n",
      "Epoch [23/50], Step [4700/5013], Loss: 0.3284\n",
      "Epoch [23/50], Step [4800/5013], Loss: 0.3466\n",
      "Epoch [23/50], Step [4900/5013], Loss: 0.3605\n",
      "Epoch [23/50], Step [5000/5013], Loss: 0.3472\n",
      "Epoch [23/50] Average Loss: 0.3370\n",
      "Epoch [24/50], Step [100/5013], Loss: 0.3364\n",
      "Epoch [24/50], Step [200/5013], Loss: 0.3243\n",
      "Epoch [24/50], Step [300/5013], Loss: 0.3302\n",
      "Epoch [24/50], Step [400/5013], Loss: 0.3380\n",
      "Epoch [24/50], Step [500/5013], Loss: 0.3222\n",
      "Epoch [24/50], Step [600/5013], Loss: 0.3106\n",
      "Epoch [24/50], Step [700/5013], Loss: 0.3207\n",
      "Epoch [24/50], Step [800/5013], Loss: 0.3321\n",
      "Epoch [24/50], Step [900/5013], Loss: 0.3321\n",
      "Epoch [24/50], Step [1000/5013], Loss: 0.3556\n",
      "Epoch [24/50], Step [1100/5013], Loss: 0.3404\n",
      "Epoch [24/50], Step [1200/5013], Loss: 0.3364\n",
      "Epoch [24/50], Step [1300/5013], Loss: 0.3316\n",
      "Epoch [24/50], Step [1400/5013], Loss: 0.3352\n",
      "Epoch [24/50], Step [1500/5013], Loss: 0.3349\n",
      "Epoch [24/50], Step [1600/5013], Loss: 0.3164\n",
      "Epoch [24/50], Step [1700/5013], Loss: 0.3278\n",
      "Epoch [24/50], Step [1800/5013], Loss: 0.3290\n",
      "Epoch [24/50], Step [1900/5013], Loss: 0.3455\n",
      "Epoch [24/50], Step [2000/5013], Loss: 0.3351\n",
      "Epoch [24/50], Step [2100/5013], Loss: 0.3541\n",
      "Epoch [24/50], Step [2200/5013], Loss: 0.3734\n",
      "Epoch [24/50], Step [2300/5013], Loss: 0.3354\n",
      "Epoch [24/50], Step [2400/5013], Loss: 0.3336\n",
      "Epoch [24/50], Step [2500/5013], Loss: 0.3161\n",
      "Epoch [24/50], Step [2600/5013], Loss: 0.3452\n",
      "Epoch [24/50], Step [2700/5013], Loss: 0.3344\n",
      "Epoch [24/50], Step [2800/5013], Loss: 0.3303\n",
      "Epoch [24/50], Step [2900/5013], Loss: 0.3306\n",
      "Epoch [24/50], Step [3000/5013], Loss: 0.3300\n",
      "Epoch [24/50], Step [3100/5013], Loss: 0.3315\n",
      "Epoch [24/50], Step [3200/5013], Loss: 0.3372\n",
      "Epoch [24/50], Step [3300/5013], Loss: 0.3149\n",
      "Epoch [24/50], Step [3400/5013], Loss: 0.3423\n",
      "Epoch [24/50], Step [3500/5013], Loss: 0.3384\n",
      "Epoch [24/50], Step [3600/5013], Loss: 0.3329\n",
      "Epoch [24/50], Step [3700/5013], Loss: 0.3366\n",
      "Epoch [24/50], Step [3800/5013], Loss: 0.3165\n",
      "Epoch [24/50], Step [3900/5013], Loss: 0.3624\n",
      "Epoch [24/50], Step [4000/5013], Loss: 0.3458\n",
      "Epoch [24/50], Step [4100/5013], Loss: 0.3113\n",
      "Epoch [24/50], Step [4200/5013], Loss: 0.3582\n",
      "Epoch [24/50], Step [4300/5013], Loss: 0.3441\n",
      "Epoch [24/50], Step [4400/5013], Loss: 0.3238\n",
      "Epoch [24/50], Step [4500/5013], Loss: 0.2951\n",
      "Epoch [24/50], Step [4600/5013], Loss: 0.3466\n",
      "Epoch [24/50], Step [4700/5013], Loss: 0.3266\n",
      "Epoch [24/50], Step [4800/5013], Loss: 0.3257\n",
      "Epoch [24/50], Step [4900/5013], Loss: 0.3324\n",
      "Epoch [24/50], Step [5000/5013], Loss: 0.3404\n",
      "Epoch [24/50] Average Loss: 0.3336\n",
      "Epoch [25/50], Step [100/5013], Loss: 0.3402\n",
      "Epoch [25/50], Step [200/5013], Loss: 0.3147\n",
      "Epoch [25/50], Step [300/5013], Loss: 0.3301\n",
      "Epoch [25/50], Step [400/5013], Loss: 0.3092\n",
      "Epoch [25/50], Step [500/5013], Loss: 0.3277\n",
      "Epoch [25/50], Step [600/5013], Loss: 0.3152\n",
      "Epoch [25/50], Step [700/5013], Loss: 0.3214\n",
      "Epoch [25/50], Step [800/5013], Loss: 0.3599\n",
      "Epoch [25/50], Step [900/5013], Loss: 0.3153\n",
      "Epoch [25/50], Step [1000/5013], Loss: 0.3359\n",
      "Epoch [25/50], Step [1100/5013], Loss: 0.3298\n",
      "Epoch [25/50], Step [1200/5013], Loss: 0.3251\n",
      "Epoch [25/50], Step [1300/5013], Loss: 0.3082\n",
      "Epoch [25/50], Step [1400/5013], Loss: 0.3400\n",
      "Epoch [25/50], Step [1500/5013], Loss: 0.3276\n",
      "Epoch [25/50], Step [1600/5013], Loss: 0.3180\n",
      "Epoch [25/50], Step [1700/5013], Loss: 0.3295\n",
      "Epoch [25/50], Step [1800/5013], Loss: 0.3333\n",
      "Epoch [25/50], Step [1900/5013], Loss: 0.3266\n",
      "Epoch [25/50], Step [2000/5013], Loss: 0.3262\n",
      "Epoch [25/50], Step [2100/5013], Loss: 0.3211\n",
      "Epoch [25/50], Step [2200/5013], Loss: 0.3391\n",
      "Epoch [25/50], Step [2300/5013], Loss: 0.3242\n",
      "Epoch [25/50], Step [2400/5013], Loss: 0.3257\n",
      "Epoch [25/50], Step [2500/5013], Loss: 0.3277\n",
      "Epoch [25/50], Step [2600/5013], Loss: 0.3276\n",
      "Epoch [25/50], Step [2700/5013], Loss: 0.3231\n",
      "Epoch [25/50], Step [2800/5013], Loss: 0.3386\n",
      "Epoch [25/50], Step [2900/5013], Loss: 0.3468\n",
      "Epoch [25/50], Step [3000/5013], Loss: 0.3165\n",
      "Epoch [25/50], Step [3100/5013], Loss: 0.3354\n",
      "Epoch [25/50], Step [3200/5013], Loss: 0.3461\n",
      "Epoch [25/50], Step [3300/5013], Loss: 0.3245\n",
      "Epoch [25/50], Step [3400/5013], Loss: 0.3350\n",
      "Epoch [25/50], Step [3500/5013], Loss: 0.3164\n",
      "Epoch [25/50], Step [3600/5013], Loss: 0.3353\n",
      "Epoch [25/50], Step [3700/5013], Loss: 0.3443\n",
      "Epoch [25/50], Step [3800/5013], Loss: 0.3410\n",
      "Epoch [25/50], Step [3900/5013], Loss: 0.3541\n",
      "Epoch [25/50], Step [4000/5013], Loss: 0.3197\n",
      "Epoch [25/50], Step [4100/5013], Loss: 0.3470\n",
      "Epoch [25/50], Step [4200/5013], Loss: 0.3268\n",
      "Epoch [25/50], Step [4300/5013], Loss: 0.3342\n",
      "Epoch [25/50], Step [4400/5013], Loss: 0.3248\n",
      "Epoch [25/50], Step [4500/5013], Loss: 0.3161\n",
      "Epoch [25/50], Step [4600/5013], Loss: 0.3337\n",
      "Epoch [25/50], Step [4700/5013], Loss: 0.3211\n",
      "Epoch [25/50], Step [4800/5013], Loss: 0.3291\n",
      "Epoch [25/50], Step [4900/5013], Loss: 0.3331\n",
      "Epoch [25/50], Step [5000/5013], Loss: 0.3498\n",
      "Epoch [25/50] Average Loss: 0.3299\n",
      "Epoch [26/50], Step [100/5013], Loss: 0.3280\n",
      "Epoch [26/50], Step [200/5013], Loss: 0.3235\n",
      "Epoch [26/50], Step [300/5013], Loss: 0.3087\n",
      "Epoch [26/50], Step [400/5013], Loss: 0.3239\n",
      "Epoch [26/50], Step [500/5013], Loss: 0.3542\n",
      "Epoch [26/50], Step [600/5013], Loss: 0.3367\n",
      "Epoch [26/50], Step [700/5013], Loss: 0.3107\n",
      "Epoch [26/50], Step [800/5013], Loss: 0.3186\n",
      "Epoch [26/50], Step [900/5013], Loss: 0.3051\n",
      "Epoch [26/50], Step [1000/5013], Loss: 0.3208\n",
      "Epoch [26/50], Step [1100/5013], Loss: 0.3332\n",
      "Epoch [26/50], Step [1200/5013], Loss: 0.3246\n",
      "Epoch [26/50], Step [1300/5013], Loss: 0.3225\n",
      "Epoch [26/50], Step [1400/5013], Loss: 0.3167\n",
      "Epoch [26/50], Step [1500/5013], Loss: 0.3089\n",
      "Epoch [26/50], Step [1600/5013], Loss: 0.3043\n",
      "Epoch [26/50], Step [1700/5013], Loss: 0.3396\n",
      "Epoch [26/50], Step [1800/5013], Loss: 0.3149\n",
      "Epoch [26/50], Step [1900/5013], Loss: 0.3324\n",
      "Epoch [26/50], Step [2000/5013], Loss: 0.2884\n",
      "Epoch [26/50], Step [2100/5013], Loss: 0.3553\n",
      "Epoch [26/50], Step [2200/5013], Loss: 0.3120\n",
      "Epoch [26/50], Step [2300/5013], Loss: 0.3181\n",
      "Epoch [26/50], Step [2400/5013], Loss: 0.3214\n",
      "Epoch [26/50], Step [2500/5013], Loss: 0.3263\n",
      "Epoch [26/50], Step [2600/5013], Loss: 0.3322\n",
      "Epoch [26/50], Step [2700/5013], Loss: 0.3363\n",
      "Epoch [26/50], Step [2800/5013], Loss: 0.3342\n",
      "Epoch [26/50], Step [2900/5013], Loss: 0.3348\n",
      "Epoch [26/50], Step [3000/5013], Loss: 0.3429\n",
      "Epoch [26/50], Step [3100/5013], Loss: 0.3357\n",
      "Epoch [26/50], Step [3200/5013], Loss: 0.3112\n",
      "Epoch [26/50], Step [3300/5013], Loss: 0.3328\n",
      "Epoch [26/50], Step [3400/5013], Loss: 0.3184\n",
      "Epoch [26/50], Step [3500/5013], Loss: 0.3145\n",
      "Epoch [26/50], Step [3600/5013], Loss: 0.3238\n",
      "Epoch [26/50], Step [3700/5013], Loss: 0.3157\n",
      "Epoch [26/50], Step [3800/5013], Loss: 0.3244\n",
      "Epoch [26/50], Step [3900/5013], Loss: 0.3473\n",
      "Epoch [26/50], Step [4000/5013], Loss: 0.3175\n",
      "Epoch [26/50], Step [4100/5013], Loss: 0.3330\n",
      "Epoch [26/50], Step [4200/5013], Loss: 0.3254\n",
      "Epoch [26/50], Step [4300/5013], Loss: 0.3264\n",
      "Epoch [26/50], Step [4400/5013], Loss: 0.3212\n",
      "Epoch [26/50], Step [4500/5013], Loss: 0.3181\n",
      "Epoch [26/50], Step [4600/5013], Loss: 0.3169\n",
      "Epoch [26/50], Step [4700/5013], Loss: 0.3293\n",
      "Epoch [26/50], Step [4800/5013], Loss: 0.3479\n",
      "Epoch [26/50], Step [4900/5013], Loss: 0.3258\n",
      "Epoch [26/50], Step [5000/5013], Loss: 0.3473\n",
      "Epoch [26/50] Average Loss: 0.3252\n",
      "Epoch [27/50], Step [100/5013], Loss: 0.3382\n",
      "Epoch [27/50], Step [200/5013], Loss: 0.3468\n",
      "Epoch [27/50], Step [300/5013], Loss: 0.3059\n",
      "Epoch [27/50], Step [400/5013], Loss: 0.3203\n",
      "Epoch [27/50], Step [500/5013], Loss: 0.3115\n",
      "Epoch [27/50], Step [600/5013], Loss: 0.3099\n",
      "Epoch [27/50], Step [700/5013], Loss: 0.3384\n",
      "Epoch [27/50], Step [800/5013], Loss: 0.3229\n",
      "Epoch [27/50], Step [900/5013], Loss: 0.3149\n",
      "Epoch [27/50], Step [1000/5013], Loss: 0.3038\n",
      "Epoch [27/50], Step [1100/5013], Loss: 0.3303\n",
      "Epoch [27/50], Step [1200/5013], Loss: 0.3090\n",
      "Epoch [27/50], Step [1300/5013], Loss: 0.3222\n",
      "Epoch [27/50], Step [1400/5013], Loss: 0.3274\n",
      "Epoch [27/50], Step [1500/5013], Loss: 0.3240\n",
      "Epoch [27/50], Step [1600/5013], Loss: 0.3087\n",
      "Epoch [27/50], Step [1700/5013], Loss: 0.3198\n",
      "Epoch [27/50], Step [1800/5013], Loss: 0.3077\n",
      "Epoch [27/50], Step [1900/5013], Loss: 0.3158\n",
      "Epoch [27/50], Step [2000/5013], Loss: 0.3268\n",
      "Epoch [27/50], Step [2100/5013], Loss: 0.3300\n",
      "Epoch [27/50], Step [2200/5013], Loss: 0.3118\n",
      "Epoch [27/50], Step [2300/5013], Loss: 0.3396\n",
      "Epoch [27/50], Step [2400/5013], Loss: 0.3292\n",
      "Epoch [27/50], Step [2500/5013], Loss: 0.3333\n",
      "Epoch [27/50], Step [2600/5013], Loss: 0.3182\n",
      "Epoch [27/50], Step [2700/5013], Loss: 0.3312\n",
      "Epoch [27/50], Step [2800/5013], Loss: 0.2918\n",
      "Epoch [27/50], Step [2900/5013], Loss: 0.3534\n",
      "Epoch [27/50], Step [3000/5013], Loss: 0.3135\n",
      "Epoch [27/50], Step [3100/5013], Loss: 0.3247\n",
      "Epoch [27/50], Step [3200/5013], Loss: 0.3201\n",
      "Epoch [27/50], Step [3300/5013], Loss: 0.3406\n",
      "Epoch [27/50], Step [3400/5013], Loss: 0.3081\n",
      "Epoch [27/50], Step [3500/5013], Loss: 0.3277\n",
      "Epoch [27/50], Step [3600/5013], Loss: 0.3293\n",
      "Epoch [27/50], Step [3700/5013], Loss: 0.3291\n",
      "Epoch [27/50], Step [3800/5013], Loss: 0.3469\n",
      "Epoch [27/50], Step [3900/5013], Loss: 0.3142\n",
      "Epoch [27/50], Step [4000/5013], Loss: 0.3212\n",
      "Epoch [27/50], Step [4100/5013], Loss: 0.3027\n",
      "Epoch [27/50], Step [4200/5013], Loss: 0.3350\n",
      "Epoch [27/50], Step [4300/5013], Loss: 0.3352\n",
      "Epoch [27/50], Step [4400/5013], Loss: 0.3274\n",
      "Epoch [27/50], Step [4500/5013], Loss: 0.3568\n",
      "Epoch [27/50], Step [4600/5013], Loss: 0.3210\n",
      "Epoch [27/50], Step [4700/5013], Loss: 0.3336\n",
      "Epoch [27/50], Step [4800/5013], Loss: 0.3312\n",
      "Epoch [27/50], Step [4900/5013], Loss: 0.3277\n",
      "Epoch [27/50], Step [5000/5013], Loss: 0.3216\n",
      "Epoch [27/50] Average Loss: 0.3243\n",
      "Epoch [28/50], Step [100/5013], Loss: 0.2998\n",
      "Epoch [28/50], Step [200/5013], Loss: 0.3264\n",
      "Epoch [28/50], Step [300/5013], Loss: 0.3290\n",
      "Epoch [28/50], Step [400/5013], Loss: 0.3095\n",
      "Epoch [28/50], Step [500/5013], Loss: 0.3228\n",
      "Epoch [28/50], Step [600/5013], Loss: 0.3048\n",
      "Epoch [28/50], Step [700/5013], Loss: 0.3280\n",
      "Epoch [28/50], Step [800/5013], Loss: 0.3307\n",
      "Epoch [28/50], Step [900/5013], Loss: 0.3247\n",
      "Epoch [28/50], Step [1000/5013], Loss: 0.3188\n",
      "Epoch [28/50], Step [1100/5013], Loss: 0.3187\n",
      "Epoch [28/50], Step [1200/5013], Loss: 0.3352\n",
      "Epoch [28/50], Step [1300/5013], Loss: 0.2975\n",
      "Epoch [28/50], Step [1400/5013], Loss: 0.3049\n",
      "Epoch [28/50], Step [1500/5013], Loss: 0.3176\n",
      "Epoch [28/50], Step [1600/5013], Loss: 0.3084\n",
      "Epoch [28/50], Step [1700/5013], Loss: 0.3260\n",
      "Epoch [28/50], Step [1800/5013], Loss: 0.3161\n",
      "Epoch [28/50], Step [1900/5013], Loss: 0.3282\n",
      "Epoch [28/50], Step [2000/5013], Loss: 0.3263\n",
      "Epoch [28/50], Step [2100/5013], Loss: 0.2973\n",
      "Epoch [28/50], Step [2200/5013], Loss: 0.3161\n",
      "Epoch [28/50], Step [2300/5013], Loss: 0.3233\n",
      "Epoch [28/50], Step [2400/5013], Loss: 0.3081\n",
      "Epoch [28/50], Step [2500/5013], Loss: 0.3378\n",
      "Epoch [28/50], Step [2600/5013], Loss: 0.3406\n",
      "Epoch [28/50], Step [2700/5013], Loss: 0.3402\n",
      "Epoch [28/50], Step [2800/5013], Loss: 0.3242\n",
      "Epoch [28/50], Step [2900/5013], Loss: 0.2983\n",
      "Epoch [28/50], Step [3000/5013], Loss: 0.3203\n",
      "Epoch [28/50], Step [3100/5013], Loss: 0.3161\n",
      "Epoch [28/50], Step [3200/5013], Loss: 0.3285\n",
      "Epoch [28/50], Step [3300/5013], Loss: 0.3203\n",
      "Epoch [28/50], Step [3400/5013], Loss: 0.3283\n",
      "Epoch [28/50], Step [3500/5013], Loss: 0.3210\n",
      "Epoch [28/50], Step [3600/5013], Loss: 0.3178\n",
      "Epoch [28/50], Step [3700/5013], Loss: 0.3202\n",
      "Epoch [28/50], Step [3800/5013], Loss: 0.3186\n",
      "Epoch [28/50], Step [3900/5013], Loss: 0.3400\n",
      "Epoch [28/50], Step [4000/5013], Loss: 0.3481\n",
      "Epoch [28/50], Step [4100/5013], Loss: 0.3128\n",
      "Epoch [28/50], Step [4200/5013], Loss: 0.3250\n",
      "Epoch [28/50], Step [4300/5013], Loss: 0.3140\n",
      "Epoch [28/50], Step [4400/5013], Loss: 0.3306\n",
      "Epoch [28/50], Step [4500/5013], Loss: 0.3265\n",
      "Epoch [28/50], Step [4600/5013], Loss: 0.3277\n",
      "Epoch [28/50], Step [4700/5013], Loss: 0.3169\n",
      "Epoch [28/50], Step [4800/5013], Loss: 0.3448\n",
      "Epoch [28/50], Step [4900/5013], Loss: 0.3035\n",
      "Epoch [28/50], Step [5000/5013], Loss: 0.3233\n",
      "Epoch [28/50] Average Loss: 0.3212\n",
      "Epoch [29/50], Step [100/5013], Loss: 0.3134\n",
      "Epoch [29/50], Step [200/5013], Loss: 0.3216\n",
      "Epoch [29/50], Step [300/5013], Loss: 0.3472\n",
      "Epoch [29/50], Step [400/5013], Loss: 0.3045\n",
      "Epoch [29/50], Step [500/5013], Loss: 0.3048\n",
      "Epoch [29/50], Step [600/5013], Loss: 0.3391\n",
      "Epoch [29/50], Step [700/5013], Loss: 0.3156\n",
      "Epoch [29/50], Step [800/5013], Loss: 0.3154\n",
      "Epoch [29/50], Step [900/5013], Loss: 0.3306\n",
      "Epoch [29/50], Step [1000/5013], Loss: 0.3049\n",
      "Epoch [29/50], Step [1100/5013], Loss: 0.3270\n",
      "Epoch [29/50], Step [1200/5013], Loss: 0.3248\n",
      "Epoch [29/50], Step [1300/5013], Loss: 0.3051\n",
      "Epoch [29/50], Step [1400/5013], Loss: 0.3115\n",
      "Epoch [29/50], Step [1500/5013], Loss: 0.3153\n",
      "Epoch [29/50], Step [1600/5013], Loss: 0.3124\n",
      "Epoch [29/50], Step [1700/5013], Loss: 0.3008\n",
      "Epoch [29/50], Step [1800/5013], Loss: 0.3030\n",
      "Epoch [29/50], Step [1900/5013], Loss: 0.3234\n",
      "Epoch [29/50], Step [2000/5013], Loss: 0.3545\n",
      "Epoch [29/50], Step [2100/5013], Loss: 0.3200\n",
      "Epoch [29/50], Step [2200/5013], Loss: 0.3212\n",
      "Epoch [29/50], Step [2300/5013], Loss: 0.3001\n",
      "Epoch [29/50], Step [2400/5013], Loss: 0.3137\n",
      "Epoch [29/50], Step [2500/5013], Loss: 0.3043\n",
      "Epoch [29/50], Step [2600/5013], Loss: 0.3279\n",
      "Epoch [29/50], Step [2700/5013], Loss: 0.3010\n",
      "Epoch [29/50], Step [2800/5013], Loss: 0.3364\n",
      "Epoch [29/50], Step [2900/5013], Loss: 0.2981\n",
      "Epoch [29/50], Step [3000/5013], Loss: 0.3095\n",
      "Epoch [29/50], Step [3100/5013], Loss: 0.3211\n",
      "Epoch [29/50], Step [3200/5013], Loss: 0.3381\n",
      "Epoch [29/50], Step [3300/5013], Loss: 0.3193\n",
      "Epoch [29/50], Step [3400/5013], Loss: 0.3230\n",
      "Epoch [29/50], Step [3500/5013], Loss: 0.3191\n",
      "Epoch [29/50], Step [3600/5013], Loss: 0.3614\n",
      "Epoch [29/50], Step [3700/5013], Loss: 0.3374\n",
      "Epoch [29/50], Step [3800/5013], Loss: 0.3221\n",
      "Epoch [29/50], Step [3900/5013], Loss: 0.3195\n",
      "Epoch [29/50], Step [4000/5013], Loss: 0.3375\n",
      "Epoch [29/50], Step [4100/5013], Loss: 0.3373\n",
      "Epoch [29/50], Step [4200/5013], Loss: 0.3318\n",
      "Epoch [29/50], Step [4300/5013], Loss: 0.3238\n",
      "Epoch [29/50], Step [4400/5013], Loss: 0.3112\n",
      "Epoch [29/50], Step [4500/5013], Loss: 0.3238\n",
      "Epoch [29/50], Step [4600/5013], Loss: 0.3226\n",
      "Epoch [29/50], Step [4700/5013], Loss: 0.3218\n",
      "Epoch [29/50], Step [4800/5013], Loss: 0.3279\n",
      "Epoch [29/50], Step [4900/5013], Loss: 0.3186\n",
      "Epoch [29/50], Step [5000/5013], Loss: 0.3103\n",
      "Epoch [29/50] Average Loss: 0.3207\n",
      "Epoch [30/50], Step [100/5013], Loss: 0.3227\n",
      "Epoch [30/50], Step [200/5013], Loss: 0.3319\n",
      "Epoch [30/50], Step [300/5013], Loss: 0.3296\n",
      "Epoch [30/50], Step [400/5013], Loss: 0.3280\n",
      "Epoch [30/50], Step [500/5013], Loss: 0.3242\n",
      "Epoch [30/50], Step [600/5013], Loss: 0.3117\n",
      "Epoch [30/50], Step [700/5013], Loss: 0.3167\n",
      "Epoch [30/50], Step [800/5013], Loss: 0.3198\n",
      "Epoch [30/50], Step [900/5013], Loss: 0.3180\n",
      "Epoch [30/50], Step [1000/5013], Loss: 0.3211\n",
      "Epoch [30/50], Step [1100/5013], Loss: 0.2997\n",
      "Epoch [30/50], Step [1200/5013], Loss: 0.2992\n",
      "Epoch [30/50], Step [1300/5013], Loss: 0.3245\n",
      "Epoch [30/50], Step [1400/5013], Loss: 0.3104\n",
      "Epoch [30/50], Step [1500/5013], Loss: 0.3221\n",
      "Epoch [30/50], Step [1600/5013], Loss: 0.3015\n",
      "Epoch [30/50], Step [1700/5013], Loss: 0.3103\n",
      "Epoch [30/50], Step [1800/5013], Loss: 0.3143\n",
      "Epoch [30/50], Step [1900/5013], Loss: 0.3113\n",
      "Epoch [30/50], Step [2000/5013], Loss: 0.3169\n",
      "Epoch [30/50], Step [2100/5013], Loss: 0.3037\n",
      "Epoch [30/50], Step [2200/5013], Loss: 0.3196\n",
      "Epoch [30/50], Step [2300/5013], Loss: 0.3083\n",
      "Epoch [30/50], Step [2400/5013], Loss: 0.3096\n",
      "Epoch [30/50], Step [2500/5013], Loss: 0.3263\n",
      "Epoch [30/50], Step [2600/5013], Loss: 0.3022\n",
      "Epoch [30/50], Step [2700/5013], Loss: 0.3159\n",
      "Epoch [30/50], Step [2800/5013], Loss: 0.3264\n",
      "Epoch [30/50], Step [2900/5013], Loss: 0.3376\n",
      "Epoch [30/50], Step [3000/5013], Loss: 0.2963\n",
      "Epoch [30/50], Step [3100/5013], Loss: 0.3235\n",
      "Epoch [30/50], Step [3200/5013], Loss: 0.3292\n",
      "Epoch [30/50], Step [3300/5013], Loss: 0.3052\n",
      "Epoch [30/50], Step [3400/5013], Loss: 0.3136\n",
      "Epoch [30/50], Step [3500/5013], Loss: 0.3054\n",
      "Epoch [30/50], Step [3600/5013], Loss: 0.3233\n",
      "Epoch [30/50], Step [3700/5013], Loss: 0.3359\n",
      "Epoch [30/50], Step [3800/5013], Loss: 0.3141\n",
      "Epoch [30/50], Step [3900/5013], Loss: 0.3310\n",
      "Epoch [30/50], Step [4000/5013], Loss: 0.3169\n",
      "Epoch [30/50], Step [4100/5013], Loss: 0.3302\n",
      "Epoch [30/50], Step [4200/5013], Loss: 0.3099\n",
      "Epoch [30/50], Step [4300/5013], Loss: 0.3028\n",
      "Epoch [30/50], Step [4400/5013], Loss: 0.3432\n",
      "Epoch [30/50], Step [4500/5013], Loss: 0.3300\n",
      "Epoch [30/50], Step [4600/5013], Loss: 0.3199\n",
      "Epoch [30/50], Step [4700/5013], Loss: 0.3201\n",
      "Epoch [30/50], Step [4800/5013], Loss: 0.3260\n",
      "Epoch [30/50], Step [4900/5013], Loss: 0.3126\n",
      "Epoch [30/50], Step [5000/5013], Loss: 0.3093\n",
      "Epoch [30/50] Average Loss: 0.3175\n",
      "Epoch [31/50], Step [100/5013], Loss: 0.3001\n",
      "Epoch [31/50], Step [200/5013], Loss: 0.3206\n",
      "Epoch [31/50], Step [300/5013], Loss: 0.3148\n",
      "Epoch [31/50], Step [400/5013], Loss: 0.3080\n",
      "Epoch [31/50], Step [500/5013], Loss: 0.3196\n",
      "Epoch [31/50], Step [600/5013], Loss: 0.3105\n",
      "Epoch [31/50], Step [700/5013], Loss: 0.3031\n",
      "Epoch [31/50], Step [800/5013], Loss: 0.3285\n",
      "Epoch [31/50], Step [900/5013], Loss: 0.3086\n",
      "Epoch [31/50], Step [1000/5013], Loss: 0.3265\n",
      "Epoch [31/50], Step [1100/5013], Loss: 0.3093\n",
      "Epoch [31/50], Step [1200/5013], Loss: 0.2950\n",
      "Epoch [31/50], Step [1300/5013], Loss: 0.3297\n",
      "Epoch [31/50], Step [1400/5013], Loss: 0.3218\n",
      "Epoch [31/50], Step [1500/5013], Loss: 0.3059\n",
      "Epoch [31/50], Step [1600/5013], Loss: 0.3072\n",
      "Epoch [31/50], Step [1700/5013], Loss: 0.3264\n",
      "Epoch [31/50], Step [1800/5013], Loss: 0.3148\n",
      "Epoch [31/50], Step [1900/5013], Loss: 0.3236\n",
      "Epoch [31/50], Step [2000/5013], Loss: 0.3022\n",
      "Epoch [31/50], Step [2100/5013], Loss: 0.2983\n",
      "Epoch [31/50], Step [2200/5013], Loss: 0.3045\n",
      "Epoch [31/50], Step [2300/5013], Loss: 0.2976\n",
      "Epoch [31/50], Step [2400/5013], Loss: 0.3150\n",
      "Epoch [31/50], Step [2500/5013], Loss: 0.2976\n",
      "Epoch [31/50], Step [2600/5013], Loss: 0.3268\n",
      "Epoch [31/50], Step [2700/5013], Loss: 0.3517\n",
      "Epoch [31/50], Step [2800/5013], Loss: 0.2955\n",
      "Epoch [31/50], Step [2900/5013], Loss: 0.3206\n",
      "Epoch [31/50], Step [3000/5013], Loss: 0.2957\n",
      "Epoch [31/50], Step [3100/5013], Loss: 0.3171\n",
      "Epoch [31/50], Step [3200/5013], Loss: 0.3231\n",
      "Epoch [31/50], Step [3300/5013], Loss: 0.3213\n",
      "Epoch [31/50], Step [3400/5013], Loss: 0.3087\n",
      "Epoch [31/50], Step [3500/5013], Loss: 0.3201\n",
      "Epoch [31/50], Step [3600/5013], Loss: 0.3242\n",
      "Epoch [31/50], Step [3700/5013], Loss: 0.2912\n",
      "Epoch [31/50], Step [3800/5013], Loss: 0.3026\n",
      "Epoch [31/50], Step [3900/5013], Loss: 0.3276\n",
      "Epoch [31/50], Step [4000/5013], Loss: 0.3215\n",
      "Epoch [31/50], Step [4100/5013], Loss: 0.3080\n",
      "Epoch [31/50], Step [4200/5013], Loss: 0.3265\n",
      "Epoch [31/50], Step [4300/5013], Loss: 0.2957\n",
      "Epoch [31/50], Step [4400/5013], Loss: 0.3233\n",
      "Epoch [31/50], Step [4500/5013], Loss: 0.3296\n",
      "Epoch [31/50], Step [4600/5013], Loss: 0.3152\n",
      "Epoch [31/50], Step [4700/5013], Loss: 0.3129\n",
      "Epoch [31/50], Step [4800/5013], Loss: 0.3166\n",
      "Epoch [31/50], Step [4900/5013], Loss: 0.3296\n",
      "Epoch [31/50], Step [5000/5013], Loss: 0.3326\n",
      "Epoch [31/50] Average Loss: 0.3145\n",
      "Epoch [32/50], Step [100/5013], Loss: 0.3068\n",
      "Epoch [32/50], Step [200/5013], Loss: 0.3273\n",
      "Epoch [32/50], Step [300/5013], Loss: 0.3253\n",
      "Epoch [32/50], Step [400/5013], Loss: 0.3036\n",
      "Epoch [32/50], Step [500/5013], Loss: 0.2932\n",
      "Epoch [32/50], Step [600/5013], Loss: 0.3026\n",
      "Epoch [32/50], Step [700/5013], Loss: 0.3215\n",
      "Epoch [32/50], Step [800/5013], Loss: 0.3351\n",
      "Epoch [32/50], Step [900/5013], Loss: 0.3087\n",
      "Epoch [32/50], Step [1000/5013], Loss: 0.3223\n",
      "Epoch [32/50], Step [1100/5013], Loss: 0.3176\n",
      "Epoch [32/50], Step [1200/5013], Loss: 0.3211\n",
      "Epoch [32/50], Step [1300/5013], Loss: 0.3199\n",
      "Epoch [32/50], Step [1400/5013], Loss: 0.3254\n",
      "Epoch [32/50], Step [1500/5013], Loss: 0.3023\n",
      "Epoch [32/50], Step [1600/5013], Loss: 0.3297\n",
      "Epoch [32/50], Step [1700/5013], Loss: 0.2911\n",
      "Epoch [32/50], Step [1800/5013], Loss: 0.3241\n",
      "Epoch [32/50], Step [1900/5013], Loss: 0.2977\n",
      "Epoch [32/50], Step [2000/5013], Loss: 0.3022\n",
      "Epoch [32/50], Step [2100/5013], Loss: 0.2976\n",
      "Epoch [32/50], Step [2200/5013], Loss: 0.3156\n",
      "Epoch [32/50], Step [2300/5013], Loss: 0.3177\n",
      "Epoch [32/50], Step [2400/5013], Loss: 0.3182\n",
      "Epoch [32/50], Step [2500/5013], Loss: 0.3338\n",
      "Epoch [32/50], Step [2600/5013], Loss: 0.3208\n",
      "Epoch [32/50], Step [2700/5013], Loss: 0.3391\n",
      "Epoch [32/50], Step [2800/5013], Loss: 0.3261\n",
      "Epoch [32/50], Step [2900/5013], Loss: 0.3209\n",
      "Epoch [32/50], Step [3000/5013], Loss: 0.3100\n",
      "Epoch [32/50], Step [3100/5013], Loss: 0.3278\n",
      "Epoch [32/50], Step [3200/5013], Loss: 0.3276\n",
      "Epoch [32/50], Step [3300/5013], Loss: 0.3138\n",
      "Epoch [32/50], Step [3400/5013], Loss: 0.3081\n",
      "Epoch [32/50], Step [3500/5013], Loss: 0.3183\n",
      "Epoch [32/50], Step [3600/5013], Loss: 0.2978\n",
      "Epoch [32/50], Step [3700/5013], Loss: 0.3238\n",
      "Epoch [32/50], Step [3800/5013], Loss: 0.3177\n",
      "Epoch [32/50], Step [3900/5013], Loss: 0.3125\n",
      "Epoch [32/50], Step [4000/5013], Loss: 0.3285\n",
      "Epoch [32/50], Step [4100/5013], Loss: 0.3375\n",
      "Epoch [32/50], Step [4200/5013], Loss: 0.2917\n",
      "Epoch [32/50], Step [4300/5013], Loss: 0.3064\n",
      "Epoch [32/50], Step [4400/5013], Loss: 0.3186\n",
      "Epoch [32/50], Step [4500/5013], Loss: 0.3130\n",
      "Epoch [32/50], Step [4600/5013], Loss: 0.2999\n",
      "Epoch [32/50], Step [4700/5013], Loss: 0.2967\n",
      "Epoch [32/50], Step [4800/5013], Loss: 0.2836\n",
      "Epoch [32/50], Step [4900/5013], Loss: 0.3087\n",
      "Epoch [32/50], Step [5000/5013], Loss: 0.3203\n",
      "Epoch [32/50] Average Loss: 0.3145\n",
      "Epoch [33/50], Step [100/5013], Loss: 0.3056\n",
      "Epoch [33/50], Step [200/5013], Loss: 0.3050\n",
      "Epoch [33/50], Step [300/5013], Loss: 0.3003\n",
      "Epoch [33/50], Step [400/5013], Loss: 0.3237\n",
      "Epoch [33/50], Step [500/5013], Loss: 0.2944\n",
      "Epoch [33/50], Step [600/5013], Loss: 0.3189\n",
      "Epoch [33/50], Step [700/5013], Loss: 0.3112\n",
      "Epoch [33/50], Step [800/5013], Loss: 0.3112\n",
      "Epoch [33/50], Step [900/5013], Loss: 0.2959\n",
      "Epoch [33/50], Step [1000/5013], Loss: 0.2897\n",
      "Epoch [33/50], Step [1100/5013], Loss: 0.3093\n",
      "Epoch [33/50], Step [1200/5013], Loss: 0.3267\n",
      "Epoch [33/50], Step [1300/5013], Loss: 0.3270\n",
      "Epoch [33/50], Step [1400/5013], Loss: 0.3138\n",
      "Epoch [33/50], Step [1500/5013], Loss: 0.3394\n",
      "Epoch [33/50], Step [1600/5013], Loss: 0.3472\n",
      "Epoch [33/50], Step [1700/5013], Loss: 0.2973\n",
      "Epoch [33/50], Step [1800/5013], Loss: 0.3178\n",
      "Epoch [33/50], Step [1900/5013], Loss: 0.3006\n",
      "Epoch [33/50], Step [2000/5013], Loss: 0.2834\n",
      "Epoch [33/50], Step [2100/5013], Loss: 0.3244\n",
      "Epoch [33/50], Step [2200/5013], Loss: 0.3116\n",
      "Epoch [33/50], Step [2300/5013], Loss: 0.3378\n",
      "Epoch [33/50], Step [2400/5013], Loss: 0.2875\n",
      "Epoch [33/50], Step [2500/5013], Loss: 0.3246\n",
      "Epoch [33/50], Step [2600/5013], Loss: 0.3158\n",
      "Epoch [33/50], Step [2700/5013], Loss: 0.3093\n",
      "Epoch [33/50], Step [2800/5013], Loss: 0.3273\n",
      "Epoch [33/50], Step [2900/5013], Loss: 0.3122\n",
      "Epoch [33/50], Step [3000/5013], Loss: 0.3277\n",
      "Epoch [33/50], Step [3100/5013], Loss: 0.3217\n",
      "Epoch [33/50], Step [3200/5013], Loss: 0.2934\n",
      "Epoch [33/50], Step [3300/5013], Loss: 0.3143\n",
      "Epoch [33/50], Step [3400/5013], Loss: 0.3146\n",
      "Epoch [33/50], Step [3500/5013], Loss: 0.3024\n",
      "Epoch [33/50], Step [3600/5013], Loss: 0.2947\n",
      "Epoch [33/50], Step [3700/5013], Loss: 0.3130\n",
      "Epoch [33/50], Step [3800/5013], Loss: 0.3234\n",
      "Epoch [33/50], Step [3900/5013], Loss: 0.3041\n",
      "Epoch [33/50], Step [4000/5013], Loss: 0.2969\n",
      "Epoch [33/50], Step [4100/5013], Loss: 0.3009\n",
      "Epoch [33/50], Step [4200/5013], Loss: 0.3244\n",
      "Epoch [33/50], Step [4300/5013], Loss: 0.3065\n",
      "Epoch [33/50], Step [4400/5013], Loss: 0.3231\n",
      "Epoch [33/50], Step [4500/5013], Loss: 0.3082\n",
      "Epoch [33/50], Step [4600/5013], Loss: 0.2970\n",
      "Epoch [33/50], Step [4700/5013], Loss: 0.3134\n",
      "Epoch [33/50], Step [4800/5013], Loss: 0.3109\n",
      "Epoch [33/50], Step [4900/5013], Loss: 0.3277\n",
      "Epoch [33/50], Step [5000/5013], Loss: 0.2882\n",
      "Epoch [33/50] Average Loss: 0.3117\n",
      "Epoch [34/50], Step [100/5013], Loss: 0.3042\n",
      "Epoch [34/50], Step [200/5013], Loss: 0.3066\n",
      "Epoch [34/50], Step [300/5013], Loss: 0.3164\n",
      "Epoch [34/50], Step [400/5013], Loss: 0.3082\n",
      "Epoch [34/50], Step [500/5013], Loss: 0.3087\n",
      "Epoch [34/50], Step [600/5013], Loss: 0.3218\n",
      "Epoch [34/50], Step [700/5013], Loss: 0.3127\n",
      "Epoch [34/50], Step [800/5013], Loss: 0.3178\n",
      "Epoch [34/50], Step [900/5013], Loss: 0.3133\n",
      "Epoch [34/50], Step [1000/5013], Loss: 0.3014\n",
      "Epoch [34/50], Step [1100/5013], Loss: 0.3076\n",
      "Epoch [34/50], Step [1200/5013], Loss: 0.3507\n",
      "Epoch [34/50], Step [1300/5013], Loss: 0.3119\n",
      "Epoch [34/50], Step [1400/5013], Loss: 0.3041\n",
      "Epoch [34/50], Step [1500/5013], Loss: 0.2848\n",
      "Epoch [34/50], Step [1600/5013], Loss: 0.2892\n",
      "Epoch [34/50], Step [1700/5013], Loss: 0.3074\n",
      "Epoch [34/50], Step [1800/5013], Loss: 0.3061\n",
      "Epoch [34/50], Step [1900/5013], Loss: 0.3166\n",
      "Epoch [34/50], Step [2000/5013], Loss: 0.2978\n",
      "Epoch [34/50], Step [2100/5013], Loss: 0.3198\n",
      "Epoch [34/50], Step [2200/5013], Loss: 0.3013\n",
      "Epoch [34/50], Step [2300/5013], Loss: 0.3034\n",
      "Epoch [34/50], Step [2400/5013], Loss: 0.3125\n",
      "Epoch [34/50], Step [2500/5013], Loss: 0.3234\n",
      "Epoch [34/50], Step [2600/5013], Loss: 0.3208\n",
      "Epoch [34/50], Step [2700/5013], Loss: 0.3129\n",
      "Epoch [34/50], Step [2800/5013], Loss: 0.3336\n",
      "Epoch [34/50], Step [2900/5013], Loss: 0.2990\n",
      "Epoch [34/50], Step [3000/5013], Loss: 0.2938\n",
      "Epoch [34/50], Step [3100/5013], Loss: 0.3100\n",
      "Epoch [34/50], Step [3200/5013], Loss: 0.2960\n",
      "Epoch [34/50], Step [3300/5013], Loss: 0.3180\n",
      "Epoch [34/50], Step [3400/5013], Loss: 0.2986\n",
      "Epoch [34/50], Step [3500/5013], Loss: 0.2984\n",
      "Epoch [34/50], Step [3600/5013], Loss: 0.2981\n",
      "Epoch [34/50], Step [3700/5013], Loss: 0.3306\n",
      "Epoch [34/50], Step [3800/5013], Loss: 0.3139\n",
      "Epoch [34/50], Step [3900/5013], Loss: 0.2863\n",
      "Epoch [34/50], Step [4000/5013], Loss: 0.3239\n",
      "Epoch [34/50], Step [4100/5013], Loss: 0.3174\n",
      "Epoch [34/50], Step [4200/5013], Loss: 0.3180\n",
      "Epoch [34/50], Step [4300/5013], Loss: 0.3296\n",
      "Epoch [34/50], Step [4400/5013], Loss: 0.3205\n",
      "Epoch [34/50], Step [4500/5013], Loss: 0.3113\n",
      "Epoch [34/50], Step [4600/5013], Loss: 0.2969\n",
      "Epoch [34/50], Step [4700/5013], Loss: 0.3093\n",
      "Epoch [34/50], Step [4800/5013], Loss: 0.3227\n",
      "Epoch [34/50], Step [4900/5013], Loss: 0.3114\n",
      "Epoch [34/50], Step [5000/5013], Loss: 0.3269\n",
      "Epoch [34/50] Average Loss: 0.3109\n",
      "Epoch [35/50], Step [100/5013], Loss: 0.2978\n",
      "Epoch [35/50], Step [200/5013], Loss: 0.2968\n",
      "Epoch [35/50], Step [300/5013], Loss: 0.2944\n",
      "Epoch [35/50], Step [400/5013], Loss: 0.2840\n",
      "Epoch [35/50], Step [500/5013], Loss: 0.2924\n",
      "Epoch [35/50], Step [600/5013], Loss: 0.3017\n",
      "Epoch [35/50], Step [700/5013], Loss: 0.3268\n",
      "Epoch [35/50], Step [800/5013], Loss: 0.2905\n",
      "Epoch [35/50], Step [900/5013], Loss: 0.3026\n",
      "Epoch [35/50], Step [1000/5013], Loss: 0.3049\n",
      "Epoch [35/50], Step [1100/5013], Loss: 0.3144\n",
      "Epoch [35/50], Step [1200/5013], Loss: 0.2900\n",
      "Epoch [35/50], Step [1300/5013], Loss: 0.2906\n",
      "Epoch [35/50], Step [1400/5013], Loss: 0.3166\n",
      "Epoch [35/50], Step [1500/5013], Loss: 0.3017\n",
      "Epoch [35/50], Step [1600/5013], Loss: 0.3233\n",
      "Epoch [35/50], Step [1700/5013], Loss: 0.3087\n",
      "Epoch [35/50], Step [1800/5013], Loss: 0.3233\n",
      "Epoch [35/50], Step [1900/5013], Loss: 0.3068\n",
      "Epoch [35/50], Step [2000/5013], Loss: 0.3033\n",
      "Epoch [35/50], Step [2100/5013], Loss: 0.2978\n",
      "Epoch [35/50], Step [2200/5013], Loss: 0.3060\n",
      "Epoch [35/50], Step [2300/5013], Loss: 0.2993\n",
      "Epoch [35/50], Step [2400/5013], Loss: 0.3026\n",
      "Epoch [35/50], Step [2500/5013], Loss: 0.3272\n",
      "Epoch [35/50], Step [2600/5013], Loss: 0.3217\n",
      "Epoch [35/50], Step [2700/5013], Loss: 0.3207\n",
      "Epoch [35/50], Step [2800/5013], Loss: 0.3038\n",
      "Epoch [35/50], Step [2900/5013], Loss: 0.2931\n",
      "Epoch [35/50], Step [3000/5013], Loss: 0.3114\n",
      "Epoch [35/50], Step [3100/5013], Loss: 0.3024\n",
      "Epoch [35/50], Step [3200/5013], Loss: 0.3251\n",
      "Epoch [35/50], Step [3300/5013], Loss: 0.3024\n",
      "Epoch [35/50], Step [3400/5013], Loss: 0.3115\n",
      "Epoch [35/50], Step [3500/5013], Loss: 0.3172\n",
      "Epoch [35/50], Step [3600/5013], Loss: 0.3096\n",
      "Epoch [35/50], Step [3700/5013], Loss: 0.3010\n",
      "Epoch [35/50], Step [3800/5013], Loss: 0.3051\n",
      "Epoch [35/50], Step [3900/5013], Loss: 0.3197\n",
      "Epoch [35/50], Step [4000/5013], Loss: 0.3137\n",
      "Epoch [35/50], Step [4100/5013], Loss: 0.3085\n",
      "Epoch [35/50], Step [4200/5013], Loss: 0.2982\n",
      "Epoch [35/50], Step [4300/5013], Loss: 0.2920\n",
      "Epoch [35/50], Step [4400/5013], Loss: 0.2853\n",
      "Epoch [35/50], Step [4500/5013], Loss: 0.3067\n",
      "Epoch [35/50], Step [4600/5013], Loss: 0.2910\n",
      "Epoch [35/50], Step [4700/5013], Loss: 0.2833\n",
      "Epoch [35/50], Step [4800/5013], Loss: 0.3287\n",
      "Epoch [35/50], Step [4900/5013], Loss: 0.3158\n",
      "Epoch [35/50], Step [5000/5013], Loss: 0.2900\n",
      "Epoch [35/50] Average Loss: 0.3052\n",
      "Epoch [36/50], Step [100/5013], Loss: 0.3066\n",
      "Epoch [36/50], Step [200/5013], Loss: 0.2867\n",
      "Epoch [36/50], Step [300/5013], Loss: 0.3042\n",
      "Epoch [36/50], Step [400/5013], Loss: 0.3005\n",
      "Epoch [36/50], Step [500/5013], Loss: 0.3167\n",
      "Epoch [36/50], Step [600/5013], Loss: 0.3024\n",
      "Epoch [36/50], Step [700/5013], Loss: 0.3181\n",
      "Epoch [36/50], Step [800/5013], Loss: 0.2899\n",
      "Epoch [36/50], Step [900/5013], Loss: 0.2923\n",
      "Epoch [36/50], Step [1000/5013], Loss: 0.2982\n",
      "Epoch [36/50], Step [1100/5013], Loss: 0.2970\n",
      "Epoch [36/50], Step [1200/5013], Loss: 0.2994\n",
      "Epoch [36/50], Step [1300/5013], Loss: 0.3025\n",
      "Epoch [36/50], Step [1400/5013], Loss: 0.3088\n",
      "Epoch [36/50], Step [1500/5013], Loss: 0.3241\n",
      "Epoch [36/50], Step [1600/5013], Loss: 0.3002\n",
      "Epoch [36/50], Step [1700/5013], Loss: 0.2904\n",
      "Epoch [36/50], Step [1800/5013], Loss: 0.3106\n",
      "Epoch [36/50], Step [1900/5013], Loss: 0.2991\n",
      "Epoch [36/50], Step [2000/5013], Loss: 0.3042\n",
      "Epoch [36/50], Step [2100/5013], Loss: 0.3037\n",
      "Epoch [36/50], Step [2200/5013], Loss: 0.3180\n",
      "Epoch [36/50], Step [2300/5013], Loss: 0.3157\n",
      "Epoch [36/50], Step [2400/5013], Loss: 0.3041\n",
      "Epoch [36/50], Step [2500/5013], Loss: 0.2963\n",
      "Epoch [36/50], Step [2600/5013], Loss: 0.3060\n",
      "Epoch [36/50], Step [2700/5013], Loss: 0.2971\n",
      "Epoch [36/50], Step [2800/5013], Loss: 0.3183\n",
      "Epoch [36/50], Step [2900/5013], Loss: 0.2971\n",
      "Epoch [36/50], Step [3000/5013], Loss: 0.3117\n",
      "Epoch [36/50], Step [3100/5013], Loss: 0.3130\n",
      "Epoch [36/50], Step [3200/5013], Loss: 0.3216\n",
      "Epoch [36/50], Step [3300/5013], Loss: 0.2985\n",
      "Epoch [36/50], Step [3400/5013], Loss: 0.3252\n",
      "Epoch [36/50], Step [3500/5013], Loss: 0.3147\n",
      "Epoch [36/50], Step [3600/5013], Loss: 0.3096\n",
      "Epoch [36/50], Step [3700/5013], Loss: 0.2870\n",
      "Epoch [36/50], Step [3800/5013], Loss: 0.2990\n",
      "Epoch [36/50], Step [3900/5013], Loss: 0.3084\n",
      "Epoch [36/50], Step [4000/5013], Loss: 0.3014\n",
      "Epoch [36/50], Step [4100/5013], Loss: 0.3000\n",
      "Epoch [36/50], Step [4200/5013], Loss: 0.3089\n",
      "Epoch [36/50], Step [4300/5013], Loss: 0.2878\n",
      "Epoch [36/50], Step [4400/5013], Loss: 0.2919\n",
      "Epoch [36/50], Step [4500/5013], Loss: 0.3094\n",
      "Epoch [36/50], Step [4600/5013], Loss: 0.3089\n",
      "Epoch [36/50], Step [4700/5013], Loss: 0.3009\n",
      "Epoch [36/50], Step [4800/5013], Loss: 0.3129\n",
      "Epoch [36/50], Step [4900/5013], Loss: 0.3043\n",
      "Epoch [36/50], Step [5000/5013], Loss: 0.2949\n",
      "Epoch [36/50] Average Loss: 0.3044\n",
      "Epoch [37/50], Step [100/5013], Loss: 0.3078\n",
      "Epoch [37/50], Step [200/5013], Loss: 0.3105\n",
      "Epoch [37/50], Step [300/5013], Loss: 0.2741\n",
      "Epoch [37/50], Step [400/5013], Loss: 0.3008\n",
      "Epoch [37/50], Step [500/5013], Loss: 0.3298\n",
      "Epoch [37/50], Step [600/5013], Loss: 0.3036\n",
      "Epoch [37/50], Step [700/5013], Loss: 0.2853\n",
      "Epoch [37/50], Step [800/5013], Loss: 0.2958\n",
      "Epoch [37/50], Step [900/5013], Loss: 0.2929\n",
      "Epoch [37/50], Step [1000/5013], Loss: 0.3036\n",
      "Epoch [37/50], Step [1100/5013], Loss: 0.3412\n",
      "Epoch [37/50], Step [1200/5013], Loss: 0.3183\n",
      "Epoch [37/50], Step [1300/5013], Loss: 0.2972\n",
      "Epoch [37/50], Step [1400/5013], Loss: 0.2966\n",
      "Epoch [37/50], Step [1500/5013], Loss: 0.2904\n",
      "Epoch [37/50], Step [1600/5013], Loss: 0.3092\n",
      "Epoch [37/50], Step [1700/5013], Loss: 0.3223\n",
      "Epoch [37/50], Step [1800/5013], Loss: 0.3078\n",
      "Epoch [37/50], Step [1900/5013], Loss: 0.2901\n",
      "Epoch [37/50], Step [2000/5013], Loss: 0.3252\n",
      "Epoch [37/50], Step [2100/5013], Loss: 0.3054\n",
      "Epoch [37/50], Step [2200/5013], Loss: 0.2997\n",
      "Epoch [37/50], Step [2300/5013], Loss: 0.3056\n",
      "Epoch [37/50], Step [2400/5013], Loss: 0.3064\n",
      "Epoch [37/50], Step [2500/5013], Loss: 0.3089\n",
      "Epoch [37/50], Step [2600/5013], Loss: 0.2936\n",
      "Epoch [37/50], Step [2700/5013], Loss: 0.3151\n",
      "Epoch [37/50], Step [2800/5013], Loss: 0.2871\n",
      "Epoch [37/50], Step [2900/5013], Loss: 0.3170\n",
      "Epoch [37/50], Step [3000/5013], Loss: 0.2855\n",
      "Epoch [37/50], Step [3100/5013], Loss: 0.2792\n",
      "Epoch [37/50], Step [3200/5013], Loss: 0.2904\n",
      "Epoch [37/50], Step [3300/5013], Loss: 0.3080\n",
      "Epoch [37/50], Step [3400/5013], Loss: 0.3040\n",
      "Epoch [37/50], Step [3500/5013], Loss: 0.2978\n",
      "Epoch [37/50], Step [3600/5013], Loss: 0.3153\n",
      "Epoch [37/50], Step [3700/5013], Loss: 0.3156\n",
      "Epoch [37/50], Step [3800/5013], Loss: 0.3143\n",
      "Epoch [37/50], Step [3900/5013], Loss: 0.2727\n",
      "Epoch [37/50], Step [4000/5013], Loss: 0.2997\n",
      "Epoch [37/50], Step [4100/5013], Loss: 0.2980\n",
      "Epoch [37/50], Step [4200/5013], Loss: 0.3102\n",
      "Epoch [37/50], Step [4300/5013], Loss: 0.2980\n",
      "Epoch [37/50], Step [4400/5013], Loss: 0.3107\n",
      "Epoch [37/50], Step [4500/5013], Loss: 0.3518\n",
      "Epoch [37/50], Step [4600/5013], Loss: 0.2933\n",
      "Epoch [37/50], Step [4700/5013], Loss: 0.3010\n",
      "Epoch [37/50], Step [4800/5013], Loss: 0.3065\n",
      "Epoch [37/50], Step [4900/5013], Loss: 0.3094\n",
      "Epoch [37/50], Step [5000/5013], Loss: 0.2872\n",
      "Epoch [37/50] Average Loss: 0.3038\n",
      "Epoch [38/50], Step [100/5013], Loss: 0.3013\n",
      "Epoch [38/50], Step [200/5013], Loss: 0.3269\n",
      "Epoch [38/50], Step [300/5013], Loss: 0.2972\n",
      "Epoch [38/50], Step [400/5013], Loss: 0.2913\n",
      "Epoch [38/50], Step [500/5013], Loss: 0.2972\n",
      "Epoch [38/50], Step [600/5013], Loss: 0.2809\n",
      "Epoch [38/50], Step [700/5013], Loss: 0.3021\n",
      "Epoch [38/50], Step [800/5013], Loss: 0.3128\n",
      "Epoch [38/50], Step [900/5013], Loss: 0.3138\n",
      "Epoch [38/50], Step [1000/5013], Loss: 0.2889\n",
      "Epoch [38/50], Step [1100/5013], Loss: 0.2966\n",
      "Epoch [38/50], Step [1200/5013], Loss: 0.3132\n",
      "Epoch [38/50], Step [1300/5013], Loss: 0.2826\n",
      "Epoch [38/50], Step [1400/5013], Loss: 0.3267\n",
      "Epoch [38/50], Step [1500/5013], Loss: 0.2894\n",
      "Epoch [38/50], Step [1600/5013], Loss: 0.2964\n",
      "Epoch [38/50], Step [1700/5013], Loss: 0.2973\n",
      "Epoch [38/50], Step [1800/5013], Loss: 0.3106\n",
      "Epoch [38/50], Step [1900/5013], Loss: 0.2996\n",
      "Epoch [38/50], Step [2000/5013], Loss: 0.2952\n",
      "Epoch [38/50], Step [2100/5013], Loss: 0.2882\n",
      "Epoch [38/50], Step [2200/5013], Loss: 0.3209\n",
      "Epoch [38/50], Step [2300/5013], Loss: 0.2951\n",
      "Epoch [38/50], Step [2400/5013], Loss: 0.3296\n",
      "Epoch [38/50], Step [2500/5013], Loss: 0.2939\n",
      "Epoch [38/50], Step [2600/5013], Loss: 0.3156\n",
      "Epoch [38/50], Step [2700/5013], Loss: 0.3188\n",
      "Epoch [38/50], Step [2800/5013], Loss: 0.2975\n",
      "Epoch [38/50], Step [2900/5013], Loss: 0.3231\n",
      "Epoch [38/50], Step [3000/5013], Loss: 0.3105\n",
      "Epoch [38/50], Step [3100/5013], Loss: 0.3073\n",
      "Epoch [38/50], Step [3200/5013], Loss: 0.3298\n",
      "Epoch [38/50], Step [3300/5013], Loss: 0.3002\n",
      "Epoch [38/50], Step [3400/5013], Loss: 0.3126\n",
      "Epoch [38/50], Step [3500/5013], Loss: 0.2817\n",
      "Epoch [38/50], Step [3600/5013], Loss: 0.3090\n",
      "Epoch [38/50], Step [3700/5013], Loss: 0.2997\n",
      "Epoch [38/50], Step [3800/5013], Loss: 0.3024\n",
      "Epoch [38/50], Step [3900/5013], Loss: 0.3265\n",
      "Epoch [38/50], Step [4000/5013], Loss: 0.3017\n",
      "Epoch [38/50], Step [4100/5013], Loss: 0.3089\n",
      "Epoch [38/50], Step [4200/5013], Loss: 0.2978\n",
      "Epoch [38/50], Step [4300/5013], Loss: 0.3046\n",
      "Epoch [38/50], Step [4400/5013], Loss: 0.2944\n",
      "Epoch [38/50], Step [4500/5013], Loss: 0.3112\n",
      "Epoch [38/50], Step [4600/5013], Loss: 0.2897\n",
      "Epoch [38/50], Step [4700/5013], Loss: 0.3190\n",
      "Epoch [38/50], Step [4800/5013], Loss: 0.3086\n",
      "Epoch [38/50], Step [4900/5013], Loss: 0.3081\n",
      "Epoch [38/50], Step [5000/5013], Loss: 0.2937\n",
      "Epoch [38/50] Average Loss: 0.3044\n",
      "Epoch [39/50], Step [100/5013], Loss: 0.3271\n",
      "Epoch [39/50], Step [200/5013], Loss: 0.2865\n",
      "Epoch [39/50], Step [300/5013], Loss: 0.2832\n",
      "Epoch [39/50], Step [400/5013], Loss: 0.3205\n",
      "Epoch [39/50], Step [500/5013], Loss: 0.3058\n",
      "Epoch [39/50], Step [600/5013], Loss: 0.3015\n",
      "Epoch [39/50], Step [700/5013], Loss: 0.3164\n",
      "Epoch [39/50], Step [800/5013], Loss: 0.2879\n",
      "Epoch [39/50], Step [900/5013], Loss: 0.2968\n",
      "Epoch [39/50], Step [1000/5013], Loss: 0.2817\n",
      "Epoch [39/50], Step [1100/5013], Loss: 0.3077\n",
      "Epoch [39/50], Step [1200/5013], Loss: 0.3119\n",
      "Epoch [39/50], Step [1300/5013], Loss: 0.3012\n",
      "Epoch [39/50], Step [1400/5013], Loss: 0.3137\n",
      "Epoch [39/50], Step [1500/5013], Loss: 0.3114\n",
      "Epoch [39/50], Step [1600/5013], Loss: 0.3202\n",
      "Epoch [39/50], Step [1700/5013], Loss: 0.3078\n",
      "Epoch [39/50], Step [1800/5013], Loss: 0.2682\n",
      "Epoch [39/50], Step [1900/5013], Loss: 0.2843\n",
      "Epoch [39/50], Step [2000/5013], Loss: 0.3234\n",
      "Epoch [39/50], Step [2100/5013], Loss: 0.3095\n",
      "Epoch [39/50], Step [2200/5013], Loss: 0.2924\n",
      "Epoch [39/50], Step [2300/5013], Loss: 0.2905\n",
      "Epoch [39/50], Step [2400/5013], Loss: 0.2847\n",
      "Epoch [39/50], Step [2500/5013], Loss: 0.2975\n",
      "Epoch [39/50], Step [2600/5013], Loss: 0.2999\n",
      "Epoch [39/50], Step [2700/5013], Loss: 0.3031\n",
      "Epoch [39/50], Step [2800/5013], Loss: 0.3105\n",
      "Epoch [39/50], Step [2900/5013], Loss: 0.2751\n",
      "Epoch [39/50], Step [3000/5013], Loss: 0.2975\n",
      "Epoch [39/50], Step [3100/5013], Loss: 0.3034\n",
      "Epoch [39/50], Step [3200/5013], Loss: 0.3109\n",
      "Epoch [39/50], Step [3300/5013], Loss: 0.2915\n",
      "Epoch [39/50], Step [3400/5013], Loss: 0.2980\n",
      "Epoch [39/50], Step [3500/5013], Loss: 0.2751\n",
      "Epoch [39/50], Step [3600/5013], Loss: 0.3020\n",
      "Epoch [39/50], Step [3700/5013], Loss: 0.3227\n",
      "Epoch [39/50], Step [3800/5013], Loss: 0.2983\n",
      "Epoch [39/50], Step [3900/5013], Loss: 0.3054\n",
      "Epoch [39/50], Step [4000/5013], Loss: 0.3130\n",
      "Epoch [39/50], Step [4100/5013], Loss: 0.3009\n",
      "Epoch [39/50], Step [4200/5013], Loss: 0.3023\n",
      "Epoch [39/50], Step [4300/5013], Loss: 0.3237\n",
      "Epoch [39/50], Step [4400/5013], Loss: 0.3150\n",
      "Epoch [39/50], Step [4500/5013], Loss: 0.3177\n",
      "Epoch [39/50], Step [4600/5013], Loss: 0.2979\n",
      "Epoch [39/50], Step [4700/5013], Loss: 0.2806\n",
      "Epoch [39/50], Step [4800/5013], Loss: 0.3080\n",
      "Epoch [39/50], Step [4900/5013], Loss: 0.3086\n",
      "Epoch [39/50], Step [5000/5013], Loss: 0.2839\n",
      "Epoch [39/50] Average Loss: 0.3016\n",
      "Epoch [40/50], Step [100/5013], Loss: 0.3038\n",
      "Epoch [40/50], Step [200/5013], Loss: 0.2943\n",
      "Epoch [40/50], Step [300/5013], Loss: 0.3069\n",
      "Epoch [40/50], Step [400/5013], Loss: 0.3131\n",
      "Epoch [40/50], Step [500/5013], Loss: 0.3222\n",
      "Epoch [40/50], Step [600/5013], Loss: 0.3007\n",
      "Epoch [40/50], Step [700/5013], Loss: 0.2938\n",
      "Epoch [40/50], Step [800/5013], Loss: 0.2975\n",
      "Epoch [40/50], Step [900/5013], Loss: 0.2778\n",
      "Epoch [40/50], Step [1000/5013], Loss: 0.2932\n",
      "Epoch [40/50], Step [1100/5013], Loss: 0.2906\n",
      "Epoch [40/50], Step [1200/5013], Loss: 0.2991\n",
      "Epoch [40/50], Step [1300/5013], Loss: 0.2969\n",
      "Epoch [40/50], Step [1400/5013], Loss: 0.2859\n",
      "Epoch [40/50], Step [1500/5013], Loss: 0.3268\n",
      "Epoch [40/50], Step [1600/5013], Loss: 0.3005\n",
      "Epoch [40/50], Step [1700/5013], Loss: 0.3300\n",
      "Epoch [40/50], Step [1800/5013], Loss: 0.3035\n",
      "Epoch [40/50], Step [1900/5013], Loss: 0.2892\n",
      "Epoch [40/50], Step [2000/5013], Loss: 0.2751\n",
      "Epoch [40/50], Step [2100/5013], Loss: 0.3086\n",
      "Epoch [40/50], Step [2200/5013], Loss: 0.3035\n",
      "Epoch [40/50], Step [2300/5013], Loss: 0.2978\n",
      "Epoch [40/50], Step [2400/5013], Loss: 0.2806\n",
      "Epoch [40/50], Step [2500/5013], Loss: 0.2792\n",
      "Epoch [40/50], Step [2600/5013], Loss: 0.3143\n",
      "Epoch [40/50], Step [2700/5013], Loss: 0.3009\n",
      "Epoch [40/50], Step [2800/5013], Loss: 0.2944\n",
      "Epoch [40/50], Step [2900/5013], Loss: 0.3163\n",
      "Epoch [40/50], Step [3000/5013], Loss: 0.2943\n",
      "Epoch [40/50], Step [3100/5013], Loss: 0.2976\n",
      "Epoch [40/50], Step [3200/5013], Loss: 0.2947\n",
      "Epoch [40/50], Step [3300/5013], Loss: 0.2814\n",
      "Epoch [40/50], Step [3400/5013], Loss: 0.2952\n",
      "Epoch [40/50], Step [3500/5013], Loss: 0.3097\n",
      "Epoch [40/50], Step [3600/5013], Loss: 0.2843\n",
      "Epoch [40/50], Step [3700/5013], Loss: 0.2971\n",
      "Epoch [40/50], Step [3800/5013], Loss: 0.3135\n",
      "Epoch [40/50], Step [3900/5013], Loss: 0.3079\n",
      "Epoch [40/50], Step [4000/5013], Loss: 0.3321\n",
      "Epoch [40/50], Step [4100/5013], Loss: 0.3088\n",
      "Epoch [40/50], Step [4200/5013], Loss: 0.2988\n",
      "Epoch [40/50], Step [4300/5013], Loss: 0.2868\n",
      "Epoch [40/50], Step [4400/5013], Loss: 0.3144\n",
      "Epoch [40/50], Step [4500/5013], Loss: 0.2873\n",
      "Epoch [40/50], Step [4600/5013], Loss: 0.3134\n",
      "Epoch [40/50], Step [4700/5013], Loss: 0.2981\n",
      "Epoch [40/50], Step [4800/5013], Loss: 0.2864\n",
      "Epoch [40/50], Step [4900/5013], Loss: 0.3176\n",
      "Epoch [40/50], Step [5000/5013], Loss: 0.3112\n",
      "Epoch [40/50] Average Loss: 0.3005\n",
      "Epoch [41/50], Step [100/5013], Loss: 0.2918\n",
      "Epoch [41/50], Step [200/5013], Loss: 0.3029\n",
      "Epoch [41/50], Step [300/5013], Loss: 0.3031\n",
      "Epoch [41/50], Step [400/5013], Loss: 0.2886\n",
      "Epoch [41/50], Step [500/5013], Loss: 0.2665\n",
      "Epoch [41/50], Step [600/5013], Loss: 0.3056\n",
      "Epoch [41/50], Step [700/5013], Loss: 0.2998\n",
      "Epoch [41/50], Step [800/5013], Loss: 0.2904\n",
      "Epoch [41/50], Step [900/5013], Loss: 0.3051\n",
      "Epoch [41/50], Step [1000/5013], Loss: 0.3012\n",
      "Epoch [41/50], Step [1100/5013], Loss: 0.2993\n",
      "Epoch [41/50], Step [1200/5013], Loss: 0.2850\n",
      "Epoch [41/50], Step [1300/5013], Loss: 0.3018\n",
      "Epoch [41/50], Step [1400/5013], Loss: 0.3007\n",
      "Epoch [41/50], Step [1500/5013], Loss: 0.3027\n",
      "Epoch [41/50], Step [1600/5013], Loss: 0.3037\n",
      "Epoch [41/50], Step [1700/5013], Loss: 0.2943\n",
      "Epoch [41/50], Step [1800/5013], Loss: 0.3017\n",
      "Epoch [41/50], Step [1900/5013], Loss: 0.3039\n",
      "Epoch [41/50], Step [2000/5013], Loss: 0.2967\n",
      "Epoch [41/50], Step [2100/5013], Loss: 0.3093\n",
      "Epoch [41/50], Step [2200/5013], Loss: 0.2944\n",
      "Epoch [41/50], Step [2300/5013], Loss: 0.2786\n",
      "Epoch [41/50], Step [2400/5013], Loss: 0.2956\n",
      "Epoch [41/50], Step [2500/5013], Loss: 0.3203\n",
      "Epoch [41/50], Step [2600/5013], Loss: 0.2949\n",
      "Epoch [41/50], Step [2700/5013], Loss: 0.2801\n",
      "Epoch [41/50], Step [2800/5013], Loss: 0.3080\n",
      "Epoch [41/50], Step [2900/5013], Loss: 0.3128\n",
      "Epoch [41/50], Step [3000/5013], Loss: 0.3223\n",
      "Epoch [41/50], Step [3100/5013], Loss: 0.3038\n",
      "Epoch [41/50], Step [3200/5013], Loss: 0.2826\n",
      "Epoch [41/50], Step [3300/5013], Loss: 0.2880\n",
      "Epoch [41/50], Step [3400/5013], Loss: 0.2954\n",
      "Epoch [41/50], Step [3500/5013], Loss: 0.2838\n",
      "Epoch [41/50], Step [3600/5013], Loss: 0.2960\n",
      "Epoch [41/50], Step [3700/5013], Loss: 0.3096\n",
      "Epoch [41/50], Step [3800/5013], Loss: 0.3007\n",
      "Epoch [41/50], Step [3900/5013], Loss: 0.3027\n",
      "Epoch [41/50], Step [4000/5013], Loss: 0.3023\n",
      "Epoch [41/50], Step [4100/5013], Loss: 0.2797\n",
      "Epoch [41/50], Step [4200/5013], Loss: 0.3055\n",
      "Epoch [41/50], Step [4300/5013], Loss: 0.3111\n",
      "Epoch [41/50], Step [4400/5013], Loss: 0.2867\n",
      "Epoch [41/50], Step [4500/5013], Loss: 0.2893\n",
      "Epoch [41/50], Step [4600/5013], Loss: 0.2817\n",
      "Epoch [41/50], Step [4700/5013], Loss: 0.3105\n",
      "Epoch [41/50], Step [4800/5013], Loss: 0.3154\n",
      "Epoch [41/50], Step [4900/5013], Loss: 0.3011\n",
      "Epoch [41/50], Step [5000/5013], Loss: 0.3003\n",
      "Epoch [41/50] Average Loss: 0.2982\n",
      "Epoch [42/50], Step [100/5013], Loss: 0.3014\n",
      "Epoch [42/50], Step [200/5013], Loss: 0.2945\n",
      "Epoch [42/50], Step [300/5013], Loss: 0.2791\n",
      "Epoch [42/50], Step [400/5013], Loss: 0.3099\n",
      "Epoch [42/50], Step [500/5013], Loss: 0.2988\n",
      "Epoch [42/50], Step [600/5013], Loss: 0.2873\n",
      "Epoch [42/50], Step [700/5013], Loss: 0.2924\n",
      "Epoch [42/50], Step [800/5013], Loss: 0.2948\n",
      "Epoch [42/50], Step [900/5013], Loss: 0.3173\n",
      "Epoch [42/50], Step [1000/5013], Loss: 0.2930\n",
      "Epoch [42/50], Step [1100/5013], Loss: 0.2872\n",
      "Epoch [42/50], Step [1200/5013], Loss: 0.3437\n",
      "Epoch [42/50], Step [1300/5013], Loss: 0.2938\n",
      "Epoch [42/50], Step [1400/5013], Loss: 0.3172\n",
      "Epoch [42/50], Step [1500/5013], Loss: 0.2980\n",
      "Epoch [42/50], Step [1600/5013], Loss: 0.2949\n",
      "Epoch [42/50], Step [1700/5013], Loss: 0.2976\n",
      "Epoch [42/50], Step [1800/5013], Loss: 0.2967\n",
      "Epoch [42/50], Step [1900/5013], Loss: 0.3064\n",
      "Epoch [42/50], Step [2000/5013], Loss: 0.2804\n",
      "Epoch [42/50], Step [2100/5013], Loss: 0.2906\n",
      "Epoch [42/50], Step [2200/5013], Loss: 0.2968\n",
      "Epoch [42/50], Step [2300/5013], Loss: 0.2947\n",
      "Epoch [42/50], Step [2400/5013], Loss: 0.3060\n",
      "Epoch [42/50], Step [2500/5013], Loss: 0.3099\n",
      "Epoch [42/50], Step [2600/5013], Loss: 0.3102\n",
      "Epoch [42/50], Step [2700/5013], Loss: 0.3153\n",
      "Epoch [42/50], Step [2800/5013], Loss: 0.3018\n",
      "Epoch [42/50], Step [2900/5013], Loss: 0.2899\n",
      "Epoch [42/50], Step [3000/5013], Loss: 0.2831\n",
      "Epoch [42/50], Step [3100/5013], Loss: 0.2928\n",
      "Epoch [42/50], Step [3200/5013], Loss: 0.3273\n",
      "Epoch [42/50], Step [3300/5013], Loss: 0.2994\n",
      "Epoch [42/50], Step [3400/5013], Loss: 0.3014\n",
      "Epoch [42/50], Step [3500/5013], Loss: 0.2816\n",
      "Epoch [42/50], Step [3600/5013], Loss: 0.2967\n",
      "Epoch [42/50], Step [3700/5013], Loss: 0.2893\n",
      "Epoch [42/50], Step [3800/5013], Loss: 0.3089\n",
      "Epoch [42/50], Step [3900/5013], Loss: 0.3133\n",
      "Epoch [42/50], Step [4000/5013], Loss: 0.3033\n",
      "Epoch [42/50], Step [4100/5013], Loss: 0.3377\n",
      "Epoch [42/50], Step [4200/5013], Loss: 0.3026\n",
      "Epoch [42/50], Step [4300/5013], Loss: 0.3089\n",
      "Epoch [42/50], Step [4400/5013], Loss: 0.2934\n",
      "Epoch [42/50], Step [4500/5013], Loss: 0.2850\n",
      "Epoch [42/50], Step [4600/5013], Loss: 0.2802\n",
      "Epoch [42/50], Step [4700/5013], Loss: 0.3046\n",
      "Epoch [42/50], Step [4800/5013], Loss: 0.2903\n",
      "Epoch [42/50], Step [4900/5013], Loss: 0.2829\n",
      "Epoch [42/50], Step [5000/5013], Loss: 0.2973\n",
      "Epoch [42/50] Average Loss: 0.2996\n",
      "Epoch [43/50], Step [100/5013], Loss: 0.2715\n",
      "Epoch [43/50], Step [200/5013], Loss: 0.2854\n",
      "Epoch [43/50], Step [300/5013], Loss: 0.2761\n",
      "Epoch [43/50], Step [400/5013], Loss: 0.2856\n",
      "Epoch [43/50], Step [500/5013], Loss: 0.2826\n",
      "Epoch [43/50], Step [600/5013], Loss: 0.3033\n",
      "Epoch [43/50], Step [700/5013], Loss: 0.2816\n",
      "Epoch [43/50], Step [800/5013], Loss: 0.2842\n",
      "Epoch [43/50], Step [900/5013], Loss: 0.2901\n",
      "Epoch [43/50], Step [1000/5013], Loss: 0.2718\n",
      "Epoch [43/50], Step [1100/5013], Loss: 0.3041\n",
      "Epoch [43/50], Step [1200/5013], Loss: 0.2931\n",
      "Epoch [43/50], Step [1300/5013], Loss: 0.2862\n",
      "Epoch [43/50], Step [1400/5013], Loss: 0.2917\n",
      "Epoch [43/50], Step [1500/5013], Loss: 0.3167\n",
      "Epoch [43/50], Step [1600/5013], Loss: 0.3162\n",
      "Epoch [43/50], Step [1700/5013], Loss: 0.3071\n",
      "Epoch [43/50], Step [1800/5013], Loss: 0.2878\n",
      "Epoch [43/50], Step [1900/5013], Loss: 0.2844\n",
      "Epoch [43/50], Step [2000/5013], Loss: 0.3037\n",
      "Epoch [43/50], Step [2100/5013], Loss: 0.2896\n",
      "Epoch [43/50], Step [2200/5013], Loss: 0.2794\n",
      "Epoch [43/50], Step [2300/5013], Loss: 0.2948\n",
      "Epoch [43/50], Step [2400/5013], Loss: 0.2938\n",
      "Epoch [43/50], Step [2500/5013], Loss: 0.2739\n",
      "Epoch [43/50], Step [2600/5013], Loss: 0.3155\n",
      "Epoch [43/50], Step [2700/5013], Loss: 0.2995\n",
      "Epoch [43/50], Step [2800/5013], Loss: 0.3081\n",
      "Epoch [43/50], Step [2900/5013], Loss: 0.3039\n",
      "Epoch [43/50], Step [3000/5013], Loss: 0.3038\n",
      "Epoch [43/50], Step [3100/5013], Loss: 0.2776\n",
      "Epoch [43/50], Step [3200/5013], Loss: 0.2970\n",
      "Epoch [43/50], Step [3300/5013], Loss: 0.2778\n",
      "Epoch [43/50], Step [3400/5013], Loss: 0.2821\n",
      "Epoch [43/50], Step [3500/5013], Loss: 0.2913\n",
      "Epoch [43/50], Step [3600/5013], Loss: 0.2994\n",
      "Epoch [43/50], Step [3700/5013], Loss: 0.2901\n",
      "Epoch [43/50], Step [3800/5013], Loss: 0.2936\n",
      "Epoch [43/50], Step [3900/5013], Loss: 0.2994\n",
      "Epoch [43/50], Step [4000/5013], Loss: 0.2928\n",
      "Epoch [43/50], Step [4100/5013], Loss: 0.3073\n",
      "Epoch [43/50], Step [4200/5013], Loss: 0.2827\n",
      "Epoch [43/50], Step [4300/5013], Loss: 0.2964\n",
      "Epoch [43/50], Step [4400/5013], Loss: 0.2957\n",
      "Epoch [43/50], Step [4500/5013], Loss: 0.2967\n",
      "Epoch [43/50], Step [4600/5013], Loss: 0.2980\n",
      "Epoch [43/50], Step [4700/5013], Loss: 0.3008\n",
      "Epoch [43/50], Step [4800/5013], Loss: 0.3136\n",
      "Epoch [43/50], Step [4900/5013], Loss: 0.3052\n",
      "Epoch [43/50], Step [5000/5013], Loss: 0.2821\n",
      "Epoch [43/50] Average Loss: 0.2932\n",
      "Epoch [44/50], Step [100/5013], Loss: 0.2732\n",
      "Epoch [44/50], Step [200/5013], Loss: 0.3051\n",
      "Epoch [44/50], Step [300/5013], Loss: 0.2774\n",
      "Epoch [44/50], Step [400/5013], Loss: 0.3102\n",
      "Epoch [44/50], Step [500/5013], Loss: 0.3188\n",
      "Epoch [44/50], Step [600/5013], Loss: 0.3049\n",
      "Epoch [44/50], Step [700/5013], Loss: 0.2871\n",
      "Epoch [44/50], Step [800/5013], Loss: 0.2883\n",
      "Epoch [44/50], Step [900/5013], Loss: 0.2970\n",
      "Epoch [44/50], Step [1000/5013], Loss: 0.2755\n",
      "Epoch [44/50], Step [1100/5013], Loss: 0.2789\n",
      "Epoch [44/50], Step [1200/5013], Loss: 0.3039\n",
      "Epoch [44/50], Step [1300/5013], Loss: 0.3066\n",
      "Epoch [44/50], Step [1400/5013], Loss: 0.2672\n",
      "Epoch [44/50], Step [1500/5013], Loss: 0.2882\n",
      "Epoch [44/50], Step [1600/5013], Loss: 0.2729\n",
      "Epoch [44/50], Step [1700/5013], Loss: 0.2963\n",
      "Epoch [44/50], Step [1800/5013], Loss: 0.3010\n",
      "Epoch [44/50], Step [1900/5013], Loss: 0.3011\n",
      "Epoch [44/50], Step [2000/5013], Loss: 0.2798\n",
      "Epoch [44/50], Step [2100/5013], Loss: 0.3128\n",
      "Epoch [44/50], Step [2200/5013], Loss: 0.2998\n",
      "Epoch [44/50], Step [2300/5013], Loss: 0.2813\n",
      "Epoch [44/50], Step [2400/5013], Loss: 0.3058\n",
      "Epoch [44/50], Step [2500/5013], Loss: 0.3080\n",
      "Epoch [44/50], Step [2600/5013], Loss: 0.2919\n",
      "Epoch [44/50], Step [2700/5013], Loss: 0.2706\n",
      "Epoch [44/50], Step [2800/5013], Loss: 0.3019\n",
      "Epoch [44/50], Step [2900/5013], Loss: 0.2965\n",
      "Epoch [44/50], Step [3000/5013], Loss: 0.2622\n",
      "Epoch [44/50], Step [3100/5013], Loss: 0.2850\n",
      "Epoch [44/50], Step [3200/5013], Loss: 0.3142\n",
      "Epoch [44/50], Step [3300/5013], Loss: 0.2808\n",
      "Epoch [44/50], Step [3400/5013], Loss: 0.2822\n",
      "Epoch [44/50], Step [3500/5013], Loss: 0.2922\n",
      "Epoch [44/50], Step [3600/5013], Loss: 0.3174\n",
      "Epoch [44/50], Step [3700/5013], Loss: 0.2836\n",
      "Epoch [44/50], Step [3800/5013], Loss: 0.2821\n",
      "Epoch [44/50], Step [3900/5013], Loss: 0.2890\n",
      "Epoch [44/50], Step [4000/5013], Loss: 0.2934\n",
      "Epoch [44/50], Step [4100/5013], Loss: 0.3039\n",
      "Epoch [44/50], Step [4200/5013], Loss: 0.3176\n",
      "Epoch [44/50], Step [4300/5013], Loss: 0.2821\n",
      "Epoch [44/50], Step [4400/5013], Loss: 0.3179\n",
      "Epoch [44/50], Step [4500/5013], Loss: 0.2937\n",
      "Epoch [44/50], Step [4600/5013], Loss: 0.3116\n",
      "Epoch [44/50], Step [4700/5013], Loss: 0.2759\n",
      "Epoch [44/50], Step [4800/5013], Loss: 0.3050\n",
      "Epoch [44/50], Step [4900/5013], Loss: 0.2877\n",
      "Epoch [44/50], Step [5000/5013], Loss: 0.2692\n",
      "Epoch [44/50] Average Loss: 0.2930\n",
      "Epoch [45/50], Step [100/5013], Loss: 0.2844\n",
      "Epoch [45/50], Step [200/5013], Loss: 0.3070\n",
      "Epoch [45/50], Step [300/5013], Loss: 0.2873\n",
      "Epoch [45/50], Step [400/5013], Loss: 0.2976\n",
      "Epoch [45/50], Step [500/5013], Loss: 0.2870\n",
      "Epoch [45/50], Step [600/5013], Loss: 0.3226\n",
      "Epoch [45/50], Step [700/5013], Loss: 0.2739\n",
      "Epoch [45/50], Step [800/5013], Loss: 0.3009\n",
      "Epoch [45/50], Step [900/5013], Loss: 0.3115\n",
      "Epoch [45/50], Step [1000/5013], Loss: 0.2891\n",
      "Epoch [45/50], Step [1100/5013], Loss: 0.2986\n",
      "Epoch [45/50], Step [1200/5013], Loss: 0.2979\n",
      "Epoch [45/50], Step [1300/5013], Loss: 0.2866\n",
      "Epoch [45/50], Step [1400/5013], Loss: 0.2594\n",
      "Epoch [45/50], Step [1500/5013], Loss: 0.3104\n",
      "Epoch [45/50], Step [1600/5013], Loss: 0.2829\n",
      "Epoch [45/50], Step [1700/5013], Loss: 0.2900\n",
      "Epoch [45/50], Step [1800/5013], Loss: 0.2846\n",
      "Epoch [45/50], Step [1900/5013], Loss: 0.3039\n",
      "Epoch [45/50], Step [2000/5013], Loss: 0.3185\n",
      "Epoch [45/50], Step [2100/5013], Loss: 0.3149\n",
      "Epoch [45/50], Step [2200/5013], Loss: 0.2657\n",
      "Epoch [45/50], Step [2300/5013], Loss: 0.2904\n",
      "Epoch [45/50], Step [2400/5013], Loss: 0.3043\n",
      "Epoch [45/50], Step [2500/5013], Loss: 0.2964\n",
      "Epoch [45/50], Step [2600/5013], Loss: 0.2965\n",
      "Epoch [45/50], Step [2700/5013], Loss: 0.2952\n",
      "Epoch [45/50], Step [2800/5013], Loss: 0.2834\n",
      "Epoch [45/50], Step [2900/5013], Loss: 0.3036\n",
      "Epoch [45/50], Step [3000/5013], Loss: 0.2731\n",
      "Epoch [45/50], Step [3100/5013], Loss: 0.2793\n",
      "Epoch [45/50], Step [3200/5013], Loss: 0.2799\n",
      "Epoch [45/50], Step [3300/5013], Loss: 0.3113\n",
      "Epoch [45/50], Step [3400/5013], Loss: 0.2889\n",
      "Epoch [45/50], Step [3500/5013], Loss: 0.2739\n",
      "Epoch [45/50], Step [3600/5013], Loss: 0.2984\n",
      "Epoch [45/50], Step [3700/5013], Loss: 0.2910\n",
      "Epoch [45/50], Step [3800/5013], Loss: 0.2895\n",
      "Epoch [45/50], Step [3900/5013], Loss: 0.3029\n",
      "Epoch [45/50], Step [4000/5013], Loss: 0.2981\n",
      "Epoch [45/50], Step [4100/5013], Loss: 0.2670\n",
      "Epoch [45/50], Step [4200/5013], Loss: 0.3167\n",
      "Epoch [45/50], Step [4300/5013], Loss: 0.3011\n",
      "Epoch [45/50], Step [4400/5013], Loss: 0.2858\n",
      "Epoch [45/50], Step [4500/5013], Loss: 0.2745\n",
      "Epoch [45/50], Step [4600/5013], Loss: 0.3076\n",
      "Epoch [45/50], Step [4700/5013], Loss: 0.3382\n",
      "Epoch [45/50], Step [4800/5013], Loss: 0.2951\n",
      "Epoch [45/50], Step [4900/5013], Loss: 0.2911\n",
      "Epoch [45/50], Step [5000/5013], Loss: 0.2881\n",
      "Epoch [45/50] Average Loss: 0.2939\n",
      "Epoch [46/50], Step [100/5013], Loss: 0.2699\n",
      "Epoch [46/50], Step [200/5013], Loss: 0.2894\n",
      "Epoch [46/50], Step [300/5013], Loss: 0.2982\n",
      "Epoch [46/50], Step [400/5013], Loss: 0.2962\n",
      "Epoch [46/50], Step [500/5013], Loss: 0.2695\n",
      "Epoch [46/50], Step [600/5013], Loss: 0.3060\n",
      "Epoch [46/50], Step [700/5013], Loss: 0.2905\n",
      "Epoch [46/50], Step [800/5013], Loss: 0.2772\n",
      "Epoch [46/50], Step [900/5013], Loss: 0.3074\n",
      "Epoch [46/50], Step [1000/5013], Loss: 0.2888\n",
      "Epoch [46/50], Step [1100/5013], Loss: 0.3012\n",
      "Epoch [46/50], Step [1200/5013], Loss: 0.2886\n",
      "Epoch [46/50], Step [1300/5013], Loss: 0.2777\n",
      "Epoch [46/50], Step [1400/5013], Loss: 0.2711\n",
      "Epoch [46/50], Step [1500/5013], Loss: 0.2855\n",
      "Epoch [46/50], Step [1600/5013], Loss: 0.3105\n",
      "Epoch [46/50], Step [1700/5013], Loss: 0.2939\n",
      "Epoch [46/50], Step [1800/5013], Loss: 0.2893\n",
      "Epoch [46/50], Step [1900/5013], Loss: 0.2897\n",
      "Epoch [46/50], Step [2000/5013], Loss: 0.2958\n",
      "Epoch [46/50], Step [2100/5013], Loss: 0.2792\n",
      "Epoch [46/50], Step [2200/5013], Loss: 0.2917\n",
      "Epoch [46/50], Step [2300/5013], Loss: 0.2806\n",
      "Epoch [46/50], Step [2400/5013], Loss: 0.2945\n",
      "Epoch [46/50], Step [2500/5013], Loss: 0.2975\n",
      "Epoch [46/50], Step [2600/5013], Loss: 0.2799\n",
      "Epoch [46/50], Step [2700/5013], Loss: 0.2907\n",
      "Epoch [46/50], Step [2800/5013], Loss: 0.2901\n",
      "Epoch [46/50], Step [2900/5013], Loss: 0.2978\n",
      "Epoch [46/50], Step [3000/5013], Loss: 0.2889\n",
      "Epoch [46/50], Step [3100/5013], Loss: 0.2859\n",
      "Epoch [46/50], Step [3200/5013], Loss: 0.2804\n",
      "Epoch [46/50], Step [3300/5013], Loss: 0.2998\n",
      "Epoch [46/50], Step [3400/5013], Loss: 0.2863\n",
      "Epoch [46/50], Step [3500/5013], Loss: 0.3130\n",
      "Epoch [46/50], Step [3600/5013], Loss: 0.3153\n",
      "Epoch [46/50], Step [3700/5013], Loss: 0.2817\n",
      "Epoch [46/50], Step [3800/5013], Loss: 0.3241\n",
      "Epoch [46/50], Step [3900/5013], Loss: 0.2738\n",
      "Epoch [46/50], Step [4000/5013], Loss: 0.2955\n",
      "Epoch [46/50], Step [4100/5013], Loss: 0.3277\n",
      "Epoch [46/50], Step [4200/5013], Loss: 0.2944\n",
      "Epoch [46/50], Step [4300/5013], Loss: 0.2919\n",
      "Epoch [46/50], Step [4400/5013], Loss: 0.3056\n",
      "Epoch [46/50], Step [4500/5013], Loss: 0.2947\n",
      "Epoch [46/50], Step [4600/5013], Loss: 0.3099\n",
      "Epoch [46/50], Step [4700/5013], Loss: 0.2878\n",
      "Epoch [46/50], Step [4800/5013], Loss: 0.2808\n",
      "Epoch [46/50], Step [4900/5013], Loss: 0.2658\n",
      "Epoch [46/50], Step [5000/5013], Loss: 0.2796\n",
      "Epoch [46/50] Average Loss: 0.2915\n",
      "Epoch [47/50], Step [100/5013], Loss: 0.2872\n",
      "Epoch [47/50], Step [200/5013], Loss: 0.2873\n",
      "Epoch [47/50], Step [300/5013], Loss: 0.2877\n",
      "Epoch [47/50], Step [400/5013], Loss: 0.2878\n",
      "Epoch [47/50], Step [500/5013], Loss: 0.3043\n",
      "Epoch [47/50], Step [600/5013], Loss: 0.3096\n",
      "Epoch [47/50], Step [700/5013], Loss: 0.2728\n",
      "Epoch [47/50], Step [800/5013], Loss: 0.2774\n",
      "Epoch [47/50], Step [900/5013], Loss: 0.2790\n",
      "Epoch [47/50], Step [1000/5013], Loss: 0.2982\n",
      "Epoch [47/50], Step [1100/5013], Loss: 0.2708\n",
      "Epoch [47/50], Step [1200/5013], Loss: 0.2637\n",
      "Epoch [47/50], Step [1300/5013], Loss: 0.2910\n",
      "Epoch [47/50], Step [1400/5013], Loss: 0.3122\n",
      "Epoch [47/50], Step [1500/5013], Loss: 0.2753\n",
      "Epoch [47/50], Step [1600/5013], Loss: 0.2976\n",
      "Epoch [47/50], Step [1700/5013], Loss: 0.2766\n",
      "Epoch [47/50], Step [1800/5013], Loss: 0.2983\n",
      "Epoch [47/50], Step [1900/5013], Loss: 0.3015\n",
      "Epoch [47/50], Step [2000/5013], Loss: 0.2820\n",
      "Epoch [47/50], Step [2100/5013], Loss: 0.2964\n",
      "Epoch [47/50], Step [2200/5013], Loss: 0.2743\n",
      "Epoch [47/50], Step [2300/5013], Loss: 0.2623\n",
      "Epoch [47/50], Step [2400/5013], Loss: 0.2882\n",
      "Epoch [47/50], Step [2500/5013], Loss: 0.2924\n",
      "Epoch [47/50], Step [2600/5013], Loss: 0.3061\n",
      "Epoch [47/50], Step [2700/5013], Loss: 0.2924\n",
      "Epoch [47/50], Step [2800/5013], Loss: 0.2886\n",
      "Epoch [47/50], Step [2900/5013], Loss: 0.2947\n",
      "Epoch [47/50], Step [3000/5013], Loss: 0.3330\n",
      "Epoch [47/50], Step [3100/5013], Loss: 0.3243\n",
      "Epoch [47/50], Step [3200/5013], Loss: 0.2992\n",
      "Epoch [47/50], Step [3300/5013], Loss: 0.2887\n",
      "Epoch [47/50], Step [3400/5013], Loss: 0.3047\n",
      "Epoch [47/50], Step [3500/5013], Loss: 0.2874\n",
      "Epoch [47/50], Step [3600/5013], Loss: 0.2854\n",
      "Epoch [47/50], Step [3700/5013], Loss: 0.2969\n",
      "Epoch [47/50], Step [3800/5013], Loss: 0.2860\n",
      "Epoch [47/50], Step [3900/5013], Loss: 0.2833\n",
      "Epoch [47/50], Step [4000/5013], Loss: 0.2722\n",
      "Epoch [47/50], Step [4100/5013], Loss: 0.2861\n",
      "Epoch [47/50], Step [4200/5013], Loss: 0.2923\n",
      "Epoch [47/50], Step [4300/5013], Loss: 0.2913\n",
      "Epoch [47/50], Step [4400/5013], Loss: 0.2754\n",
      "Epoch [47/50], Step [4500/5013], Loss: 0.3033\n",
      "Epoch [47/50], Step [4600/5013], Loss: 0.2948\n",
      "Epoch [47/50], Step [4700/5013], Loss: 0.2827\n",
      "Epoch [47/50], Step [4800/5013], Loss: 0.3011\n",
      "Epoch [47/50], Step [4900/5013], Loss: 0.2923\n",
      "Epoch [47/50], Step [5000/5013], Loss: 0.3193\n",
      "Epoch [47/50] Average Loss: 0.2913\n",
      "Epoch [48/50], Step [100/5013], Loss: 0.2887\n",
      "Epoch [48/50], Step [200/5013], Loss: 0.2613\n",
      "Epoch [48/50], Step [300/5013], Loss: 0.2814\n",
      "Epoch [48/50], Step [400/5013], Loss: 0.3006\n",
      "Epoch [48/50], Step [500/5013], Loss: 0.2823\n",
      "Epoch [48/50], Step [600/5013], Loss: 0.2950\n",
      "Epoch [48/50], Step [700/5013], Loss: 0.2954\n",
      "Epoch [48/50], Step [800/5013], Loss: 0.2757\n",
      "Epoch [48/50], Step [900/5013], Loss: 0.2812\n",
      "Epoch [48/50], Step [1000/5013], Loss: 0.2888\n",
      "Epoch [48/50], Step [1100/5013], Loss: 0.2869\n",
      "Epoch [48/50], Step [1200/5013], Loss: 0.3109\n",
      "Epoch [48/50], Step [1300/5013], Loss: 0.2907\n",
      "Epoch [48/50], Step [1400/5013], Loss: 0.3006\n",
      "Epoch [48/50], Step [1500/5013], Loss: 0.2802\n",
      "Epoch [48/50], Step [1600/5013], Loss: 0.2682\n",
      "Epoch [48/50], Step [1700/5013], Loss: 0.2924\n",
      "Epoch [48/50], Step [1800/5013], Loss: 0.2761\n",
      "Epoch [48/50], Step [1900/5013], Loss: 0.2773\n",
      "Epoch [48/50], Step [2000/5013], Loss: 0.3042\n",
      "Epoch [48/50], Step [2100/5013], Loss: 0.3080\n",
      "Epoch [48/50], Step [2200/5013], Loss: 0.2987\n",
      "Epoch [48/50], Step [2300/5013], Loss: 0.2669\n",
      "Epoch [48/50], Step [2400/5013], Loss: 0.2933\n",
      "Epoch [48/50], Step [2500/5013], Loss: 0.2850\n",
      "Epoch [48/50], Step [2600/5013], Loss: 0.2937\n",
      "Epoch [48/50], Step [2700/5013], Loss: 0.3357\n",
      "Epoch [48/50], Step [2800/5013], Loss: 0.2933\n",
      "Epoch [48/50], Step [2900/5013], Loss: 0.2857\n",
      "Epoch [48/50], Step [3000/5013], Loss: 0.2676\n",
      "Epoch [48/50], Step [3100/5013], Loss: 0.3115\n",
      "Epoch [48/50], Step [3200/5013], Loss: 0.2987\n",
      "Epoch [48/50], Step [3300/5013], Loss: 0.3249\n",
      "Epoch [48/50], Step [3400/5013], Loss: 0.2878\n",
      "Epoch [48/50], Step [3500/5013], Loss: 0.2877\n",
      "Epoch [48/50], Step [3600/5013], Loss: 0.2782\n",
      "Epoch [48/50], Step [3700/5013], Loss: 0.2846\n",
      "Epoch [48/50], Step [3800/5013], Loss: 0.2864\n",
      "Epoch [48/50], Step [3900/5013], Loss: 0.3037\n",
      "Epoch [48/50], Step [4000/5013], Loss: 0.3066\n",
      "Epoch [48/50], Step [4100/5013], Loss: 0.2854\n",
      "Epoch [48/50], Step [4200/5013], Loss: 0.2767\n",
      "Epoch [48/50], Step [4300/5013], Loss: 0.2725\n",
      "Epoch [48/50], Step [4400/5013], Loss: 0.2806\n",
      "Epoch [48/50], Step [4500/5013], Loss: 0.2856\n",
      "Epoch [48/50], Step [4600/5013], Loss: 0.2633\n",
      "Epoch [48/50], Step [4700/5013], Loss: 0.2934\n",
      "Epoch [48/50], Step [4800/5013], Loss: 0.2943\n",
      "Epoch [48/50], Step [4900/5013], Loss: 0.2889\n",
      "Epoch [48/50], Step [5000/5013], Loss: 0.2821\n",
      "Epoch [48/50] Average Loss: 0.2892\n",
      "Epoch [49/50], Step [100/5013], Loss: 0.2752\n",
      "Epoch [49/50], Step [200/5013], Loss: 0.2941\n",
      "Epoch [49/50], Step [300/5013], Loss: 0.2788\n",
      "Epoch [49/50], Step [400/5013], Loss: 0.2759\n",
      "Epoch [49/50], Step [500/5013], Loss: 0.2940\n",
      "Epoch [49/50], Step [600/5013], Loss: 0.2647\n",
      "Epoch [49/50], Step [700/5013], Loss: 0.2995\n",
      "Epoch [49/50], Step [800/5013], Loss: 0.2993\n",
      "Epoch [49/50], Step [900/5013], Loss: 0.2824\n",
      "Epoch [49/50], Step [1000/5013], Loss: 0.2952\n",
      "Epoch [49/50], Step [1100/5013], Loss: 0.2738\n",
      "Epoch [49/50], Step [1200/5013], Loss: 0.2688\n",
      "Epoch [49/50], Step [1300/5013], Loss: 0.2766\n",
      "Epoch [49/50], Step [1400/5013], Loss: 0.2998\n",
      "Epoch [49/50], Step [1500/5013], Loss: 0.2939\n",
      "Epoch [49/50], Step [1600/5013], Loss: 0.2991\n",
      "Epoch [49/50], Step [1700/5013], Loss: 0.2942\n",
      "Epoch [49/50], Step [1800/5013], Loss: 0.2947\n",
      "Epoch [49/50], Step [1900/5013], Loss: 0.2994\n",
      "Epoch [49/50], Step [2000/5013], Loss: 0.3052\n",
      "Epoch [49/50], Step [2100/5013], Loss: 0.2998\n",
      "Epoch [49/50], Step [2200/5013], Loss: 0.2738\n",
      "Epoch [49/50], Step [2300/5013], Loss: 0.2918\n",
      "Epoch [49/50], Step [2400/5013], Loss: 0.2905\n",
      "Epoch [49/50], Step [2500/5013], Loss: 0.2867\n",
      "Epoch [49/50], Step [2600/5013], Loss: 0.2879\n",
      "Epoch [49/50], Step [2700/5013], Loss: 0.2986\n",
      "Epoch [49/50], Step [2800/5013], Loss: 0.2856\n",
      "Epoch [49/50], Step [2900/5013], Loss: 0.2903\n",
      "Epoch [49/50], Step [3000/5013], Loss: 0.2871\n",
      "Epoch [49/50], Step [3100/5013], Loss: 0.2952\n",
      "Epoch [49/50], Step [3200/5013], Loss: 0.2954\n",
      "Epoch [49/50], Step [3300/5013], Loss: 0.2780\n",
      "Epoch [49/50], Step [3400/5013], Loss: 0.3246\n",
      "Epoch [49/50], Step [3500/5013], Loss: 0.2752\n",
      "Epoch [49/50], Step [3600/5013], Loss: 0.2825\n",
      "Epoch [49/50], Step [3700/5013], Loss: 0.3064\n",
      "Epoch [49/50], Step [3800/5013], Loss: 0.2900\n",
      "Epoch [49/50], Step [3900/5013], Loss: 0.2847\n",
      "Epoch [49/50], Step [4000/5013], Loss: 0.2840\n",
      "Epoch [49/50], Step [4100/5013], Loss: 0.3379\n",
      "Epoch [49/50], Step [4200/5013], Loss: 0.3107\n",
      "Epoch [49/50], Step [4300/5013], Loss: 0.2723\n",
      "Epoch [49/50], Step [4400/5013], Loss: 0.2915\n",
      "Epoch [49/50], Step [4500/5013], Loss: 0.3066\n",
      "Epoch [49/50], Step [4600/5013], Loss: 0.2756\n",
      "Epoch [49/50], Step [4700/5013], Loss: 0.2743\n",
      "Epoch [49/50], Step [4800/5013], Loss: 0.2906\n",
      "Epoch [49/50], Step [4900/5013], Loss: 0.2792\n",
      "Epoch [49/50], Step [5000/5013], Loss: 0.2933\n",
      "Epoch [49/50] Average Loss: 0.2900\n",
      "Epoch [50/50], Step [100/5013], Loss: 0.2991\n",
      "Epoch [50/50], Step [200/5013], Loss: 0.2557\n",
      "Epoch [50/50], Step [300/5013], Loss: 0.2859\n",
      "Epoch [50/50], Step [400/5013], Loss: 0.2844\n",
      "Epoch [50/50], Step [500/5013], Loss: 0.2829\n",
      "Epoch [50/50], Step [600/5013], Loss: 0.2701\n",
      "Epoch [50/50], Step [700/5013], Loss: 0.3157\n",
      "Epoch [50/50], Step [800/5013], Loss: 0.2705\n",
      "Epoch [50/50], Step [900/5013], Loss: 0.2808\n",
      "Epoch [50/50], Step [1000/5013], Loss: 0.2803\n",
      "Epoch [50/50], Step [1100/5013], Loss: 0.3089\n",
      "Epoch [50/50], Step [1200/5013], Loss: 0.2934\n",
      "Epoch [50/50], Step [1300/5013], Loss: 0.2678\n",
      "Epoch [50/50], Step [1400/5013], Loss: 0.2899\n",
      "Epoch [50/50], Step [1500/5013], Loss: 0.2789\n",
      "Epoch [50/50], Step [1600/5013], Loss: 0.2801\n",
      "Epoch [50/50], Step [1700/5013], Loss: 0.3016\n",
      "Epoch [50/50], Step [1800/5013], Loss: 0.2875\n",
      "Epoch [50/50], Step [1900/5013], Loss: 0.2839\n",
      "Epoch [50/50], Step [2000/5013], Loss: 0.2887\n",
      "Epoch [50/50], Step [2100/5013], Loss: 0.2874\n",
      "Epoch [50/50], Step [2200/5013], Loss: 0.2675\n",
      "Epoch [50/50], Step [2300/5013], Loss: 0.2826\n",
      "Epoch [50/50], Step [2400/5013], Loss: 0.2778\n",
      "Epoch [50/50], Step [2500/5013], Loss: 0.2939\n",
      "Epoch [50/50], Step [2600/5013], Loss: 0.3026\n",
      "Epoch [50/50], Step [2700/5013], Loss: 0.2823\n",
      "Epoch [50/50], Step [2800/5013], Loss: 0.2909\n",
      "Epoch [50/50], Step [2900/5013], Loss: 0.2952\n",
      "Epoch [50/50], Step [3000/5013], Loss: 0.3100\n",
      "Epoch [50/50], Step [3100/5013], Loss: 0.2939\n",
      "Epoch [50/50], Step [3200/5013], Loss: 0.2872\n",
      "Epoch [50/50], Step [3300/5013], Loss: 0.2890\n",
      "Epoch [50/50], Step [3400/5013], Loss: 0.2922\n",
      "Epoch [50/50], Step [3500/5013], Loss: 0.2711\n",
      "Epoch [50/50], Step [3600/5013], Loss: 0.2727\n",
      "Epoch [50/50], Step [3700/5013], Loss: 0.2799\n",
      "Epoch [50/50], Step [3800/5013], Loss: 0.3243\n",
      "Epoch [50/50], Step [3900/5013], Loss: 0.2894\n",
      "Epoch [50/50], Step [4000/5013], Loss: 0.2862\n",
      "Epoch [50/50], Step [4100/5013], Loss: 0.2749\n",
      "Epoch [50/50], Step [4200/5013], Loss: 0.2622\n",
      "Epoch [50/50], Step [4300/5013], Loss: 0.2912\n",
      "Epoch [50/50], Step [4400/5013], Loss: 0.2773\n",
      "Epoch [50/50], Step [4500/5013], Loss: 0.3179\n",
      "Epoch [50/50], Step [4600/5013], Loss: 0.3002\n",
      "Epoch [50/50], Step [4700/5013], Loss: 0.2718\n",
      "Epoch [50/50], Step [4800/5013], Loss: 0.2931\n",
      "Epoch [50/50], Step [4900/5013], Loss: 0.2852\n",
      "Epoch [50/50], Step [5000/5013], Loss: 0.2909\n",
      "Epoch [50/50] Average Loss: 0.2868\n",
      "Training complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "gc.collect()\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=50, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8fb799a-17f0-4200-8c58-c608e1eccdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.3204, Accuracy: 0.8877\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.32035560183354367, 0.8876636543420031)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform evaluation\n",
    "gc.collect()\n",
    "evaluate_model(model, test_loader, criterion, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8974da8-f872-4c40-85bf-e2ce496abb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\saved_models\\sentinal2_best_manuel_params_fulldata_newlabels.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129f933-aa56-4f41-bebe-7493e110f319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
