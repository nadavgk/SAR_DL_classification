{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e867de5e-0979-4867-bff3-c42f8e8ca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221b88ed-c6dc-4a18-9013-de01d1b6f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .h5 file into memory once\n",
    "h5_file_path_train = r\"F:\\DS_project\\m1613658\\random\\training.h5\"\n",
    "h5_file_path_test = r\"F:\\DS_project\\m1613658\\random\\testing.h5\"\n",
    "\n",
    "# Open the H5 files\n",
    "h5_train = h5py.File(h5_file_path_train, 'r')\n",
    "h5_test = h5py.File(h5_file_path_test, 'r')\n",
    "\n",
    "# Extract datasets\n",
    "train_sen1_data = h5_train['sen1']\n",
    "train_sen2_data = h5_train['sen2']\n",
    "train_labels = h5_train['label']\n",
    "\n",
    "test_sen1_data = h5_test['sen1']\n",
    "test_sen2_data = h5_test['sen2']\n",
    "test_labels = h5_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da8d528-5709-4247-98fa-3a63cb24d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, sen1_data, sen2_data, labels):\n",
    "        self.sen1_data = sen1_data\n",
    "        self.sen2_data = sen2_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sen1_image = self.sen1_data[idx]\n",
    "        sen2_image = self.sen2_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        sen1_image = torch.tensor(sen1_image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        sen2_image = torch.tensor(sen2_image, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        # Convert one-hot encoded label to class index\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        label = torch.argmax(label).long()\n",
    "\n",
    "        return sen1_image, sen2_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd0c11b-88bb-47f8-981c-980b636418ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = SatelliteDataset(train_sen1_data, train_sen2_data, train_labels)\n",
    "test_dataset = SatelliteDataset(test_sen1_data, test_sen2_data, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbae08b-5d56-40ce-85d8-1ecc21f4bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=17):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # Sentinel-1 branch\n",
    "        self.sen1_conv1 = nn.Conv2d(8, 32, kernel_size=3, padding=1)\n",
    "        self.sen1_dropout1 = nn.Dropout(p=0.25)\n",
    "        self.sen1_conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.sen1_dropout2 = nn.Dropout(p=0.25)\n",
    "        self.sen1_pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Sentinel-2 branch\n",
    "        self.sen2_conv1 = nn.Conv2d(10, 32, kernel_size=3, padding=1)\n",
    "        self.sen2_dropout1 = nn.Dropout(p=0.25)\n",
    "        self.sen2_conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.sen2_dropout2 = nn.Dropout(p=0.25)\n",
    "        self.sen2_pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers after concatenation\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16 * 2, 128)\n",
    "        self.fc1_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc2_dropout = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, sen1, sen2):\n",
    "        # Sentinel-1 forward pass\n",
    "        x1 = F.relu(self.sen1_conv1(sen1))\n",
    "        x1 = self.sen1_dropout1(x1)\n",
    "        x1 = self.sen1_pool(F.relu(self.sen1_conv2(x1)))\n",
    "        x1 = self.sen1_dropout2(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        # Sentinel-2 forward pass\n",
    "        x2 = F.relu(self.sen2_conv1(sen2))\n",
    "        x2 = self.sen2_dropout1(x2)\n",
    "        x2 = self.sen2_pool(F.relu(self.sen2_conv2(x2)))\n",
    "        x2 = self.sen2_dropout2(x2)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        # Concatenate both branches\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc1_dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc2_dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7aa2a4-1530-431e-b802-f0dd0c33742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with visualization\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []  # List to store training loss for visualization\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        for i, (sen1, sen2, labels) in enumerate(train_loader):\n",
    "            sen1, sen2, labels = sen1.to(device), sen2.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sen1, sen2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Store the average loss for the epoch\n",
    "        epoch_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Average Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    print('Training complete')\n",
    "\n",
    "    # Visualization of training loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbeee83-8f4a-4817-a9d5-65a4bfa68033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function with visualization\n",
    "def evaluate_model(model, test_loader, criterion, num_epochs, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    val_losses = []  # List to store validation loss for visualization\n",
    "    val_accuracies = []  # List to store validation accuracy for visualization\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for sen1, sen2, labels in test_loader:\n",
    "                sen1, sen2, labels = sen1.to(device), sen2.to(device), labels.to(device)\n",
    "                outputs = model(sen1, sen2)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "\n",
    "        val_losses.append(avg_loss)\n",
    "        val_accuracies.append(accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] Average Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Visualization of validation metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, marker='o', label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, marker='o', color='orange', label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395aa92a-559d-46d5-8e7f-2a09fb2490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = ConvNet(num_classes=17)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9c6a6b-8af1-4004-926f-ae31f133a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [100/2507], Loss: 2.0887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     10\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msen1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msen1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msen1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\dl_calssification\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\PycharmProjects\\dl_calssification\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\PycharmProjects\\dl_calssification\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\PycharmProjects\\dl_calssification\\venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mSatelliteDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 11\u001b[0m     sen1_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msen1_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m     sen2_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msen2_data[idx]\n\u001b[0;32m     13\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\PycharmProjects\\dl_calssification\\venv\\Lib\\site-packages\\h5py\\_hl\\dataset.py:781\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=20, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b5f3e-cd20-47bd-9799-eb65720f6e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader, criterion, num_epochs=20, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
