{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c83fb373-efeb-4a73-acde-e219f6485661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nbimporter\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from two_sats import SatelliteDataset, ConvNet\n",
    "from sentinal_1 import Sentinel1Dataset, Sentinel1ConvNet\n",
    "from sentinal_2 import Sentinel2Dataset, Sentinel2ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "327a4d62-55aa-4471-8b02-06292c3974f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .h5 file into memory once\n",
    "\n",
    "h5_file_path_test = r\"C:\\Users\\nadav.k\\Documents\\DS\\DL_classification\\classification_data\\testing_10perc_of_20_subset.h5\"\n",
    "\n",
    "# Open the H5 files\n",
    "h5_test = h5py.File(h5_file_path_test, 'r')\n",
    "test_sen1_data = h5_test['sen1']\n",
    "test_sen2_data = h5_test['sen2']\n",
    "test_labels = h5_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d362be5-1521-42c0-9d8d-a4bc7e1fe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloader(dataset_type, batch_size=32, shuffle=False):\n",
    "    \"\"\"\n",
    "    Returns a DataLoader for the specified dataset type.\n",
    "\n",
    "    Args:\n",
    "        dataset_type (str): Type of the dataset ('SatelliteDataset', 'Sentinel1Dataset', 'Sentinel2Dataset').\n",
    "        batch_size (int): Batch size for the DataLoader.\n",
    "        shuffle (bool): Whether to shuffle the dataset.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader for the specified dataset.\n",
    "    \"\"\"\n",
    "    if dataset_type == \"SatelliteDataset\":\n",
    "        dataset = SatelliteDataset(sen1_data=test_sen1_data, sen2_data=test_sen2_data, labels=test_labels)\n",
    "    elif dataset_type == \"Sentinel1Dataset\":\n",
    "        dataset = Sentinel1Dataset(sen1_data=test_sen1_data, labels=test_labels)\n",
    "    elif dataset_type == \"Sentinel2Dataset\":\n",
    "        dataset = Sentinel2Dataset(sen2_data=test_sen2_data, labels=test_labels)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset type: {dataset_type}\")\n",
    "\n",
    "    # Create and return the DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    print(f\"{dataset_type} loaded with {len(dataset)} samples.\")\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6d9896b-49f7-415e-9802-a58be3f7f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel2Dataset loaded with 1597 samples.\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_dataloader(dataset_type=\"Sentinel2Dataset\", batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5518e-8270-472c-9f3f-847d156d7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to load a model\n",
    "def load_model(model_class, path, num_classes=17, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Load a saved model from the specified path.\n",
    "\n",
    "    Args:\n",
    "        model_class: The class of the model to instantiate.\n",
    "        path: Full path to the saved model (e.g., './models/sentinel2_classification_model.pth').\n",
    "        num_classes: Number of classes for the model.\n",
    "        device: Device to load the model ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        The loaded model.\n",
    "    \"\"\"\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38a519-e352-4f0c-af79-eaa57e0d57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model_performance_general(model, test_loader, num_classes=17, satellite_type=\"both\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    General evaluation function for Sentinel-1, Sentinel-2, or both.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model to evaluate.\n",
    "        test_loader: DataLoader for the test dataset.\n",
    "        num_classes: Number of classes.\n",
    "        satellite_type: 'sentinel1', 'sentinel2', or 'both'.\n",
    "        device: Device for computation ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model(data)\n",
    "\n",
    "            # Get predicted labels\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Append to lists\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=range(num_classes))\n",
    "\n",
    "    # Display confusion matrix\n",
    "    print(f\"Confusion Matrix for {satellite_type.capitalize()}:\\n\", cm)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(num_classes)).plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - {satellite_type.capitalize()}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Correct vs incorrect predictions\n",
    "    correct_per_label = np.diag(cm)\n",
    "    total_per_label = np.sum(cm, axis=1)\n",
    "    incorrect_per_label = total_per_label - correct_per_label\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(correct_per_label))\n",
    "    plt.bar(x - 0.2, correct_per_label, width=0.4, label=\"Correct\", color=\"g\")\n",
    "    plt.bar(x + 0.2, incorrect_per_label, width=0.4, label=\"Incorrect\", color=\"r\")\n",
    "    plt.xticks(ticks=x, labels=range(num_classes))\n",
    "    plt.title(f\"Correct vs Incorrect Predictions - {satellite_type.capitalize()}\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
